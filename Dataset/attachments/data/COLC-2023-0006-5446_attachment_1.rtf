{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1033{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\*\generator Riched20 10.0.22621}\viewkind4\uc1 
\pard\sa200\sl276\slmult1\f0\fs22\lang9 1. The only benefit to the use of generative AI is the speed at which passable artwork and highly questionable clickbait articles can be produced. The issues far outweigh this in not only removing jobs typically inhabited by entry level writers and artists, but also greatly reducing the overall quality produced. When on the topic of articles, especially those related to news, it's important to remember that AI programs like ChatGPT are incapable of discerning the difference between fact or fiction. The program is often described as suffering "hallucinations" and frequently simply invents answers to questions that don't exist in its database. Often, even if they do exist, it does not accurately link those things together. That isn't it's function after all, the goal is to generate predictive text, not true information.\par
Likewise with image generators there are still a lot of flaws with the images produced, though that isn't the main concern. Already we are seeing the effects of companies utilizing software like Stability Diffusion and Midjourney to oust large portions of their workforce. Wizards of the Coast has recently come under fire for AI generated images being placed in its art book, an expensive book in which people wish to see the work of human artists, not generated images. Some companies have been caught using AI to make book covers, rather than hiring an artist, and even video game companies like Niantec are pairing down the workforce to replace them with machines. Let us not forget that in order for these tools to even work they were trained without the consent of any parties involved in the data collection process.\par
\par
5. New legislation will be the only way to bulwark against mass abuse of these tools, eliminating jobs in all major creative sectors including graphic design, journalism, authorship, screenwriters, so on and so forth. New copyright law would likely have to carefully lay out exactly what constitutes adequate human interaction to be viable for authorship, and possibly consider how much of an individual's labor can a company or corporation lay claim to. I.E. can they own an individual's face to put into movies indefinitely, can they own their style, can they own their entire library of written works?\par
7. Generative, particularly the LORA datasets (those used for most generative text and image programs), were trained by scraping large swaths of the internet for data. Over 5 billion, the latest dataset claims, primarily from sites commonly used as online digital art and writing portfolios such as Artstation, DeviantArt, and social media sites. This data was collected enmasse without regard to consent, privacy, or copyright.\par
7.3. Simply put, no. Once a work is in the dataset it is in the dataset forever, it is impossible to remove.\par
8. Fair use should only work for research, or open source (non commercial) availability. Anything produced with those models should not be eligible for its own copyright.\par
8.3. If datasets were gathered without knowledge or consent for the purposes of research those datasets should be required to remain locked into the research role only, and never provided for commercial use. Should an algorithm prove viable for commercial use, it should be required to be freshly trained on public domain, donation, or appropriately purchased works only.\par
9. All training datasets should be required to be opt in only, as not only is opt out cumbersome and largely impossible (once data is in the dataset, it cannot be removed), there are no other circumstances in which the default option is opt out. Imagine if one were automatically enrolled in an experimental medical study and not informed until being dragged off to a facility? That would be outlandish. \par
9.1. Yes.\par
9.2. Opt out would be impossible to implement fairly.\par
9.3. If a company desired to train a model they should only be allowed to utilize works that are already in the public domain, and that which are volunteered or paid for. The exact same process utilized for the use of all creative works in commercial print or production.\par
13. While I cannot speak to the complexity of such licensing schemes, I can imagine that putting out a call for artists and writers to submit works for use in training sets would create a number of jobs, either long term or contractor based.\par
15. Yes. To all.\par
15.1. Thorough documentation of contributed authorship and number of works included.\par
15.2. Disclosures should be publicly available.\par
16. AI models should not be trained without consent from copyright holders. They should be informed prior to training ever taking place.\par
18. If there is significant alteration from a human author, such as turning generative images into a video, only using parts within an overall artistic work, or a video game then copyright would apply to those portions under direct human creation. Typing keywords into a prompt generator is akin to a complicated google search, and does not qualify as notable human authorship. Likewise selecting which images to keep out of a batch of generated images makes for a curator, not a creator. The owner of an art museum is no more the copyright holder of the paintings within than someone selecting which generated image to use.\par
19. It will probably become necessary to specify what constitutes human authorship. If a monkey cannot own copyright to its own selfie, a machine certainly cannot.\par
20. I do not personally feel it would be beneficial to protect AI-generated works, as that only further encourages the mass art theft we're already seeing. Protecting the code should be sufficient, as that is the part that falls under human authorship.\par
21. No.\par
22. No.\par
23. Yes.\par
25. Whoever was responsible for the training dataset should be liable for not properly licensing the works used within. In the cases of a tool being made publicly available without being pre-trained, then the issuing company may hold some liability if they are failing to impress the importance of not infringing on copyright when training and utilizing models.\par
28. AI use should be clearly identified in all instances, yes. If generative AI is utilized in full or in part, there should be an apparent notice of what program was used and for what part. Much like a rating disclaimer.\par
28.1. Whoever produced the work.\par
28.2. If one can slap an ESRB rating or notify of sponsored content, they can make it clear when AI was utilized in a creative work.\par
28.2. Removal and possibly fines and/or legal action in the case of repeated offenses.\par
30. One should absolutely not be permitted to copyright the use of someone else's likeness or identiy for the use in AI.\par
32. There should be, though I do not know exactly how one might go about that without also risking the ability of traditional artists to experiment with the styles of artists in the past. Perhaps if the protection was only in place against the use of generative works, as they are capable of essentially flooding out the works of existing artists. See Greg Rutkowski.\par
34. Art theft has always been a problem, and always will be a problem, but the use of generative AI has amplified it a thousandfold. However, there arise numerous other problems with allowing the unfettered utilization of AI tools. In journalism it will likely only increase the issues in regards to misinformation and disinformation, as well as creating even greater distrust for genuine news outlets. Already we are seeing very convincing replications (deepfakes) of political leaders, which could absolutely be used with malicious intent. On Amazon swaths of self-published low quality children's books poses a risk to the ability to learn important skills about grammar and sentence structure. Entry level jobs will be automated out. Overall I cannot see a future where the current status of generative AI programs does anything but harm society as a whole.\par
}
 