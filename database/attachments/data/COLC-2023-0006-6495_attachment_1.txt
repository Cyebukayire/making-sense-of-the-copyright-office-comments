1.) As the technology currently exists, I believe it is mostly harmful to creators of visual and literary arts. AI is a tool, one which corporate interests desire to use as a replacement for skilled workers. I have heard of artists using AI to generate backgrounds, which they then draw over; it isn't a problem that AI exists, and there are definitely positive use cases for it. But the negative possibilities of writers and artists being imitated warrant regulation.
2.) For clarity, I am a writer and a game developer. Large studios in my industry (notably Ubisoft) have expressed a desire to downsize their writing staff in favor of AI models.
6.) From my understanding, all kinds of materials are fed into the dataset, and it depends entirely on the individual model whether that material is copyrighted or not and how it was sourced. At least some of the material has been gathered by bot programs that scrape websites for information, and I believe that some sites will give or sell the material to people working on the model based on their terms of service.
6.2) I have not heard of a single creator willingly contributing their material into these datasets.
7.1) My understanding of how AI is trained is as follows: the program is fed the dataset and begins to look for patterns (which word is most likely to come next, what color should the next pixel be based on the others); these patterns are then confirmed or rejected by human input to create a model based on what the use-case for the model is (ie, a model designed to produce works similar to Picasso would reject a realistic image of a house in favor of an abstract one). However, the output of the model is effectively cut and paste from its input, such that it is impossible to say where one work ends and another begins.
7.4) I do not believe it is possible to determine the exact material a model was trained on without access to the dataset used in most cases. A particular quirk in writing or art style might give it away, however.
8.) I do not feel there is a fair use case for training an AI model on copyrighted material, except (perhaps) for an academic project performed by a student with no commercial intent or distribution beyond the confines of the class. In short, distributing the model is, in my opinion, equivalent to distributing all of the component works that compose the dataset.
8.2) Entities which collect material to be used in training should be required to disclose to all those they've collected from what entities they are giving the material to, and allow anyone they've collected from to opt out of individual distributions.
8.3) Such a model should be required to excise all material that it does not have expressed permission to use, acquire permission for all used works, or otherwise forfeit all output into the public domain.
9.) The collection of training materials should only ever be opt-in, no exception.
9.5) Yes, the creator of the work (even if they no longer own it) should have the right to opt out of having their work put into a training set. Ideally, it would be expressed by contract to the commissioner, and anyone contributing to a training set would have to confirm that they either are the creator of the work or that the creator consented to the work being contributed.
10.) The individual or organization creating the model should be required to obtain the direct consent of each copyright holder, for each individual work being added to the model.
15.) Yes to both entities.
15.1) A comprehensive list of all items used in the training data, consisting either of the named works and creators, the portions taken from the individual item if it is not the whole, and the entirety of "short" items (such as Twitter posts). Ideally, this would include the date the items were acquired, and be as specific as an academic bibliography.
15.2) The disclosure should be publicly available.
15.3) They should be required to ascertain that the third party in question followed the above listed procedures.
15.4) Negligible; all I'm asking for is a text document posted where the end user can see it.
16.) As it should be opt in only, no notice would be required; the notice is in asking permission in the first place.
18.) I believe a human can only be considered the "author" of a work generated through AI if the model used consisted solely of their prior works.
19.) I believe that copyright law should be revised to clarify human authorship, while leaving the possibility of non-human (ie, alien or true artificial sentience) authors for later inclusion.
20.) Not only is it not desirable, I believe AI generated works should be wholly discarded from copyrightability. Existing law creates a gray area that should be firmly closed.
22.) If merely taking a few lyrics from a song can infringe, I fail to see how outputting whole quotes from another work is not infringing.
24.) I do not believe they can, which is why transparency requires legislative enforcement.
25.) The developer should be liable, as should the ones incorporating the model. Additionally, anyone that acquired data for the model without acquiring permission should be liable.
25.1) Yes; for an open-source model, only contributors to the model that infringed should be liable, rather than the creator of the model or all contributors to it.
27.) AI does not produce a truly unique work in any sense of the word; it creates a statistically likely work based on the input. If the works submitted to the model contain a signature in a particular area, the model will attempt to put something where that signature goes without understanding what that signature is or why it is there. That is to say, that it is the real world practice of the metaphorical monkeys on a typewriter, only each key represents a word taken from someone else or a brushstroke on another's canvas. By its very nature, the technology must borrow from what already is in a way that the general act of creation does not; it cannot iterate, it cannot improve, all it can do is repeat the old in a different manner.
28.) Yes. The output of an AI should be marked by the one distributing that output. Ie, if someone uses an AI to write a book and then submits it to Amazon for sale, that person is required to disclose to Amazon that the book is AI generated, and Amazon is in turn required to include that disclosure to would be purchasers. This requirement should apply to all users of AI, in whole or in part, with the extent of the use being included in the disclosure.
28.3) Removal of the label should constitute the same punishment for distributing a work without credit to the work's creator.
30.) I am unaware if any such rights exist. It could be argued that using AI in that manner constitutes a form of impersonation.
31.) Yes, some federal regulation should protect people from having their likeness copied by an AI.
32.) There absolutely should be laws extending protection from an AI copying the style of any person, living or dead, without their expressed permission.
34.) The use of an AI to copy the voice of a person carries serious legal ramifications for impersonation, libel, and other matters of public image. It is a veritable Pandora's Box of potential dangers that should be carefully considered for how it can interfere with the credibility of public figures.