Commenter: Miroslav Policki

7.1. How are training materials used and/or reproduced when training an AI model? Please include your understanding of the nature and duration of any reproduction of works that occur during the training process, as well as your views on the extent to which these activities implicate the exclusive rights of copyright owners.

Training materials are not "reproduced". They are digital data briefly existing in volatile computer memory (RAM) (after being loaded from permanent storage), and training merely performs computations involving this data, with the results of the computations stored in the parameters of the model. Any copying of the digital data inside the components of the computer doing the training results in ephemeral copies which are necessary to perform the computations. Nowhere in the process is it necessary for a human to consume the training materials with his/her senses. The only human involvement with the materials, training-wise, might be to label them before training (which is a necessary activity in supervised learning), not to consume them for their expressive purposes. Therefore, these activities do not significantly implicate the exclusive rights of copyright owners.


8. Under what circumstances would the unauthorized use of copyrighted works to train AI models constitute fair use?

Under all circumstances, for the following reasons.
1. The unauthorized use of copyrighted works to train AI models does not significantly implicate the exclusive rights of copyright owners.
2. It would be practically impossible to train AI models in the first place without being able to use massive sets of data. It would be practically impossible to build a massive data set by seeking permission from each individual copyright holder for each work in the data set. It would also be enormously and impracticably expensive to license all the works necessary for building a massive data set from profit-seeking entities which are tasked with monetizing copyrighted works in a profit-maximizing way.

From this it should be clear that without unauthorized use of copyrighted works, AI models would not have been developed and would simply not exist, at least those that are usable and useful in a general way.


8.4. What quantity of training materials do developers of generative AI models use for training? Does the volume of material used to train an AI model affect the fair use analysis? If so, how?

It has been known for years within AI circles that bigger models (in terms of parameters) trained on more training materials are more capable models (see https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/8/). Thus, to maximize AI models' usefulness, they need, quite simply, all the data. For this reason, it is practically impossible to train state of the art models if the person wanting to train the model has to perform some work or provide payment for every single copyrighted work.


9.1. Should consent of the copyright owner be required for all uses of copyrighted works to train AI models or only commercial uses?

Consent of the copyright owner should not be required to train AI models. From the beginnings of civilization, human artists in training have studied artworks of artists who came before them, and used this training to create new artworks, implicitly derived from the ones that were used for training. No consent was ever needed.


9.3. What legal, technical, or practical obstacles are there to establishing or using such a process? Given the volume of works used in training, is it feasible to get consent in advance from copyright owners?

Since the volume of works is all of them (for state of the art models), it is obviously practically impossible to get consent in advance.


13. What would be the economic impacts of a licensing requirement on the development and adoption of generative AI systems?

Since the development (training) of an AI model in a generative AI system occurs effectively once, and then it can be used by anyone an unlimited number of times (like software in general), the potential economic benefit from using generative AI systems is unlimited in both the amount of value and the number of people that value is created for. Saddling generative AI systems with a licensing requirement would severely curtail the enormous amount of value that could be generated by them and is thus, on the whole, a bad thing.


14. Please describe any other factors you believe are relevant with respect to potential copyright liability for training AI models.

US perspectives on copyright are overly strict and are largely in the service of profit-maximizing behavior that benefits the few at the expense of everyone. The topic of copyright liability for training AI models should very much be viewed from the perspective of maximizing benefit for the greatest amount of people.


15. In order to allow copyright owners to determine whether their works have been used, should developers of AI models be required to collect, retain, and disclose records regarding the materials used to train their models? Should creators of training datasets have a similar obligation?

No such obligation should be required. State of the art models require all of the data to be maximally useful. The burden of record-keeping would thus be vast and unreasonable.


15.3. What obligations, if any, should be placed on developers of AI systems that incorporate models from third parties?

No obligations should be required. The more obligations there are, the more experimentation and innovation is suppressed and discouraged, with obvious negative consequences on generating value through AI systems.


15.4. What would be the cost or other impact of such a recordkeeping system for developers of AI models or systems, creators, consumers, or other relevant parties?

Since state of the art models require all of the data to be maximally useful, both the financial and person-hour cost of record-keeping would be vast and unreasonable. The effect on consumers would in turn be that they are denied useful models, with great negative consequences for value creation.


16. What obligations, if any, should there be to notify copyright owners that their works have been used to train an AI model?

No such obligation should be required. State of the art models require all of the data to be maximally useful. The burden of notification would thus be vast and unreasonable.


18. Under copyright law, are there circumstances when a human using a generative AI system should be considered the “author” of material produced by the system? If so, what factors are relevant to that determination? For example, is selecting what material an AI model is trained on and/or providing an iterative series of text commands or prompts sufficient to claim authorship of the resulting output?

A human should never be considered the author of material produced by a generative AI system, even when the AI model is guided by the human by selecting training material or providing prompts. No one would consider a human an author in such a situation if the entity producing the material were another human instead of an AI model.


20. Is legal protection for AI-generated material desirable as a policy matter? Is legal protection for AI-generated material necessary to encourage development of generative AI technologies and systems? Does existing copyright protection for computer code that operates a generative AI system provide sufficient incentives?

Legal protection for AI-generated material is not desirable because its effect would largely be to concentrate wealth and control in the hands of AI model owners, instead of maximizing value for the largest number of people.

Legal protection for AI-generated material is not necessary to encourage development of generative AI technologies and systems. Such technologies and systems have been developing rapidly without legal protection and show no signs of slowing down; not only proprietary, but also open technologies and systems. Thus, existing copyright protection for computer code that operates a generative AI system clearly does provide sufficient incentives.


21. Does the Copyright Clause in the U.S. Constitution permit copyright protection for AI-generated material? Would such protection “promote the progress of science and useful arts”?  (52) If so, how?

Copyright protection for AI-generated material would do the opposite of promoting the progress of science and useful arts. Science and useful arts have always flourished in conditions of freedom. Indeed, it was the (practical) freedom of being able to use vast amounts of material to train AI models that led to this discussion in the first place. Generally useful AI models would not exist otherwise.


25. If AI-generated material is found to infringe a copyrighted work, who should be directly or secondarily liable—the developer of a generative AI model, the developer of the system incorporating that model, end users of the system, or other parties?

The only person liable should be the person who publishes the infringing material.


25.1. Do “open-source” AI models raise unique considerations with respect to infringement based on their outputs?

No, since the only person liable for infringement should be the person who publishes the infringing material, regardless of how the material is generated.


28. Should the law require AI-generated material to be labeled or otherwise publicly identified as being generated by AI? If so, in what context should the requirement apply and how should it work? 

Yes, for all AI-generated material that is made publicly available. How it should work depends on the nature of the material; watermarking could be appropriate in some cases, metadata in all cases.


28.1. Who should be responsible for identifying a work as AI-generated?

The person who used an AI model to create the work.


28.2. Are there technical or practical barriers to labeling or identification requirements?

I can't think of any that are insurmountable. Metadata can always be placed somewhere.


28.3. If a notification or labeling requirement is adopted, what should be the consequences of the failure to label a particular work or the removal of a label?

Whatever the consequences are, if the lack of such a label caused harm, the consequences should be proportional to that harm. For instance, if an AI-generated work helps to create an insurrection, the person who knowingly omitted or removed the label should serve a lifetime prison sentence.


29. What tools exist or are in development to identify AI-generated material, including by standard-setting bodies? How accurate are these tools? What are their limitations?

Whatever tools of that nature exist, they will inevitably become completely ineffective, since the sophistication of AI models keeps increasing and will inevitably reach a point where AI-generated material is completely indistinguishable from human-generated material.


32. Are there or should there be protections against an AI system generating outputs that imitate the artistic style of a human creator (such as an AI system producing visual works “in the style of” a specific artist)?

There should not be any such protections. Style is a very broad and vague concept and thus can not and should not be protected. The very notion of owning or having rights to a style is ridiculous.