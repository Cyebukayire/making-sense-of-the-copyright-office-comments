Generative AI has a lot of problems. The more obvious is stealing private and copyrighted data to train these machines (something it is illegal and should be punished), then using the data to make convincing material like imitating real people and living artists&#39; works creating an unfair competition of humans vs machines while doing it for profit. I&#39;m worried AI will keep facilitating the replacement of human artistic labor or that it will devalue their work; like it&#39;s happening right now unregulated. People are forced to work more to just survive or in the worst case scenario force to just watch as creative careers disappear and these jobs are replaced by anyone without the knowledge or respect for the career.<br/><br/>Data privacy and copyright are a great issue. It&#39;s incredible how easy it was for AI companies to claim to be non-profit so they could get the training data from the whole internet and then be changed to for profit and releasing this kind of tech to the public without a single worry for the issues it could create on a global scale. I can only describe it as irresponsible and it can not be legal to do and it can not be left unpunished. Even if this software could be possible without stealing data, the mere nature of a machine that generates a lot of convincing content it&#39;s a problem and risk by itself. Problems like misinformation, spam, unfair competitions, fake news, fraud, blackmailing, deep fakes of real people, and more are things to be seriously concerned about and heavily regulate the software and properly identify its creations. A future where AI it&#39;s not regulated, limited or banned by an entity that favors the victims of the data it stole from, it&#39;s a future where creative jobs are no longer an option and it&#39;s also a future where people from all over the world has to doubt anything they see, hear and read because of massive misinformation.<br/><br/>I will begin to describe regulation ideas for this technology. Please consider mine as well as other creatives&#39; opinions, testimonies from victims from these technologies and those from ethics, copyrights and privacy experts.<br/><br/>AI companies should delete their actual models and retrain them only with data that they own or can legally use. This can only be possible by opt-in training data by asking for consent from the authors, giving credit and compensating them via paying for licenses or similar. In contrast, opt-out is not an option for consent, since it can not guarantee that everyone gives explicit permission to use their work and that their copyrights are repsected. The absence of an answer and absence of a &quot;no, I do not consent&quot; it&#39;s not the same as &quot;I consent&quot;. It should be explicit, direct, without a doubt and on a contract to give consent. Again, only possible by deleting their current models of AI and retraining them with opt-in data where authors explicitly give consent, they get credit and paid compensations.<br/><br/>Generative AI technologies in the work field should be limited or banned in work areas by regulations to guarantee fair competition, avoiding the replacement of human labor or unfair layoffs. In the case of allowing these technologies they should be integrated to generate more jobs positions and not replacing and decreasing the current ones. And also it should be avoided to demand more productions from workers once the AI tools facilitate their work; they should not be expected to produce more without earning more money.<br/><br/>All content generated with AI should be correctly and explicitly labeled as AI generated. Big watermarks, unerasable marks or texts, unique file type and other options should be considered and mixed to guarantee that at first sight the generations can be correctly identified as AI generated. Also it should be punishable as fraud to erase these marks and pass the info as real and we should pressure the AI companies to the highest standards so it&#39;s difficult to erase the labels. This should be accompanied with informational campaigns to educate the people on how to identify the generated AI info and to be skeptical about the info it presents.<br/><br/>Regulations against AI should never be within the hands of AI companies. It is not not neutral since they will always look for their favor. If there&#39;s a favor it should be with the victims of data stealing and victims of violations (like artists, creatives or whoever may be affected by these technologies and the stealing of data). The entity responsible for regulations should be the copyright and data privacy offices that apply the law of copyright and privacy rights. Within the conversations and talks of regulations it should be included AI ethics experts like Timnit Gebru and Emili Bender as well as organizations and guilds that advocate for the working people in the creative industry like WGA (Writers Guild of America West), Concept Art Association, Arte es &Eacute;tica from latin america and EGAIR (European Guild for Artificial Intelligence Regulation).<br/><br/>Thank you for reading.