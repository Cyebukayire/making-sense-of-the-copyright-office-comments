As a former AI programmer and current fantasy novelist, the explosion of hype around LLMs and content creation is a strange confluence of my interests.  It&#39;s something I follow closely, though my technical expertise is a bit out of date by now.  In general, I think the AI companies need to be restrained; they&#39;ve taken a &quot;let them sue us&quot; approach to the rights of copyright holders that, if rewarded, risks undermining the basis of the system creatives rely on to make a living.<br/><br/>First and most importantly, the vast datasets used for training LLMs are an open abuse of copyright.  The resulting model contains (albeit in a very lossy way) all the works used to train it -- easily shown by entering a sufficiently popular work (for example, &quot;Mona Lisa&quot;) into an LLM image generator, which returns a good approximation of the original.  I don&#39;t pretend to be a copyright law expert, but it seems clear that changing the format of something (for example, scanning an image) is not a license for infringement, even if the new format can&#39;t precisely recreate the original.  (JPEG compression, for example, is &quot;lossy&quot;, so a PNG converted into a JPG cannot be converted back into an identical PNG; but the JPG is still the &quot;same&quot; image as the PNG.)<br/><br/>The result is a piece of software that clearly has economic value, created from the bits and pieces of the works that make it up.  We cannot be deceived by scale alone.  A &quot;model&quot; trained on a single book, answering all queries with quotes from that book, would presumably be infringing; the fact that the model includes tens of millions of books should not be a free pass.  There is nothing IN the model except its training data.<br/><br/>The AI companies cannot be given a pass simply because contacting and obtaining permission from rights holders would be time-consuming and difficult, either.  Their infringement does not become less damaging just because they&#39;ve already done it and it was expensive; any output from the current set of models is tainted by the illicitly acquired inputs.  There is a vast amount of data available to use free and clear (in my own AI work, for example, among others we used the &quot;Enron corpus&quot;, entered into the public record during the trial) and a great deal more that could be acquired in a straightforward way.  (For example, stock image providers control rights to huge numbers of images.)  Complaints that recreating models without sweeping up everything on the internet amount to saying that distinguishing between copyrighted and non-copyrighted material is too expensive and time-consuming; it&#39;s hard to imagine the same argument succeeding from, say, the owner of a free music download site.  Model developers must be made to acquire permission for copyrighted work on an opt-in basis, and openly post the list of works that were used in the creation of the model.<br/><br/>As to whether the outputs of an LLM can be copyrighted, I have less applicable knowledge.  I will say it doesn&#39;t seem like the act of sorting through many potential outputs and choosing one is an act of creation of the kind that is normally rewarded by copyright.  If I had access to the proverbial infinite monkeys with typewriters, and scanned their output until I found a chunk more-or-less identical to a popular novel, it seems wrong that either I or the monkeys could claim the result as our own work.<br/><br/>In a larger sense, the purpose of copyright has always been to reward the creative acts that enrich our culture generally and allow individual creatives to earn a living.  In many cases this is an egalitarian, decentralizing goal -- the copyright of a novice painting their first picture is just as valid as that of a big corporation.  LLMs, improperly regulated, have the potential to profoundly reverse that goal.  By their very nature they are extremely centralizing, requiring so much computing power and storage to create that only the largest and wealthiest entities can hope to build one.  If ownership of an LLM becomes a license to infringe the rights of creators, a tremendous amount of artistic and cultural power will fall into the hands of a tiny group of unaccountable entities.  In order to avoid this, the owners of these models must abide by the same rules as everyone else, and negotiate and pay appropriately for the work that they require to build their businesses.<br/><br/>Thank you for your time.