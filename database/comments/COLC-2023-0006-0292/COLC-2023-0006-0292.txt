AI-created material poses a grave threat to human artistry and the entire landscape of creative work. Large language models threaten to create a storm of disinformation that floods our communication channels and ruins accessibility of accurate information online. Image production models are strip-mining art on the  internet and seriously threatening livelihoods for the artists. Video models are already enabling non-consensual pornography and deepfakes. In the best case, with the abuse cases reined in, large language models are feeding on centuries of artistic output, savaging the creators responsible, and sowing a landscape where human-created art is hard to find and the models have destroyed their own training sets going forward.<br/><br/>From a copyright perspective, there are two core reforms that must be implemented. One is a strict clarification that AI-generated content cannot be eligible for copyright protection - indeed, any work in which AI tools contributed in any substantial way to its production. If companies cannot hold copyright in their AI-created works, and therefore cannot control how those works are reused and redistributed, it will do an enormous amount to help preserve the careers of the creators being threatened. The copyright office has already made one ruling in this direction, but more is needed.<br/><br/>Second, a categorical ruling is required that inclusion of a work in an AI&#39;s training dataset is not a fair use. By a traditional four-factor analysis, every *individual* work in a training dataset is a relatively small component of the resulting output. But these works are being used in their entirety, were never intended to be used in this fashion, and LLMs are already creating a commercial catastrophe for the works they are trained on. We have already seen book publishers resorting to AI instead of cover artists, film studios claiming the right to use AI to replicate actors&#39; voices and appearances, and factual news being outcompeted by massive quantities of AI-written mostly-accurate dreck. Forbidding AI companies from including copyrighted works in their training data is a drastic step - but it is necessary to protect creators. AI companies will claim that this is tantamount to criminalizing their business models, but the truth is that those models are themselves criminal. And AI companies will still have a wealth of data available - public domain works, privately-purchased or generated datasets, and works with an affirmative license consenting to inclusion in a training dataset. But the presumption that any text or images on the internet are fair fodder for training LLMs is wrong, it is disrespectful, and it is destructive. Creators, commercially, must be present on the internet; saying that AI can hoover up their works is mandating that artists be complicit in their own destruction.<br/><br/>We have already seen, over the past months and years, that AI companies are fundamentally bad-faith actors here. They are producing harmful models, taking a wrecking ball to the creators they are ultimately dependent on. Much innovation is possible thanks to LLMs, but an industry that insists on self-regulation is one that intends to perform a slash-and-burn operation to the existing landscape of creative works. Artists and creators must be protected, or tomorrow&#39;s world will be one with a dearth of creativity and a wholesale demolition of the creator class.