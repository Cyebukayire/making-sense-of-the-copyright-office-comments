Works created wholly by or with the assistance of AI generation or other artificial intelligence tools should be labeled as such, or works should be mandated to disclose that they were created in this manner. Artistic works that are created with the use of artificial tools differ from traditional methods particularly in terms of effort, resources, and level of skill required, so when such artwork is marketed, it would be compared unfairly to other works. <br/>In terms of AI artwork, learning models that take aspects of existing art exist in nebulous area of copyright law and it is unfair to the artists whose art is the basis of AI generated works that others can freely use their creations through the &quot;loophole&quot; of AI collage. If art that is generated in this way, which reuses or plagiarises the work of other artists, the producer must be required to disclose this fact, or otherwise the AI generation models must be required to add a watermark or other indicator to all output that they are created with AI. Sound and musical recordings fall into this same category because they may include elements of copyrighted material or material that does not belong to the individual using an AI tool to generate the work, and so any works made in this way must include clear indication that AI tools were used, or the generator must include an indicator or audio cue that AI generation was used. This will inform record labels or other publishers that copyrighted material may not be properly attributed so they can make more informed decisions.<br/>In terms of scholarly writing and journalism, AI is a tool that will doubtless remove many hurdles of writers by providing a template or framework to write from. Because the facts or opinions provided by AI generation cannot be confirmed, verified, or wholly trusted, the audience reading these writings have an important, vested interest in knowing whether AI was used. In such cases the AI generator must be cited, or else the generator must be mandated to append a note, footnote, or other indicator that AI was utilized in writing the text. Because of concerns regarding the veracity of facts pulled from AI generation, this should provide a barrier to dissuade academics or journalists from using the technology. It is not professional to rely on a tool to automatically generate textual content when the job of an author or writer is to generate that content on their own. Until greater regulation or uniformity can be applied to available and forthcoming AI generation tools, their output should not be trusted or placed in front of an audience that expects to have accurate factual representation of events, figures, ideas, and so on. Failing to put in place any form of disclosure or protecion for the audience is a threat to academic and journalistic integrity to place trust in research or findings that are not verified by a trusted individual and instead generated by an algorithm.