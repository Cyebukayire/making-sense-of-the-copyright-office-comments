If an artist finds out that their copyrighted art has been stolen and used for product packaging or an ad campaign or put on a t shirt, they&#39;re able to (when the process works as it should) get it taken down at the bare minimum. &quot;Artificial Intelligence&quot; programs producing visual and/or written media, which have their source databases far less publicly recognizable than traditional copyright infringement, should be subject to the same rules as anything else. It&#39;s incredibly difficult already to find out if your work has been fed to one. It isn&#39;t enough to protect your work from your side, or to trust the groups behind these programs when they state where they do and do not source material from (though most refuse to disclose that information in the first place). If your work is fed to a system by an individual, it continues to be used as part of the database of the program. And it can be all but impossible to prove that, unlike what can be done to locate and prove traditional infringement. It&#39;s likewise all but impossible to reliably and accurately prove that something has been created by such a program, because every tell is quickly eliminated as the program is refined. Not only do we need protections which prevent companies behind AI programs from training using copyrighted work selected by the developers, we also need protections against users introducing such material into the database. Unlike other novel forms of infringement and plagiarism that came with the internet, it&#39;s difficult to find out that your work has been used for by an AI, because the database isn&#39;t public. It&#39;s not like video sites like Youtube, where even before algorithms designed to detect copyright infringement were developed it was easy for a rights holder to point to a specific video and show that the contents belong to them. 