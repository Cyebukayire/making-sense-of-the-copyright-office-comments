6.4 I can&rsquo;t answer that, but as I firmly believe that training AI on copyrighted works is an infringement on authors/creators, I think that requiring AI programs to document their training datasets is essential as this technology continues to evolve. Otherwise, how can creators protect their work&mdash;what recourse do they have to defend their art?<br/>9 Copyright holders should have to opt in to allowing their work to be used to train AI. Doing otherwise places an onerous burden on creators/artists (many of whom are already burdened by strained economic circumstances), and would go against existing protocol for the use of copyrighted works, where the creator&rsquo;s permission is required if fair use does not apply. <br/>15 AI developers absolutely must keep a complete and detailed record of their training datasets. Academics are required to cite their sources in publications; so too should AI developers be, but by law. The temptation to do otherwise and so skirt the responsibility for copyright permissions is too great otherwise. <br/>15.2 Disclosures should be made to the copyright holder as well as their publisher or equivalent (if applicable)<br/>16 Copyright holders should be universally informed if their works have been used to train AI, so that they have the information necessary to choose how to proceed legally and artistically. <br/>18 I&rsquo;m a PhD candidate and assistant lecturer at my university, and there are many reasons I tell my students not to use AI to do their homework. The most important one is that a machine can&rsquo;t think. LLMs are not truly &ldquo;artificially intelligent&rdquo;; they&rsquo;re predictive text generators on steroids. As such, nothing they produce is truly creative or critical, but rather an often erroneous summary of what it has scraped from its training datasets. They author nothing, and should not be recognized as authoring anything, even if a user selects their training dataset and hones the response with different prompts. Telling a computer what to read and what to do with what it reads is not a creative or critical act: it does not involve any sustained, engaged thinking or reasoning, and this is evident in what the LLMs produce. <br/>20 Why are you asking if it&rsquo;s desirable to offer legal protections for AI-produced work instead of questioning whether or not AI-produced work is itself desirable? Even those who have pioneered this technology worry that it will be the doom of the human race (https://www.rollingstone.com/culture/culture-features/women-warnings-ai-danger-risk-before-chatgpt-1234804367/); but before it gets to the point of posing an existence-level threat, it poses another threat&mdash;the desiccation of the human spirit and human ingenuity. If we outsource our thinking and our creativity to machines, Homo sapiens sapiens loses what has distinguished it from other nonhuman animals for tens of thousands of years: our wisdom, debatable though such &ldquo;wisdom&rdquo; often is. Offering protections to this technology does not help society, and in fact could harm it by encouraging its use and hastening our decline. <br/>25. The developer of the generative AI model. 