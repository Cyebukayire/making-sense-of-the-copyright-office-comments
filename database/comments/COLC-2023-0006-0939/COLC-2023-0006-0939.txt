The content that makes up an ML/AI system&#39;s dataset, how it was collected and then trained matters. If a system, such as OpenAI &#39;s Dalle-2 or Midjourney use images stolen off the Internet without consent or compensation for their image generators? Then everything that comes out of that system are, by default, plagarisms. The same goes for the text content collected for systems such as ChatGPT. The bottom line is that this is wholesale theft for the sole purpose of putting the people whose works were stolen out of business.<br/><br/>An ML/AI system don&#39;t have a soul, subjective memories or feelings. They are algorithms, incapable of making leaps of faith or creating genuinely new works on their own. They require human direction to tell them what is good, what is bad. And, even then, those concepts aren&#39;t fully understood. They are simply two opposite directions to move the scores. That is it. <br/><br/>Giant corporations stealing people&#39;s work for their own commercial gain does not, by any stretch of the imagination, constitute &quot;fair use&quot;. If a company wants to use my photographs to create something, they need to ask my permission. They need to compensate me every time my image is used to create a derivative work. Nothing else is acceptable.<br/><br/>