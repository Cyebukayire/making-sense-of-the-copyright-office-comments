There is one very important detail people do not seem to realize: machine learning Models **does not** store information about data used for training. Neural Networks are trained to respond to certain words with patterns, which are stored as numbers. Those numbers do not represent binary data, which can be used to reconstruct the original image the Stable Diffusion Model was trained on. The training data **is lost**. Words (tokens) trigger Neural Networks to respond with learned patterns to create a completely new image, which will **resemble** the image the Model was trained on.<br/><br/>The reason why I say &quot;resemble&quot; is that Stable Diffusion Models do not store the training data (images) and they are not able to completely reconstruct them from this process. Neural Networks can be trained to recognize what the images represent, but due to the nature of those networks (Randomness), they are not able to create the same exact image from the training data. This is the same exact reason why a Human can not reconstruct a photography or a painting in its entirety. We learn by studying and analyzing. Neural Networks learn from analyzing and associating words with certain patterns on the given image.<br/><br/>Refferring to the most overused example: &quot;The Starry Night&quot; by Vinvent Van Gogh. It is obvious that Models can reconstruct the image in some way, but it is not an exact copy. This is a representation of a scene __in style__ of Van Gogh containing objects it was given to train from. This is exactly how a Human would learn a style. He looks at a painting, studies the patterns, can recognize what is on the given painting, can learn from it, then in the result of this process, he is able to recreate a painting based on what he learned, but that painting will not be an exact copy. He __looked__ (this word is important) at the painting and analyzed it and from the gained knowledge of analysis, he can create multiple paintings in the style that painting was created in.<br/><br/>At this point, the argument of &quot;where did the art come from&quot; is absolutely irrelevant, as the painting is available publicly for everyone to see and this is exactly why the copyright infringement argument will always be irrelevant in this and any future case, because &quot;style&quot; is not something, that is a subject for copyright. Style is an idea, the copyright law does not protect ideas, but __finished works__. Stable Diffusion Models do not copy any artist&#39;s work, it is learning from the presented images, which is what nobody seems to understand.<br/><br/>Fortunately, images created Artificial Intelligence can still be protected by copyright laws if enough Human Authorship is involved, which is only available to those, who incorporate lots of human hand guidance in their artworks - this process is called Inpainting. Just check any &quot;Stable Diffusion Inpainting Timelapse&quot; videos to see how AI artworks are created manually, how much work, creativity and originality can be put into single artwork, which is not as simple as &quot;putting words into boxes&quot; as many outraged people think it is.<br/><br/>Embrace the A.I.