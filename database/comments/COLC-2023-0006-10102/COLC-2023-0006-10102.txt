I have read through a lot of the points that the major tech companies like have made in favor of their companies being able to use copyrighted images for their training data at no cost and a lot of their usual points don&#39;t add up in my opinion. For example, the phrase &quot;Generative AI is just the democratization of Art&quot; is sketchy at best. If that was really the case, Meta, Google, and OpenAi should have asked the creators and artists they have scraped data from if they were even willing to let their work be used for the purpose of training said models. In short, where is the democratic process when there is no consent? <br/><br/>There is also the reluctance of major AI companies to disclose the data they trained their models on. We already know in the early days of this tech that their models recreated images with clear watermarks from companies like Getty, or even mangled versions of artists&#39; signatures. That goes to show that of course the datasets have been trained with multitudes of data that they didn&#39;t buy the rights for and were wholesale pirated. That leads me to believe that the fact that they want to continue to keep their training data private means that it should be revealed and scrutinized more than ever. The Burden should be on the billion-dollar company to be open and forthcoming, not the millions of individual creators they scraped data from. <br/><br/>There is also the claim of &quot;fair use&quot; being made by a lot of these companies. Is it fair that large multi-billion dollar companies are allowed to use AI models trained on billions of data points created by working-class artists to actively compete with those same artists in their respective industries? We have already seen jobs being lost to AI in the conceptual design fields of film and television, and spot illustration for magazines and books. In the ethical sense that is in no way &quot;fair use&quot;. <br/><br/>It has also been laughably argued that tech companies would no longer profit if they had to pay for the copyrighted material if they had to pay for the same data that makes their tech work. If they are able to make billions of dollars off that training data, why shouldn&#39;t the creators of that same important data not stand to profit from it as well? <br/><br/>I wish I had the time and resources to respond to every specious argument, but sadly I do not. But as a creative, I will end by saying this. I hope the fine people at the Copyright Office can see through all the double speak and propaganda that big tech is throwing out there in order to have others turn a blind eye to a real issue. Instead of their tech potentially being &quot;A world-ending problem&quot;  down the road, it actually is causing a lot of harm now. These companies should not get away with not asking CONSENT to use other people&#39;s data in order to compete in their spaces. AI companies should be willing to COMPENSATE people for the data they find so valuable. After all, without it all, their tech would not even be possible. Lastly, AI companies should also open up their data set so that all the unwilling contributors can be CREDITED for their work. <br/><br/>I will end this comment by including a link to excerpts of Karla Ortiz&#39;s testimony she gave to Congress a few months back. She has so eloquently put into words the plight that creators have dealt with since the onset of this new interaction of Geneterive AI. https://www.linkedin.com/posts/karla-ortiz-385a2314_senate-judiciary-committee-holds-hearing-activity-7085105297949667328-Dp4L/?trk=public_profile_like_view<br/><br/>Thank you for your time, <br/><br/>