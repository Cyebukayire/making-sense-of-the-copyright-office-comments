Hello, I work at a university in Texas and have been interested in scholarly publishing for quite some time. While some aspects of AI can help (grammar, etc), other aspects have been upending how we as academics are able to do our work. I&#39;m genuinely concerned about how the data is being managed, which none of the corporations who &quot;own&quot; this technology are able to discuss. IBm and others say they have ethics boards, but what happens when someone like Musk takes over an AI company, and fires the ethics boards? Who&#39;s going to be the watchdogs for this? <br/><br/>Further, adding these &quot;tools&quot; to things like Word and Google Docs, all so that GDocs and Word can mine me for more data without paying me is ridiculous. It is my thoughts, my words, going into these tools. Why are we not seeing any of the benefit. When it comes to scholarly publishing in particular, I can understand how some of these tools help people who are neurodivergent or whose second language is English (or whatever language they need to write the paper in). However, there are bigger issues at play here. Our data is not our own. We should be modeling our technology laws after what Europe is doing-- but we can&#39;t seem to get out of our own ways about it because the capitalist will always win here. <br/><br/>Additionally, the technology is being abused. We have already had issues with deep fakes and viral bullshit. We can&#39;t even get social media right-- see Facebook and the massacres that have occurred because the &quot;algorithms&quot; were feeding people massive amounts of misinformation, also Twitter/X with Elon Musk and his anti-Semitic comments and platforming of white nationalists. I suggest whoever reads this comment at the Copyright Office take some time and read the following books: &quot;Artificial Unintelligence&quot; and &quot;Algorithms of Oppression.&quot;  <br/><br/>Back to scholarly publishing-- It&#39;s already bad enough with the &quot;big 5&quot; publishers making money off of the scholars whose work they publish, and with the Nelson memo, forcing people to publish in open access places when they might not be able to for reasons is going to exacerbate the problems when it comes to scholarly publishing. People have to find places to put their work, the publishers will not have open access unless we as authors pay them (APCs) and then we still can&#39;t get it published because those APCs are ridiciulous amounts of money (upwards of $5,000 sometimes). No one has that kind of money, and most insitutitions are unable to pay it. What happens next is that people will start looking for cheaper options-- AI could be making lots of fake new journals, stealing people&#39;s money because they have to make things open access, and those people are now victims to predatory publishers.<br/><br/>I&#39;ve also seen an uptick in articles that are being written with the &quot;help&quot; of AI models-- words and paragraphs taken directly from the machine and people trying to pass it off as their own work. I know that this will only get worse. As well as having issues with student work.<br/><br/>Please consider these aspects when forming policies (and maybe laws) regarding the use of this technology.  <br/><br/>Thank you. <br/>~Erin