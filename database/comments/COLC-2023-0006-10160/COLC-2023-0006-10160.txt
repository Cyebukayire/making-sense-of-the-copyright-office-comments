I am the daughter of an artist and I am an artist myself. As an artist who follows the development of AI and who has used this technology, I want to offer my understanding based on personal experience and my observations of AI development. <br/><br/>On the question of human authorship, this depends on the complexity of the prompt and the AI&rsquo;s ability to adhere to the prompt. So, this can only be determined on a case by case basis. In one case, the prompt written by the human could simply be, &ldquo;blue seagull&rdquo;. There will be several elements in the image result that were not specified by the human and fully generated by the AI, including the background, the style of the image, and so on. However, if the majority of the elements of a resulting image were described in detail (sky blue seagull perched atop a forest green metal bench with wings outstretched, etc - this is a quick example&hellip;it could be described in greater detail) and, if the AI was able to adhere to this human instruction, then it would make sense for the human to be considered the author for copyright purposes, depending on the level of detail in prompting required for human authorship. There might need to be prompting requirements/standards for copyright purposes.<br/><br/>Most current AI art generators are not able to adhere to prompts with such precision, but this is expected to change within the next few years. Currently, DALL-E 3 is skilled at adhering to prompts and I expect the ability to increase, so that eventually a human could describe their idea in great detail and receive an image as imagined (and through making adjustments, such as the &ldquo;zoom&rdquo; and &ldquo;vary&rdquo; features on Midjourney, which involve direction from the human). <br/><br/>To see the difference in prompt adherence, try inputting a complex prompt into earlier versions of Midjourney (v1) vs later versions (v 5.2) vs DALL-E 3. You will see that the ability for prompt adherence has increased significantly since 2022. If there was this level of improvement from 2022 to 2023, then try to imagine the state of AI art in 2025 or 2030. The rate that the technology is improving needs to be taken into consideration so that regulation doesn&rsquo;t become outdated only a year after its implementation.<span style='padding-left: 30px'></span><br/><br/>On the question of training data, I support using publicly available art in AI training. Contrary to the notion of it being akin to theft, AI systems do not produce exact replicas of the input but rather learn and generate outputs similar to human learning. To test this, input the name and artist for a specific work into Midjourney. Midjourney will not produce a copy of the image, but will only produce transformative works inspired by the original image.<br/><br/>All of the output from the AI is transformative. At most, style or painting techniques can be replicated, but this ability is not unique to AI. Plenty of human artists mimic the styles or painting techniques of other artists. If there&rsquo;s an attempt to overregulate in terms of style or technique, that would NOT ONLY negatively affect AI, but could ALSO negatively impact human artists, especially smaller artists. When more powerful artists and companies could then attempt to claim general elements such as styles or techniques, this form of regulation might benefit the few, the powerful, and the wealthy as they are more equipped to take legal action. Less powerful artists could struggle if such a system became misused. The effects of this form of regulation must be examined for their potential impact on human artists. <br/><br/>Besides, AI companies are now moving toward developing synthetic data for AI training. Synthetic data presents several advantages. <br/><br/>Here are some quotes from IBM research&rsquo;s article on synthetic data, &ldquo;What is Synthetic Data? (February 7, 2023)&rdquo;:<br/><br/>&ldquo;Synthetic data is information that&#39;s been generated on a computer to augment or replace real data to improve AI models, protect sensitive data, and mitigate bias.&rdquo;<br/><br/>&ldquo;One of synthetic data&rsquo;s key advantages is that it comes pre-labeled. Gathering real data and annotating it by hand is time-consuming, expensive, and often humanly impossible.&rdquo;<br/><br/>&ldquo;Training a billion-parameter foundation model takes time and money. Replacing even a fraction of real-world training data with synthetic data can make it faster and cheaper to train and deploy AI models of all sizes.&rdquo;<br/><br/>I quoted from this article because of the concise and understandable explanation, but there have been countless research papers and articles published on synthetic data this year.<br/><br/>There&rsquo;s no point in wasting time attempting to regulate AI art data, when the method of training favored by companies will change within the next few years.<br/><br/>We need to consider the pace of development (prompt adherence), as well as new developments (synthetic data), and the impact that regulation could have upon human artists (making sure that the copyright system remains fair and benefits the population as a whole).<br/>