To the US Copyright Office: <br/>My name is Ameorry Luo. I&#39;m an artist in the video game industry in LA. I submitted a comment to the initial request for public opinion on this topic, &amp; I&#39;m here again to respond to some of those given by several AI tech companies.<br/><br/>The trade group TechNet, which serves the interests of Apple, Google, Meta, etc. claimed that the idea of properly crediting &amp; compensating the creators of the copyrighted works they&#39;ve used to train their AI models would be impossible because the number used is in the billions--essentially, that they can&#39;t possibly keep track of each piece, &amp; therefore shouldn&#39;t be held responsible for properly licensing it. This is a laughable &amp; insulting argument. If a robber stole a billion dollars cash, could they make the argument that they shouldn&#39;t have to return it because they couldn&#39;t keep track of where each bill went? Of course not. To claim that being forced to do so is impractical &amp; would &quot;unduly burden&quot; developers is ridiculous. &#39;Publicly accessible&#39; does not &amp; has never meant &#39;legally free to take &amp; use for one&#39;s own profit&#39;-- recording movies in a theater on a video camera is just one obvious example that comes to mind. <br/><br/>TechNet also claims that generative AI is no different than previous technological developments that affect the field of art, such as the camera. This is false. Photography is a medium, completely different from something like painting. A photo of a treasured memory &amp; a painting of the same are two pieces of art that both hold distinct, intrinsic value. Cameras are a marvel of mechanical &amp; optic lens technology, &amp; crucially, do not involve the wholesale, direct theft of the work of other artists. <br/><br/>I call what these companies have done to obtain their training data theft, because that&#39;s what it is. In a particularly astounding argument, Google says that &#39;most LLMs are trained on a wide variety of publicly available data&#39;-- implying that due to this fact, their taking &amp; profiting off of it should not be counted as copyright infringement against their rightful creators and owners. However, in the very same paragraph, they say that &#39;a disclosure [of the datasets they have trained on] requirement would be unsound policy...[because it would] expose competitively sensitive (&amp; potentially trade-secret-protected) information. They&#39;re blatantly stating that a significant portion of what brings value and power to the technology they&#39;ve created lies in the data that they&#39;ve trained it on, i.e. the data they&#39;ve taken from artists, &amp; yet they shouldn&#39;t be held responsible for disclosing that data, crediting or compensating those artists, OR reckoning with the fact that this tech will directly compete with &amp; likely displace the livelihoods of those artists (another factor that Google has willingly acknowledged). They can&#39;t have it both ways. Either our work provided the AI value and you compensate us for it, or you can&#39;t profit off it. It&#39;s that simple. <br/><br/>Another argument these developers make in trying to justify data scraping as fair use is that it&#39;s the same as a human being inspired or influenced by another artist. This too is untrue. When I make art, no one is feeding me the entirety of art history for me to reference, all with equal weight. I get inspiration through my experiences as a human being-- the people &amp; things I love, memories I cherish or even hate. It&#39;s about conveying emotions, telling a story, expressing the things that matter most to me. An AI model, by definition, can&#39;t do this. It hasn&#39;t lived or felt, it has no opinions, no relationships, no passion. It &#39;learns&#39; by clinically identifying patterns &amp; correlations across vast swathes of data in perfect analysis, &amp; &#39;creates&#39; by regurgitating a generalization derived from it. That data was deliberately placed there by the developers, who took it wholesale from its creators. In no world is that &#39;inspiration&#39;.<br/><br/>The last thing I&#39;d like to respond to is TechNet&#39;s suggestion that imposing regulations on AI will create a huge economic problem considering the billions of dollars of investment that have been poured into its development--&amp; that that in turn would make the US fall behind in competition against foreign adversaries. To this I can only say: what, so because our enemies might play dirty, we should abandon all attempts at doing things the right way? That we should join them in cutting corners, to barrel headfirst into a future rampant with AI-generated disinformation, art &amp; entertainment monopolized by huge companies only seeking to increase their profits, all while making it so that our own citizens can&#39;t even feel safe posting a photo or their art online for fear that a machine might sweep it into a database &amp; use it for profit?<br/><br/>That&#39;s incredibly nihilistic, &amp; it&#39;s not the future I want to live in.<br/><br/>I hope you&#39;ll take these thoughts into consideration as you move forward on this issue. Thank you for reading.<br/>