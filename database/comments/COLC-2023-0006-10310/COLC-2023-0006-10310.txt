On Microsoft&rsquo;s point A. Q.8, &laquo; AI models are Transformative Uses &raquo;, AI models are actually not transformative and don&rsquo;t abide by fair use policies. AI models do not learn and express themselves as humans do, and can only work by copying images from databases. Ai models strive to &ldquo;recreate&rdquo; the images as accurately as possible, and can only do so with the noise of the original images &ndash; the images present in the databases. (https://encord.com/blog/diffusion-models/#:~:text=During%20forward%20diffusion%2C%20the%20model,desired%20complex%20data%20points%20distribution)  (Nicholas Carlini et. Al; https://arxiv.org/abs/2301.13188)  This means AI models cannot adapt or be &ldquo;transformative&rdquo; uses, as the models themselves don&rsquo;t actually change the image data, like painting over an image and changing it using human creativity, because it still uses the original image itself (the noise) by deconstructing it and attempting to reconstruct it. It tries to &ldquo;replicate&rdquo; as well as possible, but not as a human. Furthermore, there are many cases in which the original image can be recognized, especially if a more famous artwork is used, whether the image belongs in the public domain or is copyrightable, meaning that it just spits out as an output as closely as it can to the original images used. (https://www.researchgate.net/publication/371222697_Wuerstchen_Efficient_Pretraining_of_Text-to-Image_Models) <br/>Additionally, Ai models are essentially huge compression models, meaning that they indeed have all the stolen data stored by the models. (https://arstechnica.com/information-technology/2023/09/ai-language-models-can-exceed-png-and-flac-in-lossless-compression-says-study/) <br/>Nevertheless, this point takes away the focus on these models doing mass copyright infringement and tries to compare them to humans, when they really are not the same, and don&rsquo;t function the same. (Jenelle Feather, Guillaume Leclerc, Aleksander Madry, Josh H. McDermott; https://www.nature.com/articles/s41593-023-01442-0) <br/>At Point C. Q9 &ldquo;License and Consent Requirements would Limit Competition and Inhibit<br/>Technological Progress&rdquo; tries to imply that asking for permission to use copyrightable data would slow down their technology. Taking without consent is plagiarism, which is inexcusable, and results in copyright infringement.<br/>On Point A. Q 18 &ldquo;Copyright Protection Should Extend to Creators Using AI&rdquo;, there is nothing that AI models create from exploitation of artists. It only spits out what it has in its database, including &ldquo;mixes&rdquo; of images, which (the database) was made unethically and maliciously.<br/><br/>Very often, Ai programs made exploitation of people in general much more accessible &ndash; with the theft of artists&rsquo; work and the identities of people whose faces appear online. (https://www.404media.co/andreessen-horowitz-invests-in-civitai-key-platform-for-deepfake-porn/) <br/>The issues stated about AI in these particular points are a fraction of the amount of problems these pieces of software have produced over the course of just one year, and the damages created by companies like Microsoft, Midjourney, Stability AI, and generative AI companies relying on image and video data are very many: Attacking artists; threatening to steal their work; planning DDos attacks against sites that protect artists from their images being stolen and used in image generation without consent. <br/>These companies imply they do not want to ask for consent to use copyrighted data, and discreetly want to continue on exploiting artists and people whose data has been stolen in the first place.<br/>