Thank you for looking into better legal protections surrounding AI and accepting public comment.<br/><br/>I am commenting as a performer, writer, video editor, and private citizen. As a member of SAG-AFTRA, I do not feel that the new contract that was ratified last night provides enough AI protections for performers and am seeking legal policy changes for better protections that would supersede the contract language.<br/><br/>2. Unique issues in the entertainment industry deal with scans to produce digital replicas of talent to replace the need for human actors, as well as ingesting past and future footage to train generative AI models to create synthetic characters without knowledge, consent, or compensation to the human performers. While name and likeness may not be generally protected by copyright law, there is a unique intersection of rights of publicity and copyright when it comes to AI and GAI output as a performer&#39;s image, voice, and style are their unique means of commerce in this industry; therefore, use of NIL for any AI use could come at a significant cost to the performer who is not given say in how their NIL is used in replication or character generation. It also raises the question on, if performers own no copyright to their likeness, who owns the copyright to their digital replicas? I believe, as defined in the current contract, that copyright would go to the employer, when it more closely resembles work created by an artist and rights should be retained by the performer.<br/><br/>5. Yes, new legislation is warranted. As mentioned above, there is an overlap in legal areas when it comes to image and likeness being used in conjunction with AI. This issue is not solely related to actors but even private citizens whose likeness can be scraped from online forums, such as personal photos and videos on social media. Whether someone falls into the category of &quot;influencer,&quot; every person of the general public is creating content every time they post to social media, and legislation needs to cover protections of NIL and content from misuse and abuse, including AI creation and training.<br/><br/>6. As it pertains to training AI models: After following the negotiations surrounding the new SAG contracts, it is my understanding that the self-tapes garnered by employers may be used to train generative AI models without consent of or compensation to the performer. In a modern, more virtually-connected world, it has become the norm and expectation that actors submit self-tapes, that is an audio or video audition that the actor records at home with a reader and uploads/sends to casting, rather than an in-person audition. If performance and personal attributes are not protected under copyright law, perhaps the creation of these self-tapes could be, and therefore, would be subject to any new legal considerations as it pertains to tracking work used in AI training and creation, requiring consent of creators for use of copyrighted work, and compensating creators of said work.<br/><br/>9. Copyright owners should be notified and have to give consent (opt in) to use their works for training materials. An opt out option is a too little, too late approach that puts little burden and responsibility on the AI user and should the artist object to the usage of their work to train the model, it would be impossible to remove their work from an already trained AI.<br/><br/>10. A proposed solution to obtaining licensing and tracking usage of copyrighted work would be to use blockchain. This creates a verifiable opt in strategy that can be tracked for consent and compensation purposes. In the instance of a performer, their scan to be used to create a digital replica, would be created for the blockchain and owned by the performer and able to be licensed out on a production by production basis.<br/><br/>12. In the case of performers, no it is not feasible to identify the degree to which an actor&#39;s image and likeness contributes to a particular output from a generative AI system. Yet that is the only basis for protection against training AI models in the new SAG contract language--if you can prove from an output that your specific body part (eye, nose, lips, etc.) AND name were used in the prompt to generate the synthetic character, then you may qualify for compensation or punitive damages. However, this clause mainly protects A-list celebrities and not the majority of the labor union who likely wouldn&#39;t be able to significantly prove similarities in likeness and whose names wouldn&#39;t be used in generation (even though footage would be used for inputs and training). Which is why there must be consent and compensation on the front end rather than after the fact.<br/><br/>The new SAG contract allows for producers to require actor consent to get scanned or not get the job, effectively creating a scenario where a performer&#39;s loss of bodily autonomy and identity is now a condition of employment. See attached for another SAG member&#39;s notes on the contract where more legal protections are needed.