While many people consider machine learning tools to be &quot;plagiarism software&quot; that was &quot;unethically trained&quot; without artists&#39; consent, it should be considered how much of the original work is actually being copied. ML models take a &quot;fingerprint&quot; of a work, not the entire work. Multiple terabytes of data are often used to produce a several-gigabyte stable diffusion model, for instance. This results in an average storage of one tenth of one percent of the original work. Surely if I were to use a thousandth of a famous painting in another medium, it would not pass the test for the amount of a copyrighted work being used to qualify as infringement.<br/>What we chiefly need is a way to determine whether a programmatically-generated work is likely to have been produced to be too similar to other