The use of Artificial Intelligence in all fields must be regulated, labeled, and fiercely checked, reviewed, and moderated. We live in an exciting age, to see the emergence of a technology that can help in so many places when applied correctly - bridging the gap on rewording educational content into easier to understand wording, active translation between languages to ease the burden of communication, helping illustrate concepts with ease - these are the mere basics of what such a technology is starting to assist with.<br/><br/>However, this comes at too great a cost. Many of these projects were developed on the basis of images, text, art - without the appropriate permissions of the artists, let alone the residuals of the artworks produced using the technologies. The usage of these tools has further withdrawn value from the market - with artists being dismissed in lieu of the &quot;savings&quot; of machine generated derivative artworks, only further benefiting shareholders at the top, who have gorged themselves on the excess of their fountains of wealth, but will never feel satiated in their attempt to understand the concept of having &quot;enough&quot;. <br/><br/>As an artist myself, I&#39;ve released my works under Creative Commons, some with a license for Commercial usage, some with a Non-Commercial license. To understand that tools utilizing Artificial Intelligence are using my labor - the result of my training, my equipment, my skills, and my time - could be used not by single individuals or small firms, but larger corporate entities in order to train their tools and output something that would otherwise highlight or compensate me for my work, and that they are seeking to copyright the result is preposterous. These tools require regulation. The unregulated use of Artificial Intelligence chokes small business and ensures that the output of ALL types of work suffers, leading to the inevitable collapse of entire industries. It starts with art - VFX workers, graphic designers, writers, cinema, photographers, etc. It moves through the chain. News sites have laid off journalists, and the quality of journalism and reporting has dropped drastically. Websites have begun to spam generative content, and due to the lack of the labeling - AI faces the issue of recycling its own generated content into its training batches, dropping the quality dramatically - and some of the people operating the tools aren&#39;t sure of which ones were authored, and which ones are generative. The quality of which - might affect the way the public shape opinions, literacy, and their action.<br/><br/>It is paramount that above all else, in order to protect the working class, to preserve the arts, to prevent the threat of misinformation at scale - The development, training, use, and outputs of these tools must require at the very least:<br/><br/>1) License on materials used in training<br/>2) Labeling and Disclosure of published outputs and training data sets<br/>3) Digital Watermarking in metadata/output of generative content<br/>4) Public Domain ownership of outputs - no copyright<br/>5) Compensation to artists if art is generated without license on materials<br/>6) Moderation of content<br/><br/>This list is incomplete - but it is what I consider the foundation of starting toward developing effective uses of this technology - that does not abuse and further bleed a working class into exploitation.