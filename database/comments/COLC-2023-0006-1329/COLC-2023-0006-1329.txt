It&#39;s inevitable that A.I. will eventually become a major part of industry in the world; and here in the growing period, we have a responsibility to develop it as ethically and responsibly as possible, because setting strict regulations now will have an impact with how its developed way down the line.<br/><br/>A.I. &#39;learns&#39; by the using the collection of human creativity, from art to written works. This creates two challenges; one is that humans are fallible, and in an era of open information, any data can be incorrect implicitly. This information can be disseminated through A.I. as fact, and then others will state it as fact, which will cause a cycle of misinformation to perpetuate. We are seeing this happen even now (source: https://decrypt.co/152060/ai-is-literally-trying-to-kill-you-with-this-grocery-store-app) As such, those who are developing A.I. hold a very important responsibility to make sure that no harmful data is entered or distributed through their system, and should be held accountable and responsible when such data *is* perpetuated. Otherwise we risk major harm being done while people who cause it hiding behind a veil of untested technology.<br/><br/>Second, we must make sure that AI gets its data done ethical. AI does not create, it merely interprets works made by humanity; from art, fiction and non-fiction books, and others. Many, even now, are using their platforms and reach to unethically take the efforts of many to profit off of it, without attribution or compensation. Left unchecked, this will create a dark period where artist, writers, researchers, and others will be unable to share their work without it being absorbed into a collective AI in which will claim and attempt to take credit and profit, creating a black box where each covets their own knowledge in the fear of someone else will profit from it.<br/><br/>Both these are problems that can be solved with strict regulation that is enforced heavily in this era while AI developers are still developing these tools and take these issues into consideration. But they will not voluntarily, as the cost and manpower and disincentive to profit creates a barrier they much rather avoid. This is why we need strict regulation to force them to be held accountable, so that AI can be a benefit to humanity in the future.