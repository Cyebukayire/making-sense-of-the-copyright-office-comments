I think AI works should not be copyrightable. (For that matter I think copyright is a bad idea in general, but I think this particular thing is a much more palatable decision even to people otherwise interested in preserving copyright&#39;s existence). It&#39;s generally anti-consumer to allow similarities in style, perceived or real, to be copyrighted. After all, this would limit creativity in many ways, allowing large corporations to take control of stylistic choices. Imagine what would have happened should such an influential movie as Citizen Kane&#39;s cinematic techniques been copyrighted! We&#39;d never see movies that even remotely compare to or surpass it ever again, because of how few tools would be available to the creatives, as each tool is used and its use copyrighted in turn. To allow copyright to apply to style or AI works would create a nightmare scenario where all possible methods to create a work in turn are copyrighted, and creative stagnation as techniques are locked away behind studio doors, forever kept out of the hands of smaller studios by the law.<br/><br/>As things stand, I think current law is fine, and no change is necessary, other than to specify clearly that AI work cannot be copyrighted, much as the work of say, an Elephant cannot be, as it was not created by a human and thus, unless we are to ascribe the copyright to the model itself (which I don&#39;t think many would be willing to do, especially considering the model is not a General Artificial Intelligence and how we don&#39;t give copyright to non-human animals anyway) makes no sense to describe as copyrightable.<br/><br/>As for your questions about what it means to train an AI, my understanding of the process is that first, a database is provided to the model. The database is huge, many terabytes, if not petabytes(!) in size, usually collected by third parties, often researchers, and consists of many well-described examples of what the model is intended to generate. The database may contain copyrighted information, there is very little curation involved. The model scans through all the data over a few days, and draws correlations between the data in the database and the descriptions attached. It remembers the correlations, but does not remember the data in the database. The database is then discarded. The model is then released. It does not remember the individual elements of data in the database.<br/><br/>When the model is prompted to give an output, it scans through the correlations it&#39;s drawn, and generates an output based on what the prompt it was given most closely correlates to. This is very similar to human cognition, and is also a very valuable tool for such things as protein folding problems, a major tool in the medical sciences.<br/><br/>It is not possible for a model, once released, to unlearn from the database, without deleting everything and starting over with a clean database. This is infeasible in many situations. It may be possible in specific cases to see that a model was trained on a certain type of thing (for example, image generators may also generate unnecessary watermarks) but this only emerges if it&#39;s been trained on a high volume of those types of thing. It is usually impossible without seeing the database to find out a specific, individual thing that the model was trained on.<br/><br/>As for your question 9, I think it should be opt-in, in principle, but few would actually provide data for that, so perhaps not regulating whether it&#39;s opt-in or opt-out would be best for now. Consent of the holder should not be required for noncommercial uses, and probably shouldn&#39;t be required for commercial uses either, as previously established.<br/><br/>Jumping right to your copyrightability questions to answer your specific ones (18-21)<br/><br/>18: Flatly no.<br/>19: No, as a consequence of 18<br/>20: I do not think protection is desirable.<br/>21: The constitution permits anything you want it to with creative enough interpretation. With that said, the protection would not help science or useful arts, and would indeed actively hinder them in many ways.<br/><br/>Thank you for reading this, if you did. I may not like your work as copyright people, but I do like your work as government people. Have a good day (or night if you&#39;re reading this late)