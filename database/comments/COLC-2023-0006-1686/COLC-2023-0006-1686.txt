I will be answering the general questions on the request document.<br/><br/>1. I have already seen this technology being used in attempt to remove humans from creative works. There was the uproar about the short Netflix film made mostly with AI for example. They credited it as AI (+human), they didn&rsquo;t even bother to name the person. I did research on this topic for an assignment and found that a living artist&rsquo;s style of art was made into an AI model without their consent, literally cutting the artist out of their own art. I&rsquo;ve seen AI art showing up in many different places, corporations don&rsquo;t want to pay artists, I&rsquo;ve seen an ad for a mobile phone game that was obviously made with AI. They can pay to advertise but won&rsquo;t pay someone to make a decent piece of art for the game they&rsquo;re advertising. This technology, without proper regulation, will allow companies to steal copyrighted work to use in training models. Going further, AI is now starting to be able to copy someone&rsquo;s voice, we should not have to copyright a person&rsquo;s voice but here we are. There are already companies that tried to get actors to sign away their likeness for the them reproduce in AI without any compensation whatsoever.<br/><br/>5. Yes it is warranted. I believe it should entail not being allowed to use someone&rsquo;s voice to make new sentences, and training models should not be allowed to scrape the internet indiscriminately, they should not be able to take artwork without permission.<br/><br/>8. I would say probably when it becomes public domain, Mickey Mouse has been avoiding becoming public domain for quite a while after all. Except for an Actor&rsquo;s likeness and voice, that should never be allowed even after their death. <br/><br/>8.3 training datasets should only be allowed to use materials that have explicitly given consent. If it is unknown where the image comes from/who it is of, they should not be allowed to use it.<br/><br/>9.  They should be provided the means to &ldquo;opt out&rdquo; but going further I think they should be automatically &ldquo;opting out&rdquo; in order to safeguard against people trying to steal their work anyway.<br/><br/>9.1 yes<br/><br/>9.2. Opting out should be automatic. There is a tool that was created by students at a Chicago college. It is called GLAZE. Essentially it scans and messes with the image data so that it is unusable in AI training sets should someone attempt to take it without permission. I think it would do well to be something to put in website codes (for uploading images) so that it is easier for the creators to protect their works. This would also protect against a person&rsquo;s face being used without permission, not just artwork.<br/><br/>9.3. Applying GLAZE to all image uploading websites would be a huge undertaking but would be good in the long run. AI takes and uses an enormous amount of data when scraping the internet will nilly, so getting permission from everyone is not currently feasible. Which is also why AI shouldn&rsquo;t be allowed to indiscriminately scrape data.<br/><br/>15. Yes, absolutely <br/>15.1. Should be extremely specific, down to individual person(s) that created the work they are using.<br/>15.2. It should be entirely public, no hiding anything<br/>15.3. They are obligated to track down where all images used came from and give credit.<br/>15.4 if they fail to do diligent record keeping, they must remove the uncredited images from their model.<br/><br/>16. They should be notified the moment their work is even being considered for use<br/><br/>23. No because it is not about copying the similarities in a specific work. They are literally taking a work without permission to make something. <br/><br/>24. AI model makers should get an automatic strike for not providing where the training material came from. They can prove an element of copying if a watermark is seen being repeated such as in the Getty Images case, and if their style of artwork is obviously seen within the generated images when put side to side. (I am not an expert this is just one part)<br/><br/>25. The creator + developer of the model. Whoever submitted the training data should be liable. <br/><br/>28. It should always be made apparent that the work was AI generated. In all contexts it should be made plain that the work is AI generated. Whether that be through a watermark stamp of some sort of written below the work. <br/><br/>28.1 ideally the person who generated the work, but there could be an implementation that has AI work automatically have an AI watermark somewhere on the generated image.<br/>31. Yes, insomuch that a person&rsquo;s likeness and voice are not to be used as it is a right to oneself to not have their likeliness and voice used, changed, or generated without their explicit consent.<br/><br/>32. Yes there should be protections against imitating the style of a specific artist. Everyone should be eligible for it. Even dead artists. <br/><br/>33. I&rsquo;m not sure what is in the section, but a person&rsquo;s voice should be taken and used without permission. Ever.