I am an artist. <br/><br/>For me, training AI models on existing work is a two part problem. <br/><br/>The first part is that the work used for training was created by individual humans for purposes that were emphatically not training AI models. The work may have been copyrighted or made for commission, in which case the work is, in a fundamental way, owned. Even if it was made for personal reasons, that does not place it in the public domain. Were the models trained only on material in the public domain, it would still be unsettling because the models can work well enough to forge work from individuals long dead. <br/><br/>The second part is that the models themselves cannot create work that is not contained within the models. Human creativity is a constant reaching out from within the bounds of the known. AI is not creative, it is generative, meaning it can only create work from within the areas it was trained on. This means that all AI work is by definition derivative and, basically, banal. This is backed up by several experiments songwriters and artists have made, asking various AI models to create work in their own style. The results are boring. They are a least common denominator of the available knowledge, not some new spark of creativity. <br/><br/>I think the current AI training protocols are theft from artists. <br/><br/>I do not think any of the work from AI models should be copyrighted. <br/><br/>