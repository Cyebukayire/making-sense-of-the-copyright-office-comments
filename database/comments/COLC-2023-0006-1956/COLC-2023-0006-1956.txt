I live in Boston, and I&#39;m a writer, as well as a scientist and coder (looking at using AI for protein engineering).<br/><br/>My strong opinion is that comprehensive laws should be passed to prohibit AI from training on almost all data, but especially copyrighted art or people&#39;s likenesses (which can be used to generate messed up pornography of them that looks just like a real photo or video, and therefore is really violating), without the explicit permission of the artist / subject / creator of that data. The reason why copyright laws exist is to protect an artist&#39;s rights to how their art is used, and a neural net that generates art / voices / etc. is simply &quot;interpolating&quot; between embedded transformations of their data. That means that when a net trains on a piece of datum (like a piece of art) it is inherently embedding a rough mathematical transformation of that art into its model; the art becomes one small component in the grander machine that is the net. Someone should not have their art used in a model without their permission, therefore, because it is a /part/ of the net. <br/><br/>Beyond that, copyright also exists to protect people&#39;s livelihoods, and therefore encourage the production of more art. As neural nets can only interpolate, they&#39;re not going to really make anything new or exciting - they&#39;re just going to make art that looks like what&#39;s fed into them. It&#39;s recyclitive and redundant, whereas real people produce fresh and interesting art. This is valuable to us as a society; we need to protect people&#39;s rights to their art not being stolen. I&#39;ve seen artists get all their work trained on to produce a neural net that replicates their exact art style, and it&#39;s derivative, it doesn&#39;t add anything... besides making them lose their livlihood because people can get free art that looks just like their commissions. But they were the ones that spent 10, 20, etc. years developing that art style and creating it. If we just allow things like this to happen, no one will be incentivized to hone their artistic talent and create novel art styles, as their style could be copied and mass-produced after they spent decades refining it. It will make art stagnate.<br/><br/>Moreover, as there is no human authorship, AI art should not be copyrightable. I think this is obvious enough.<br/><br/>I think that preventing AI training on people&#39;s art without their express permission will require more than just laws on the books; it&#39;ll require regular audits. Every AI company should have to pay a special tax and share their datasets with the government, and the tax money can be used for private auditors from the government to randomly spot check the data (like with random number generators for indexes in the dataset). If someone&#39;s not a company, just a small non-profit coder, then they should should have the option to pay the tax or just publicly share the dataset - so that the citizens of the internet can inspect it themselves.<br/><br/>I also think there should be laws prohibiting big tech companies from putting that users agree to their data being trained on by default. The thing is, lots of people HAVE to use facebook or twitter or whatever the big social media company of the moment may be for networking / their career / etc., and so do not have real choice in the matter. Therefore, it&#39;s coercive. Instead, all AI training on ANY personal data on social media sites should be opt-out by default, and require users to chose to opt-in, like cookies. They also shouldn&#39;t be allowed to pressure users into it by making the site difficult without the AI, like purposefully making people&#39;s feeds terrible if they don&#39;t use the AI, or making a pop up asking if they want to opt-in show up every time someone logs in, or other stuff like that I&#39;m sure they&#39;ll try unless it&#39;s explicitly banned. There should be HUGE fees that go to helping the government run as well as jail time to make sure companies don&#39;t do this.<br/><br/>However, I do not think this should apply to openly-available scientific datasets, in which case there is no right to be violated. Training a net to try and predict markers of cancer on an openly-published for academic use database, for example, only provides good to the people, without any downside or violation of artistic rights. In that case, I don&#39;t think scientists who published the datasets should be required to manually go back and opt-in for allowing their datasets to be trained on. That&#39;s the only relevant exception I can think of, though I&#39;m sure there may be more (it just comes to mind because of my field.)