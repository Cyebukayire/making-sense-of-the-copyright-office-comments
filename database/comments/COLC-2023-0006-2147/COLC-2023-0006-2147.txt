I believe that companies developing generative AI technology should have to acquire written consent from every person whose work they use to train their models, requiring opt-in, not opt-out. The burden should be on those who seek to profit from other people&rsquo;s work to gain permission from those people; ordinary citizens should not be burdened with the responsibility of seeking out every single corporation who might want to exploit their work. I understand that large sample sizes are crucial for training these neural networks, but those sample sizes should be sourced ethically, and that means informed consent. <br/><br/>Individuals should not be allowed to copyright work generated by these algorithms. If profit is generated from AI, it should be distributed among everyone whose work went into the creation of the neural network, including people whose data was used to train said network. Tech companies should have to keep detailed registers of where they sourced their data, who the original author was, when the data was sourced, and how it was acquired. There should be a governmental standard for records of provenance, and there should be penalties for noncompliance. <br/><br/>Tech companies must do everything in their power to make the utilization of AI identifiable: requiring licenses for use, retaining records of who used the technology and when. Most importantly, if AI technology is abused in any way, the creator of the neural network should be held liable for damages. Hopefully, this will incentivize better record-keeping, and a more mindful attitude about the harm that neural networks can cause in the wrong hands.