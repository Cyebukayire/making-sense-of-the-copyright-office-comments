From: Shannon<br/><br/>ATTN U.S. Copyright Office,<br/><br/>I have previously written to my Senators (Angus King and Susan Collins), and recieved a response from Sen. King, regarding why AI is unethical in its current state and requires appropriate regulation. I would like to reiterate some of the points in which Sen. King has agreed with.<br/><br/>Artificial Intelligence is an unprecedented technology, much like when the personal computer was first invented. Unlike the PC, however, the term AI is a misnomer and catch-all. The technology it suggests is that equivalent to a human brain, living and capable of independent, sentient thought. Unlike a human, which is capable of creating independent material, AI &#39;creates&#39; output from a vast swath of data collection which it rehashes into a final product. As a result, there are many areas in which copyright becomes a major issue.<br/><br/>First and foremost is the data collection. In the case of image generation, most generators [DALL-E 1 &amp; 2, Midjourney, Imagen] take their data sets from LAION [Large-scale Artificial Intelligence Open Network], a non-profit that has taken millions upon millions of material from the internet over the past decade. LAION uses their non-profit status to avoid copyright infringement by obtaining images under &quot;research&quot;, but the images themselves were pulled directly from copyrighted sources. This includes unpaid stock photography, like Shutterstock, to handmade digital art from individual users. In both cases, there have been numerous examples of stock image watermarks and individual signatures being recreated in AI images. Watermarks aside, the artists whose work are featured on these platforms did not upload or give consent for their art to be used in these contexts, much less other image uploaders.<br/><br/>Futhermore, the datasets also include explicit material that have already been copyrighted, or can never be copyrighted by another entity. There are specific examples of LAION obtaining images from private medical documents, crime scenes, and explicit violence or graphic non-consensual material. Much as an attorney cannot include new evidence in a trial after the discovery period, sensitive material cannot be leaked without due cause.<br/><br/>A second issue in AI use also arises from the generation of material. In order to create an image or text (i.e. essay, search results), the AI must take from the data sets it has. Thus, when it generates the material, it cannot create unprecendented content. The AI must incorporate that which already exists, and therefore work solely within context. This becomes a copyright issue where, in the example of educational and legal situations, assigned content is filled with plagiarism.<br/><br/>The problem of plagiarism is a significant issue in education with essays and scientific data. Students have used prompts to generate their assignments, which are then caught in a plagiarism checker. While the checkers have room for error, it has been found that AI writing generators are copy-and-pasting entire paragraphs from other sources. Furthermore, the sources can be completely unreliable. There was a recent case in which inexperienced lawyers submitted a brief including referenced court cases (to establish precedent) that do not exist. The AI generator they used had made up the cases in order to fit the context of the prompt. As one can derive, this matters in a copyright scenario due to the legal standings of which AI is based. The &quot;intelligence&quot; of the technology where it stands now does not and cannot be used in court applicable settings as the output cannot be trusted. The material is either already copyrighted, or cannot be sourced, and therefore cannot be proven to be original output.<br/><br/>The final point comes from when material cannot and should not be copyrighted; for example, national security. As Maine State Senator Angus King has written to me, the National Defense Authorization Act (NDAA) for Fiscal Year 2024 includes legislature King has authored to approve the DoD to &quot;improve labeling and detection capabilities for generative A.I&quot;. In other words, give established precedent to determine what is AI and give informed consent. <br/><br/>As how an item cannot be advertised with fradulent claims under the guise of the claims being copyrighted, generative AI has often attempted to pass for original art, material, and even personhood. According to King, in 2019, &quot;A U.K. energy company lost hundreds of thousands of dollars when hackers used an A.I.-based software to impersonate their CEO.&quot; Can you copyright videos that impersonate important figures, such as CEOs, politicians, or celebrities, for nefarious purposes? What about everyday citizens?<br/><br/>There are numerous real-world examples of workers being plagarized and their content used without consent or compensation. The precedents are already there. It is up to the US to uphold its security and protect its citizens from injustice by maintaining regulations against AI and to deliver appropriate restitution.