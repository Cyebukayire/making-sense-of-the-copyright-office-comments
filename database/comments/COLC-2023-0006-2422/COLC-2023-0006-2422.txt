Hello, <br/><br/>I&#39;ve attached a file answering every question directly. If possible, please hide my PII.<br/><br/>My background and familiarity is that of a freelance artist, operating my business entirely via the internet with digital commission work. It&#39;s for this reason I believe I have the best view into the impacts that AI will impact creative laborers, as I was one of the first one in the trenches.<br/><br/>I&#39;ve gone over the entire notice PDF and absorbed all of the questions, and without a doubt cannot give in-depth responses to many of them, but I do know I can provide opinions on desired law and information on where I stand in this in relationship to AI technologies, and the impact it&#39;s going to have on industries of not just creatives, but anyone whose labor produces data-- though, for the purposes of this comment, I will primarily be referring to image generation.<br/><br/>The copyright office seems aware of the nature of training on AI systems, though I&#39;m unsure of how deeply, and would hope objective machine-learning experts will be referenced to obtain a deeper understanding of how diffusion models, CLIP, and other AI technologies &quot;copy&quot; on some fundamental level to obtain their efficacy (I do not think this should even be a debate, but it is.)<br/><br/>In reference to the questions, I would like to preface with almost insultingly basic logic: the nature of training copyrighted works to generate more competing works is an explicitly exploitative relationship. As AI systems always require training data to function to the degree they do, they will inherently require real humans living and producing the data to build value/income, which the AI will copy. When AI is used to generate more predicated upon the need to feed off of that labor, you have a tool that is ultimately summed up as copying other&#39;s data and producing more that competes with that market. With this, you have a system that requires the existence of external human producers to function, provides no authorship to those producers, and has no sort of compensation to those human producers-- boiling down our labors into feed for algorithms and code to compete with us. For this reason, I do not believe there is a difference between one single image being copied and identifiable as a traditional copyright infringement, and the act of billions of them being customizable and interpolated together. They will have the same impact on the market, if not worse.<br/><br/>Of course, I speak from the ego of a creative illustrator, but this applies to anything that can be turned into data. The writings of professionals writers, creators of recipes, intellectual papers, voices, likeness, and the list goes on to anything else that can be inputted into computers systems. The projected crippling degree of losses of jobs from AI systems seen touted on media are ultimately predicated on mass exploitation of obscene amounts of individuals, having their output centralized and laundered by interpolation (through what&#39;s been defined as inference), and resold back to them by the companies that scraped their data from the web, almost always without so much as even an authorship source provided. I support a fine legal and ethical distinction between things that are acceptable for a human with needs and internal motivations and inherent biological inaccuracies to do to compete in a marketplace, and a tool that copies devoid of needs, intent, wants, desires, or all the other things that we biologically understand separate us from &quot;algorithms&quot;.<br/><br/>With the above paragraphs in mind, <br/><br/>The way I hope to see the legal landscape proceed for AI generation is that it resembles the previous generation of P2P and digital piracy. With P2P being an innocent but effective medium for piracy, there is a strong parallel to machine learning and AI systems with regards to competing, exploitative generation. I wish to see an explicitly affirmative consent future, perhaps being achieved generally through obvious wording on the terms of service of a website that is easy to find (and be avoided), or more strenuous means of individual solicitation. While, like piracy, these things do not simply disappear from the existence of executive and legislative action, they are not enabled by billion dollar industries and normalized and engrained into the fabric of our economic systems. I want to see a future where exploitative AI use can be legally, more than just morally shunned out of the limelight, and enforced to the point where business entities will refuse to engage with AI generation that they cannot maintain trust was ethically built, just like anything else. I personally question if the spiritual intent of copyright fits for AI generation, but I think such a discussion needs to occur only after the nature of it&#39;s training is dealt with. Fair use should only apply to consistently non-commercial, non-competitive practices, I want human endeavor to enable previously impossible fields, not compete with one&#39;s own. 