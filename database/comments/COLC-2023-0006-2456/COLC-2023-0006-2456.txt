Ai in the creative field in almost all applications is a travesty. Not just in the fact it unethically harvests data that doesn&rsquo;t belong to the companies behind them, including medical data, personal info, creative works, biometrics, etc. <br/>ai models cannot become unbiased. They advertise this, but ai models are only able to make an output based on its input. It can only remix existing work. Every bias that goes into those works gets picked up on and repeated.<br/><br/>Another tactic ai companies are pivoting to are saying ai will destroy the world.<br/>It is fearmongering and random work to get more funding out of nothing. If they were so concerned there would be no ai models being made. They are trying to exploit research to fatten themselves up.<br/>Ai cannot understand the world around it. It does not have concepts of what makes a cat a cat. It doesn&rsquo;t think that ears are ears, it just reads the overall shape and guesses. It does not think. It gets told yes or no on if it was right and then tries again. That is all it does. <br/>It will not have emotions or think to hurt anyone because all it does is try to predict an output.<br/><br/>When training an ai to detect tuberculosis, it made a guess based on the age of the photo. Not anything to do with the lungs themselves. <br/><br/>Back to specifically ai and copyright.<br/><br/>Ai is not a tool when it comes to art. It scrambled existing art, and can output the exact or almost exact image it was trained on. It does not learn what goes into art.<br/>It recycles a finished product.<br/><br/>Ai is using artists work to replace them. If they did not have the work made from artists, it wouldn&rsquo;t exist. <br/><br/>Ai also has extreme unethical uses, including blackmail, forgery, propaganda, doxxing, and more.<br/>It will be used to fake signatures. it has already been used to train on someone&rsquo;s voice, call someone they know, and then scam them.<br/>Due to training models containing personal info, that data could be output at random or if asked about someone specific may just pull it up.<br/>Misinformation will become rampant.<br/><br/>Ai companies mention a watermark, but it will likely be easily removed, and only allows them to continue to crowd out artists by continuing to harvest data that isn&rsquo;t labeled as such.<br/><br/>Opt out models are useless. The companies make it hard to know if they have your data, are willing and able to ignore such requests, and will make it hard to sue with a legal team.<br/><br/>At minimum<br/>Ai models must be transparent. If they cannot be looked into, no one will know they&rsquo;re being exploited.<br/>Ai models must be trained on copyright free images only. Possibly only images that are allowed for such uses.<br/>Ai must not get copyright protection. 