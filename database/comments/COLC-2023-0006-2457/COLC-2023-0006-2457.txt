I am a writer and occasional artist. I have a background in computer science going back to the 90s. I have a bachelor&#39;s degree in theatre and graduate degrees in oral traditional storytelling and business administration. I probably have some contrarian or counter-intuitive thoughts.<br/><br/>First of all, saying that AI generated work is not eligible for copyright is bad for artists. This essentially means that if an AI generated work is trained using an a writer or artist&#39;s own work that they cannot assert copyright over outputs that resemble the original work, including infringing works generated by AI. Should all AI outputs be found to be in the public domain, this would only further deprive artists of their livelihood, allowing their works to be endlessly infringed upon. I think it is important to assign copyright to the prompt engineer of the original elements of an infringing work specifically so as to define in the negative what copyrights of a pre-existing artist&#39;s work are being infringed upon and defining where the infringement lies.<br/><br/>I also think manually deciding whether AI works are eligible for copyright is problematic as it runs counter to the principle of automatic copyright being granted the moment a work takes fixed form, enshrined in law and treaty.<br/><br/>It is absurd to suggest that an AI itself be granted a copyright unless that AI has citizenship. However, insofar as AI is a tool like a pencil or word processor, I believe a prompt engineer need only assert two points to legitimately be an author who enjoys copyright: 1. Sweat of the brow, a concept enshrined in U.S. (though not all countries&#39;) copyright law. A simple prompt may not enjoy full protection. A complex or original prompt might. The originality of the effort should be key. 2. To fruitfully enjoy copyright, a prompter&#39;s work should not infringe on an existing copyright due to excessive similarity. This does not apply to style which is generally not copyrighted -- although state laws regarding personality rights and rights of publicity may be invoked. However, the usual factors of infringement like similarity of composition and structure, plot, editorial choices (such as in a translation), or arrangement are where infringement factors in.<br/><br/>Next, as someone with a background in computing/programming, I think the characterization of AI models as a plagiarism machine is misleading. As a function of what current computers can efficiently process, no major AI models with near realtime responses contain a complete repository of everything they were trained on. Much like a human art student, these models generally contain patterns or heuristics of the works they were exposed to -- and the more works they are exposed to, the less likely they are to plagiarize. In many respects, these are much like human authors. If anything, they would benefit from retaining copies of works used for training as part of a self-contained or separate anti-plagiarism model. My studies in oral storytelling and folklore inform my perspective here. Because these realtime AI models do not strongly &quot;remember&quot; the particulars of what they were trained on, they cannot -- as a human would -- acknowledge their influences fully with attribution in all cases or self-censor because they recognize an output as being similar to something they learned. Present realtime AIs exist almost wholly in a model or orality rather than literacy, reflecting how pre-literate cultures assumed collective authorship for works without attribution and did not concern themselves with plagiarism or distortion because the words could be reshaped by multigenerational lineages of speakers. There are deep similarities between how realtime AI works and traditional oral cultures such as Appalachian folk culture or the oral tradition of events in Hebrew and Christian scriptures prior to them being recorded in written form, when the specific wording became fixed.<br/><br/>By contrast, there are AIs that are not realtime and these should be regarded and categorized differently. The major player in this space is the deepfake family of AIs. These, likewise, do not contain all general knowledge as the model would be too big to process but focus on taking two sets of inputs and making elements of one set more closely resemble another, such as taking one actor&#39;s face or voice and modulating it to resemble another. Here, the goal is essentially to infringe on a source sample dataset and it should be essential that the party involved have permission to infringe on the underlying source. Whereas realtime AI strives to diverge from numerous source inputs, the goal of deepfake style processing is to achieve similarity to a relatively narrow sample of inputs using precise references. For example, &quot;Indiana Jones and the Dial of Destiny&quot; used an AI with a long processing time to scan hours of old Harrison Ford footage and slowly contort footage of his present self and young stand-ins to more closely match it.