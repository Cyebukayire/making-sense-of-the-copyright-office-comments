I am a freelance artist, cartoonist and I appreciate human skill and creativity, enough to see the dehumanization of STEM people who see humans as little more than wet computers from which to get free data.<br/><br/>Piracy and counterfeits are a tremendous damage to the creative industry, why allow it now just because technology companies do it?<br/><br/>There are several lies like &quot;learns like a human&quot; or similar garbage, when in reality it is an interpolative coded database.<br/><br/>They could give technology companies a free pass to extract the value of people, artists and ordinary people around the world from their data, their image and their identity if they allow AI to have copyrights.<br/><br/>People&#39;s photographs, their art, their creations are not the property of large companies, nor can they be taken just by saying things like &quot;the computer learns&quot;, there are no real grounds for that to happen, it is image encoding in value the distribution of pixels and labels,<br/><br/>Just because they had created a lossy compression process for billions of images does not give them the right to use those images, or to say they &quot;learn&quot; to take over the work and data of millions of people around the world, we cannot simply change the rules to favor cheaters and thieves, that is why they took everything by force, because they know that without data their algorithms are nothing, they are probabilistic copiers, and they need to hide where the copy comes from, by quantity.<br/><br/>For a person to see 5 billion images it would take around 237 years if they slept 8 hours and saw an image every second, it does not &quot;learn&quot; like a human, it encodes the images in value to the deltas of said images, just like a Video does not have to store all the frames of a movie but the pixels that move, the AI does the same by storing common data of various images to be able to regenerate them, what is known as lossy compression is an encoding method,<br/><br/>This is why AI companies want and need their theft to be seen favorably by the copyright office, because they are selling stolen material decorated and with a bow that they define as &quot;intelligent.&quot;<br/><br/>And this goes beyond copyright, violation of privacy, child pornography, illegal content, etc., everything among these data, the artists have proof that both Emad (stable diffusion) and David (midjourney) knew that What they were doing was illegal, they knew it since 2022, according to the stable diffusion discord, they knew it since April, or even before.<br/><br/>But they didn&#39;t care, because for them it is &quot;learning&quot; even though they clearly know that it is an image coding system based on decision trees in Markov schemes,It is to generate equations on pixel distributions in order to create compressed versions of said distributions and with them to be able to reconstruct said images.<br/><br/>They hope to deceive the public and organizations such as copyright with phrases like &quot;the data is not in the models&quot;, when in reality it is, encoded, many of it lost, but still copies of the distribution of the pixels. , they are encoded images just like pokemon images are encoded and you can only read them with the appropriate software , example https://www.youtube.com/watch?v=aF1Yw_wu2cM<br/><br/>Not to mention that licensing a total of 5 billion images so that these systems function less like a copier and more like something that is a &quot;creative tool&quot; (which we already know it is not) could not be possible for any company to finance.<br/><br/>So, are we really going to change the rules of the game to allow cheaters and thieves to get away with it? Will we allow the destruction of the copyrights of true creatives by greedy companies that see people as just data that they can take and exploit without any repercussions?<br/><br/>We should not see it as a &quot;tool&quot;, but rather as lossy compression software for billions of stolen images that benefit a few companies with the computing power to develop such systems.<br/><br/>