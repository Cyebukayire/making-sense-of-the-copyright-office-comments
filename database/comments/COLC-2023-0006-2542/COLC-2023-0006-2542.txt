It is considered good ethical practice for human artists to pay for their reference photos, only use photos they take themselves, or be granted the license to use someone else&#39;s photo openly; either through open license sites like Pexel.com or through a private agreement.<br/><br/>Artists use these reference photos to create their art (painting, digital art, sculpture etc.).<br/><br/>However,  AI does not follow this ethical practice. It scrapes other people&#39;s owned images to make a smash up of these images into an image. I have often even found the remnants of watermarks on AI created images, like Getty images, Associated press, or an artists personal signature/watermark.<br/><br/>Watermark images are copyrighted images. Using these images directly, even for derivative works, could get a human artist sued for using the image without licensing it. <br/><br/>So, the question is, if it would be bad, even legally precarious, practice for a human artist, why not for an AI company. <br/>AI does not learn how to make art by looking at other people&#39;s art and making new art. It takes elements from other people&#39;s existing art, scraped from the internet, and mashes it all together. Again, as can be seen by the fact that artist&#39;s signatures and watermarks can  be clearly scene in a lot of the AI&#39;s output images. <br/><br/>I hope for a legal precedent on whether AI companies will be held to the same ethical and legal standards as artist have been for decades.<br/><br/>*Examples of AI images with the relics of watermarks and artist signatures attached.