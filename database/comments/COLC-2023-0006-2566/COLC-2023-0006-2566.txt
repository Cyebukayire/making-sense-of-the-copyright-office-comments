As an engineer who runs a small game studio I am very concerned about the proliferation of generative AI and its disruptive and isolating effect on multiple creative industries. Already among myself and many of my friends and colleagues have experienced their life work, efforts, and even self worth being taken from them without any say so on their part. Art, music, code, 3D models, assets, writing, narratives, etc have all been taken from the internet and incorporated into training databases without any permission, compensation or agreement. At present there seem to be very little recourse for those impacted by this unwanted use of their creations without authorization. Barring general legal precedent or regulation these acts continue unabated. Further even if you can now &quot;opt-out&quot; of your work being used for training there is no method of removing the already trained content from the AI training networks. In other words undoing the damage now is no longer as simple as requesting no further training can occur on said work.<br/><br/>Disruptive technology has been developed numerous times throughout history. Jobs changed. Workplaces changed. And every time those disrupted by the work were undoubtedly upset. This, however, is different. This technology can only exist on the backs of millions and millions of people - it can only function by consuming their life&#39;s work and training networks of weights of how to reproduce it. Worse, the output of this technology is in direct competition with those who life work it consumed for its very existence. The technology would have no value without the work it consumed - without any compensation or approval. <br/><br/>In the case of images this is particularly apparent. The algorithms are generally trained to take art, add noise, and train themselves to remove that noise to reproduce the underlying art. In other words they are specifically being trained to reproduce the art they obtain. Without enough samples of art this is extremely obvious in the outputs. Only when the results are obfuscated by adding millions of other samples do the generations look &quot;unique&quot; or &quot;new.&quot; <br/><br/>Direct copying of copyrighted works is illegal especially when the copied product competes with the original. But is copying limited to the identity function? How much does one have to change something before it becomes something new? In the art world the essence of copying comes down to human senses - namely the appearance. If something looks the same it&#39;s probably copied. If it doesn&#39;t... it&#39;s probably unique. I would argue this does not apply to machine art however. The machine art generation algorithm is designed to obfuscate and blend the source material to make the results look new - but in the domain of the feature space the machine works in - the art is very similar to the source. Consider the Fourier transform of a function - a function can be changed wildly in time space and produce entirely different outputs but in Fourier space it may only be a mere phase change of a few parameters. <br/><br/>If a pharmaceutical company copies a product under patent and changes the periphery of the chemicals to obfuscate the source so that it looks entirely new does that represent an entirely new product? No - the process matters. The same is true with that of machine content generation.<br/><br/>Therefore in my view we have a technology that relies entirely on the consumption of protected works, competes with the same protected works, and provides no compensation or agreement to anyone who produced said works. It is theft. And I hope we do not see a world where&#39;s one work, one&#39;s own voice, one&#39;s own appearance can be simply taken from them and used for whatever purposes suit so long as it is tweaked a bit.<br/>