<br/>This comment aims to address the following questions posed in the notice:<br/><br/>1) <br/>I think that AI is an interesting tool, but comes with many issues if its word is taken as fact. The AI applications mentioned in this notice (ChatGPT, MidJourney, Stable Diffusion) are predictive engines, not creative engines. They only predict what a probable word for a response should be based on its data set. As I&rsquo;ve seen and heard in my Computer Science classes, an AI is only as smart as the data you train it on. If an AI was presented as an engine based on credible and diverse sources, but trained on a data set with an ideological tilt or patently false information, it could have negative impacts on members of the public who seek answers on its false credibility. Creators can see significant impacts if their works are used to train datasets without their consent, because generated works based on that dataset could mimic the majority of a creator&rsquo;s style without giving due credit to the original author or the work they put in to honing their craft. Some image generation engines even allow a user to input a creator or human model&rsquo;s name and generate pictures blatantly in that creator&rsquo;s style or that human&rsquo;s likeness, without the source party&rsquo;s input. They only predict what the end result should be based on a massive data set and the user&rsquo;s input. They aren&rsquo;t adding any element to the creative process.<br/><br/>4) <br/>I think one significant copyright case that has precedent in how AI copyright should be handled is regarding animal-made art. The copyright office has already stated that non-human animal-created works have no grounds for copyright, and such uses belong in the public domain. As current AI technology is only predicting and generating from its processes, and that these works are non-human, I believe works solely generated from a predictive engine don&rsquo;t have grounds for copyright and should be treated as public domain. <br/><br/>9)<br/>I strongly believe that copyright owners should affirmatively consent to the use of their works in training datasets. Though having an opt-out method is better than having no method of objection at all, I have seen several online applications that use opting out as a shield for taking and distributing protected works without an author&rsquo;s consent (Ex. content posted on monetized sites like Patreon or OnlyFans, model files &ldquo;ripped&rdquo; from creators and video games and sold on marketplaces, etc.) An explicit, opt-in approach would empower creators rather than people or corporations that can hide behind legal ambiguities on their legitimate use. <br/><br/>9.1)<br/>The consent should be required for all uses, as it&rsquo;s tough to discern which uses are commercial vs. non-commercial for a generative engine. I&rsquo;m not well-versed in business and how commercial vs. non-commercial intent is handled, but I could definitely see at least one person trying to make a quick buck off of casual ChatGPT usage to a gullible friend, or a site using AI-written material to squeeze out more clicks and ad revenue.<br/><br/>9.3)<br/>Some may argue that the volume of works used for training would make attaining copyright from authors unfeasible, but I argue that the current lack of required consent is what drives the massive volume of data sets. Allowing the LLM&rsquo;s size to block the need for consent will give AI maintainers a grey area for unauthorized use of creative works.<br/>