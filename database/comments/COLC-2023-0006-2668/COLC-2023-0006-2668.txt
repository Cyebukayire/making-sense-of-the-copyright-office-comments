As an artist, I have witnessed AI usage that is creative but also exploitative. There needs to be regulation.<br/><br/>It is far too easy to utilize AI to mimic the likeness (visual, audio, etc.) of real people, which can be used to generate rapidly spreading misinformation.<br/><br/>E.g., a person&#39;s voice is replicated by an AI to say something illegal or socially shocking, then spread online as a &#39;leak&#39;. In the person&#39;s struggle to disprove the false &#39;leak&#39;, they are terminated from work and their reputation suffers.<br/><br/>Political and educational misinformation is already a huge problem; AI contributes to it exponentially through examples such as this. Regulation is a way to combat it.<br/><br/>In regard to art, there is argument to be made with fair use remixing (parody, satire, non-profit fan work). That sort of creation should still be allowed. AI can be a great tool for artists to add to their work. However, it should be limited to that: a tool. Artists should have the right to reject AI usage if they desire, preferably through a default opt-out rather than assuming they want to opt-in. <br/><br/>Currently, certain AI models scrape online art regardless of the artist&#39;s wishes, and they scrape popular trademarked work that can go on to be used against a company&#39;s brand standards. That sort of usage should at the very least not be commercialized, or else that constitutes art theft. Records should be kept as to what data is scraped and why it was chosen, and copyright holders should have a say in removing their data from those datasets. This is where regulation comes in.<br/><br/>Concluding: a human is the one who builds and runs the AI. That person&#39;s decisions should be held accountable.