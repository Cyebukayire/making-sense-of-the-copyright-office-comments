While I think that AI is an interesting and exciting development in technology, as a professional, I think that we as a society should proceed with much more caution around this technology than many in the private sector have been. <br/><br/>People think that the widely available technologies, such as ChatGPT, Google Bard and other interactive online tools that general text or art being called Artificial Intelligence (AI), means that they are actually intelligent. This is not true and to my understanding, a misunderstanding of the field. While it is under the field of Artificial Intelligence, what these tools actually represent are large scale machine learning models that use machine learning and training data to create the tools we interact with. That means it had to learn or train on data that came from somewhere, and somewhere is from things other humans have created. AI as it stands is a black box, we do not understand where the information is from and so the humans who originally developed an idea are not able to be credited. This means that many people might be left out from monetary success from an idea they created, or replaced by a technology that actually uses ideas they create. As such I believe that there should be regulations broadly (in patents and elsewhere) that create more transparency around these learning models and that compensate those whose ideas the models learn from. <br/><br/>It is deeply perverse to watch sectors put people out of work, when many of those very same people likely contributed to the information that the AI model they are being replaced by learned on in the first place.<br/><br/>I believe that things created with artificial intelligence should be held to a citation standard, the same way I would be if I were to publish a book, article, paper, or documentary that was influenced by other people&#39;s work. I don&#39;t think it is wrong to use tools to help generate ideas, refine or edit code, or to do new things. But I think we should know how those came to be, and be able to identify at the very least whether an AI tool was used, what prompts were involved to create the new item, and even more ideally for these products to be able to accurately site where it learned. For example, if one creates and wants to patent AI image, in the style of Georgia O&#39;Keeffe, Pablo Picasso and an online web comic artist, I think we should be able to understand that, and if the case is that someone is living and their work contributed a way to potentially associate them with the resulting patent/product/idea.<br/><br/>Additionally, efficacy in AI is elusive. The goal of the algorithm is to compose responses (whether text or visual) that best mimic human responses or style, not to actually be correct. When you prompt AI, the goal is to respond in the most human way based on what it has learned, not to general new ideas, nor to be correct. This causes errors and potential harm at large commercial scale, if inaccuracies are still not caught by a knowledgeable human reviewer. I think that the reductions in work in certain fields we already see, in favor of AI could be costly in the long run as I think that the capacity and capability to generate new and accurate responses is oversold in its current stage. As such, I think that we should scrutinize with caution any product (or patent) that has used AI in its development to ensure that a human with enough knowledge has created something that is accurate and safe. <br/><br/>New technology is exciting and though I have concerns expressed above, I don&#39;t think we should rush head long into it, without due consideration and regulation. As a member of the millennial age generation, I have seen the damage technologies and products adopted too soon and without adequate regulation have had on society (leaded gas, personal data collection online sold by data brokers to advertise, various pharmaceutical products, and more and more). I think it would be a mistake to leave this new sector unregulated and to not acknowledge that humans are still very much essential to it&#39;s success, without getting credit or compensation. <br/><br/>With new technologies, we don&#39;t know what we don&#39;t know, and it is important for federal agencies to act as guardrails for society and to help develop frameworks and regulations that both allow us to engage with and observe the impacts of developing technologies but also to protect humans from being too harmed by those developments.