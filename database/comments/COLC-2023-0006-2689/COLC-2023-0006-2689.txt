This comment is being submitted in a personal capacity. As a law student and an artist, I support the development of legislative or regulatory steps regarding AI in copyright. Artists have already begun to attempt to use the legal system to protect their works, such as a group of writers suing OpenAI (Reuters; 2023). Notably, in a class action lawsuit against Midjourney and two other AI imagery generators, the attorney summarized the wrongdoing of the imagery generators in &ldquo;the three C&rsquo;s&rdquo; (Chayka, 2023). The artists did not consent to their art being used to train these generators, they were not compensated for their involvement, and they were not credited for their unknowing contributions (Chayka, 2023). These three C&rsquo;s exemplify the harm AI causes creators and copyright holders. <br/><br/>15. In order to allow copyright owners to determine whether their works have been used, should developers of AI models be required to collect, retain, and disclose records regarding the materials used to train their models? Should creators of training datasets have a similar obligation?<br/><br/>Yes. To the extent that it is possible, developers and creators of data sets should be required to retain and disclose records regarding the materials used to train their models. Doing so would allow copyright holders to potentially check if their work was used to train AI without their approval. It could also be used in a potential lawsuit to help prove there was copyright infringement.<br/><br/>23. Is the substantial similarity test adequate to address claims of infringement based on outputs from a generative AI system, or is some other standard appropriate or necessary?<br/><br/>It is not. AI systems are trained on thousands of inputs, aspects of which may appear in any particular output. The question should not be &ldquo;is the output substantially similar&rdquo; but rather &ldquo;was a copyrighted work used in the training datasets without authorization by the copyright holder.&rdquo; The use of a copyright holder&#39;s work without their permission violates the right to control derivative works. While the work might not be utilized in every output, the AI was still trained with the copyrighted material and can use elements of it in an output if it determines that it fits the prompt. <br/><br/>28. Should the law require AI-generated material to be labeled or otherwise publicly identified as being generated by AI? If so, in what context should the requirement apply and how should it work?<br/><br/>There should be a requirement to label AI-generated material. A large concern with AI-generated material is that people will believe it is real. Fake images of the former president getting in a scuffle with police, fake sound recordings of celebrities &ldquo;saying&rdquo; whatever the prompt directs them to, and people&#39;s pictures unknowingly being used to create deep fake porn are all examples of current AI-generated materials where the line between reality and generated reality get blurred (Bond, 2023; Hao, 2021). While it may come out later that the materials were created by AI, the damage was already done when people believed it was real. Even if people are able to figure out if the materials are AI, the prevalence of AI-generated materials makes it harder to trust the materials out there.<br/><br/>Appendix:<br/>Brittain, B. (2023) More writers Sue OpenAI for copyright infringement over AI training, Reuters. Available at: https://www.reuters.com/technology/more-writers-sue-openai-copyright-infringement-over-ai-training-2023-09-11/.<br/>Bond, S. (2023) AI-generated deepfakes are moving fast. Policymakers can&rsquo;t keep up, NPR. Available at: https://www.npr.org/2023/04/27/1172387911/how-can-people-spot-fake-images-created-by-artificial-intelligence.<br/>Chayka, K. (2023) Is A.I. Art stealing from artists?, The New Yorker. Available at: https://www.newyorker.com/culture/infinite-scroll/is-ai-art-stealing-from-artists.<br/>Hao, K. (2021) Deepfake porn is ruining women&rsquo;s lives. Now the law may finally ban it., MIT Technology Review. Available at: https://www.technologyreview.com/2021/02/12/1018222/deepfake-revenge-porn-coming-ban/.<br/>