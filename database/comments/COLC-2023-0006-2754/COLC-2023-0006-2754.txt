Comment on the use of copyrighted works to train AI models<br/><br/>The main issue in my view is the right of attribution for visual artists. In labeling training data there should be a conscious decision whether to include the artist&rsquo;s name. Generative AI systems now use artist&rsquo;s names to invoke a typical style associated with that name. This is problematic. From my own experimentation it is already possible to make works that are in many ways indistinguishable from the input training data with the use of specifically trained LoRA models in combination with a strong base model. I applied this successfully with my own art (my aim is to create a sort of assistant for myself). People having a hard time distinguishing original works from the fakes is diminishing the value of an artist&rsquo;s name. His original images are at risk of drowning in a stream of fakes. There is simply little way of knowing (for the layman) whether an image you come across who the original creator is of the style. In my view a base model can be trained on the work of living artists but they can&rsquo;t be labeled with the artists name. How to recreate a certain style should be left to the creativity of the user of AI systems, cutting off the shortcut of simply invoking the style by prompting the artist&#39;s name. Dead artists can be included with names in datasets if we can agree on establishing a prudent time of copyright expiration after their deaths. This way recreating living artists&rsquo; work should require effort and creativity in a way that is not dissimilar to how a real artist would study another artist. <br/>In copyright it should be a distinguishing factor whether somebody is able to produce works in a certain style with or without the use of another artist&rsquo;s name. <br/>Copyright claims should also inform about the use of LoRAs and how these were obtained by the claiming party. Training a LoRA can be considered a creative effort because it involves creative selection, curation, proper labeling, dataset preparation, computing effort and time. For a copyright claim the training data and parameters of a LoRA should be made completely transparent. <br/>For training datasets living artists should be asked for permission and  commensurately compensated. I could also think of a social fund that for profit AI companies would pay a tax for, which helps artists when they&rsquo;re ill for a longer time. This should also apply outside the US if these AI companies source their data worldwide. <br/><br/>Comment on the copyrightability of material generated using AI systems<br/><br/>There needs to be a distinction of input effort. For example: A midjourney image can never be copyrighted because the user has no control except for what is typed in the prompt input box. The variation is purely dependent on the random input noise seed. The creative decisions in terms of composition, pose, color, light, perspective are all produced by the system. For the user it is impossible to have a creative vision and have the system produce images completely in line with that vision. <br/>Stable diffusion is another platform that can be used in the same way as midjourney, but at least the system offers the possibility of creative user input such as:<br/>- controlnets for color, perspective, pose and composition; <br/>- LoRAs, embeddings and fine tuned models  for style or likeness;<br/>- inpainting and outpainting for refining results.<br/>It offers possibilities for manual guiding the results with user sketches and photos. <br/>In conclusion: for a copyright claim it should be apparent whether an image is a deterministic result of prompt and (depending on chip architecture) noise seed or that there is more to the creation that couldn&rsquo;t be done by another user on the same system. <br/><br/>Comment on the liability for infringing works generated using AI systems<br/><br/>The burden of ethical curation should definitely be on the creators of the AI system. A user should not be able to generate infringing works and if they do the creator of the system/trainer of the datasets is at fault. Therefore AI systems should be subject to thorough government regulation. The user can only be expected to behave ethically within bounds. Consider my first comment on the right of attribution. It should be possible to trace the origins of a work to the proper creator. AI systems should be designed to allow this. <br/><br/>Comment on generative outputs that imitate the identity or style of human artists.<br/><br/>Traditionally the competence and ability to create compelling art is hard-earned by years of study and practice. This is considered fair. If you put in the work you deserve the recognition for being an artist and the job opportunities that are afforded by having these skills. Our concern is that this fairness will cease to exist. In the future it could be that I would have to compete with somebody who managed to download my art and created an AI model with it. 