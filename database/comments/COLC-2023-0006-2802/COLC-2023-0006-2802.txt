It is dangerous, for reasons people often don&#39;t bring up. Statistic aggregation software can compile the works of authors and visual artists and spit out poor regenerations of them, without attribution. This form of theft often goes unnoticed by the general public, it goes uncredited by the human engineer, and it goes unpaid for. Copyright under the &quot;artificial intelligence&quot; &quot;revolution&quot; is difficult to maintain. It needs to be outright banned to preserve the integrity of human creativity and productivity. My writing has already been stolen, reproduced, and profited off of with the use of &quot;artificial intelligence&quot; software. <br/><br/>I have also had thousands of images forced down my throat on social media. AI generated images of celebrities, influencers, random people, all naked, all doing salacious and heinous sexual acts. These are only possible because of AI. All of these images completely indistinguishable from genuine photographs. Videos that look 100% real are being generated and sold for hundreds and thousands of dollars on Discord. Celebrities have the money to get these things taken down, but what about the average person? What about the kindergarten teacher that has her life ruined because an ex boyfriend with advanced software capabilities decides to send out a mass email to her coworkers, or worse, to her students&#39; parents? What about a foreign agent or government that creates a deepfake of a US President or equally identifiable representative? It doesn&#39;t even have to be sexual - they create a video saying we&#39;re planning on bombing, or already have bombed, the Kremlin. Or North Korea. And we don&#39;t know about it until Mainland USA is receiving counter attacks. <br/><br/>These are all things that actual military officials in my personal life have concerns about. So I raise them to you - what looks better? A severe, sweeping over correction that keeps us safe? Or not acting, and making the wrong choice?