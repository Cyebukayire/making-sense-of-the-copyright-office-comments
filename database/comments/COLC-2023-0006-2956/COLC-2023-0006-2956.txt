I am an operations researcher who uses AI and ML models in his work as well as someone who uses generative AI for personal use. Views are of mine alone and not my employer. Below are answers to some of your questions:<br/><br/>1) One issue I&#39;ve seen in the creative space is that LLMs are being used to generate junk content which are used to overwhelm smaller content venues. For example, a sci-fi magazine that used to accept user-submitted stories no longer does so because they were flooded by AI-generated submissions. https://www.npr.org/2023/02/24/1159286436/ai-chatbot-chatgpt-magazine-clarkesworld-artificial-intelligence <br/><br/>This is also an issue in web content. Spam websites are siphoning ad dollars from legitimate businesses. (e.g. https://www.newsguardtech.com/misinformation-monitor/june-2023/) Etsy is being flooded with AI generated junk as well. <br/><br/>It is unclear whether or not a lack of copyright protection would stop, or even slow, this flood of junk. But from an ethical perspective, I don&#39;t feel they should be given extra protections from the US government. <br/><br/>AI-generated content is functionally the output of an equation. I don&#39;t believe I can copyright the number 293891980100442929919, even if it has never been generated before, if all I did was take an off-the-shelf equation.<br/><br/>That said, the output of an equation can definitely violate IP protections, and this isn&#39;t new. There exists an equation that, when plotted on a 2d plane, generates the Batman logo. It&#39;s called the &quot;batman equation.&quot; https://mathworld.wolfram.com/BatmanCurve.html <br/><br/>One could argue that constructing such an equation takes technical and artistic skill, and if a novel piece of art were generated by creative use of algebra, that piece of art should be protected IP. <br/><br/>So-called &quot;prompt engineering&quot; is a grey area, lying somewhere between completely automated AI-generated content (with no &quot;human in the loop&quot;) and painstakingly crafting algebra to make a specific piece of art. I do not know where the line there is.<br/><br/>7.2) Generative AI models are &quot;neural networks&quot; in which various &quot;nodes&quot; each represent a function and they are connected to other nodes, groups into layers. Evaluating a neural network is akin to evaluating an equation. It&#39;s just a far more complex version of a*x + b*y = c. In this case, x and y are variables, and a and b are the coefficients. In a neural network, x and y are the connections between neurons and a and b are the weights of those neurons. <br/><br/>In a generative AI network, there may be billions of terms in that &quot;equation&quot;. Just like in the batman equation, where the terms of the equation come together to form the batman logo, the terms of a generative AI model can form a poem, image, or whatever. <br/><br/>The parameter weights are then &quot;trained&quot; on various inputs and outputs to give new outputs that match well with new inputs. It&#39;s a prediction algorithm. If I say &quot;1 + 1&quot; to an LLM and the model respond &quot;4&quot;, the model isn&#39;t trained very well, but if it says &quot;2&quot; it is. That&#39;s not because the model is actually evaluating 1+1, but rather because it has been trained that if you say &quot;1+1&quot; the most likely response is &quot;2&quot; given its training data. This leads to question 7.3.<br/><br/>7.3) The trouble is, it is impossible (to my knowledge) to disambiguate exactly what contributed to which weight and by how much. If a particular weight is, say, 0.838921..., it is not possible to know what that weight otherwise would have been if a particular copyrighted work were not in the training set. In fact, it&#39;s almost impossible to know even what the variable represents. <br/><br/>The way to remove a copyrighted work from a training set would be to train a new model from scratch with the revised training set. Even then, it&#39;s hard to put that genie back in the bottle, since the weights have already been trained and are publicly available. Anybody wanting to start their own model can start with the weights of an existing open source model, and go from there. I don&#39;t know how to enforce saying &quot;You cannot use 0.838921... as a weight on the connection between neurons 3010 and 993 because that number was generated using copyrighted data.&quot; Even if you tried enforcing that, they could make a change in the 10th decimal place such that it&#39;s technically different. <br/><br/>7.4) As far as I know, there&#39;s no way to know for certain, because others discussing the material could also lead to knowledge about copyrighted material. For example, if you tell a LLM to write a poem in the style of Maya Angelou, it may still be able to do so based on people on the internet writing poems in the style of Maya Angelou. Or, for example, a textbook outlining Angelou&#39;s style. You may have suspicions that it was trained on certain work. Depends on burden of proof.<br/><br/>9) I don&#39;t know that it should be limited, as long as the work was acquired legally. If I buy a book, I&#39;m allowed to count the number of times a word appears. I can write it down, and even sell my findings.