Including a copyrighted body of work in training data should not preclude the results of a generative technology from obtaining its own copyright, so long as that result is substantially different from the original. In instances where one or two bodies of work make up the the entire sample space for a particular input, it is likely that the final result will reflect aspects of, if not wholesale copies, the copyrighted data. That should be discouraged. From the AI organization&#39;s perspective, it can be difficult to cover the sample space of hundreds of billions of parameters. It&#39;s often the case that only a subset is tested against in the verification process, leaving the possibility that an unexpected input leads to unwanted, unexpected and/or prohibited behavior. Protecting against these &quot;adversarial inputs&quot; is an open question and the source of ongoing research. <br/><br/>On the topic of remuneration, I believe that this should be addressed explicitly by the individual sources. Github, a repository for code, asks that each project include a license detailing how that code/data/project may be used, under what commercial applications, and details the liability of the original author. I think that individuals who make their work publicly available on the web without restricting use should not be granted compensation for their inclusion in a training set. Conversely, if data was illegally scraped or gathered against the wishes of the author, in a way that violates a user agreement or terms of service, the organization responsible for the license violation should be fined and the author should be due compensation.<br/><br/>These are the opinions of an computer engineer with an undergraduate grasp of the technology and the math behind it.