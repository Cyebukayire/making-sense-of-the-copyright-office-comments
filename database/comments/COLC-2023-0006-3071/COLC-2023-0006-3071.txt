Anything generated by AI models will always be derivative works only, as the original artists&#39; works will always be needed to train them and because of this. You should only use copyrighted works with the opt-in consent of the author and giving them financial compensation. In addition, you should always be given credit for your contribution.<br/><br/>If this is not done, the AIs become &quot;Parasites&quot; of the artistic industry, because they are totally up to the artist to train them, but at the same time the artists see their market and job opportunities damaged by having to compete with derivatives of their own work. . This is what already happens with plagiarism and copies without licenses and in the same way, it must be illegal.<br/><br/>I also believe that the consent of the artists should only be through contracts signed by them, not TOS or EULAs that these systems would be very easy to be abused by companies.<br/><br/>In addition to the fact that AIs cannot unlearn, because the neural network they work with is largely a black box where you don&#39;t know for sure what interacts with what. The current solution from AI companies is to &quot;mute&quot; certain results that may occur, but these can be removed with user modification and are not a real way to unlearn. so I think that the AI that are trained with data that should not be used for training, is to be destroyed regardless of the economic cost that this implies.<br/><br/>And finally. Companies that create AI models should make all training data public (so security, private and identity data should not be used for training) by law and with legal consequences in case of hiding them, they should put watermarks recognizable images that show that the material is generated by AI reduce possible deception and should be held responsible for everything that their AI models do, since the user does not create them, they only request them from the machine.