As someone who works in accessibility and technology, I have been looking at the arguments for AI/Machine Learning and copyright.<br/><br/>Machine Learning and AI - I say &quot;Machine Learning&quot; specifically - all just scrape data. This data is generally scraped and reviewed automatically, without consent, and different from an artist getting inspiration from a painting or craft - all Machine Learning and AI can do is &quot;sound&quot; correct, or to remix existing work.<br/><br/>We thus not only have an issue with art and copyright, but national security. But as this is about copyright, let me concentrate on that; I keep hearing the arguments that 1) it is not substantially different from an artist getting inspiration or learning different techniques and using them in their own pieces; and 2) the advocacy for AI as part of &quot;well it&#39;s the future, we&#39;ll figure it out later&quot;. This advocacy ignores a decades-old history of abuse, widening existing marginalizations, rife with abuses on the personal level (such as a vengeful ex), company level (such as usage of data without authorization), and on a national security level (misinformation, political inflammation even worse) and potentially criminal level (accusing/destroying innocent lives). <br/><br/>1) ML does not improve or create on its own. All it can do is remix and steal; especially on using engines like Google Image Search, or Adobe, it might not even be artists who consented to having their data and art used. ML/AI is the equivalent rather not of creation, but of taking two art pieces and swirling them together and then claiming it is an original work at BEST; at worst, even signatures of the artist are left in the pieces. This is not the same as an artist studying in museums or an artist trying to work out a pose or anatomy. Related to this, what about the people who have the data - like photos, artworks, etc - with that art being used without their permission? I have a friend who when trying to use a prompt AI, found out that the AI was scraping her own articles on live-action roleplaying without attribution or permission - she would not get paid for any use of them, and her contributions did not matter anymore. Likewise, in some states we have &quot;revenge pornography&quot; and &quot;stalker&quot; laws relating to nonconsensual sharing of pictures, for example with a couple who has broken up and one ex shares pictures given originally in confidence, or information like their address - with AI, that vengeful ex could easily use it to abuse their ex, putting words in their mouth, using their image or claiming the AI words as their own, scraping old photos and putting them into obscene situations, without any kind of recourse to the person whose photos were used. We know AI has a inherent-bias problem, we&#39;ve known this since issues with automatic hand dispensers and facial recognition. Do not let AI/ML be copyrighted, and only make these existing issues of safety, privacy, data, etc so much worse.<br/><br/>2) The second argument follows a bit from the previous example. We KNOW there have been issues of facial recognition not only likening Black people to monkeys or gorillas (offensive in itself) but due to the inherent biases of the training dataset, assumes that minorities must be criminals - and further compounds issues of &quot;assuming guilt&quot; with marginalized people. We know there have been issues of inherent biases regarding accessibility (also see the recent Department of Justice investigation on how accessibility already does not often get enforced even among federal agencies subject to the Rehabilitation Act and Section 508), we already know that there are inherent biases regarding sexism and racism (see Microsoft&#39;s attempts; see even the older example of automated hand soap dispensers not recognizing anyone darker than toast) - we know that these have been issues, but have done nothing to correct them. With the speed of technological improvements outpacing law, we cannot wait for more people&#39;s lives to be at risk - we also cannot risk the threats to national security, such as Facebook&#39;s investigation about election influences and such, which would only be intensified with AI use.<br/><br/>In conclusion, do NOT grant AI/ML produced works any kind of copyright. The old adage from the 1970s of &quot;a machine (computer) cannot accept blame, therefore should not make any management decisions&quot; is useful information in this case, because of just how many times it could go wrong - especially with the state of the Union so fragile already between attacks on our civil rights, the Jan 6th investigation, etc, we cannot afford to be so blase with data, things like AI-generated comments, AI-generated compromat, accusations, and even more risks to our civil rights. If it was ourselves, our free speech can have consequences; but an AI&#39;s &quot;speech&quot; cannot be so protected, because all it is, is code scraped from other places and it cannot deal with any consequences.