The threshold for human intervention in copyrightable works is extremely low<br/><br/>Imagine an artist who photographs sticks. They take a bunch of sticks and throw them onto the ground in a pile and then photograph the result. This is essentially a random process, largely outside the control of the artist. The resulting photographs would be copyrightable. The copyright is attributable to the photographer due to the acknowledged choices of tools used, composition, and post processing.<br/><br/>When an artist decides to create a work of art using a tool such as Midjourney they are immediately making definite and creative decisions. Just as a photographer selects their camera and its settings so does an artist using generative AI select their tool, and modify its settings. They then engage in a process of creativity where they supply an initial text description of their desired output and get a pseudo-random outcome. Even in the case where an artist selects the very first generation (a vanishingly rare occurrence) the artist has already made intentional decisions to craft their art in a specific way. Midjourney, for example, has a specific style to the model it uses. Other tools, like Leonardo.ai have other styles. Many generative AI tools, such as desktop gen ai like automatic1111 allow artists extensive control over the generation of works at the style, composition, and pixel level.<br/><br/>From well established precedent in other media the threshold for human intervention in a creative work to qualify for copyright is extremely low. The use of generative AI tools exceeds that bar in almost all cases.<br/><br/>Training AI models on copyrighted works is not infringement and is clearly transformative<br/><br/>There is no assertion that a student of art who views thousands of pieces of artwork in the course of their study is in violation of the copyright of the original artists. Such a claim would be both absurd on its face and create such an undue burden on students of art as to cripple the creation of new works. When a model is trained on works of art it is the same process. The result of this process is an update to the weights of a neural network (in many implementations). This is very close to the modification that occurs in a human brain when they acquire new knowledge and experience. This is clearly a transformative process as it takes in a vast amount of training data and produces a compact network which captures high level and abstract concepts such as symmetry, aesthetic quality, and emotional content. A network by does not substitute for any of the art on which it was trained.<br/><br/>Producing new works from a network trained on copyrighted works is not infringement and is clearly transformative<br/><br/>Many generative AI models are trained to map text descriptions to images. The text descriptions are often annotations provided by third parties and not the original artist. When you supply a novel text input to a generative ai model you get out a novel image. The image may bear a resemblance to real life objects, people, or artistic styles, but it is a distinct production. The training process of the network means that it has to learn abstract representations that it can use to produce new works. It does not contain an exact copy of every work it has ever seen. Learning abstractions and the means by which to take those abstractions, a source of randomness, and a target text prompt to produce an output is a large series of transformations. The result is that the output of generative AI models, even when trained on copyrighted works, are distinct new pieces of art which only superficially resemble their training data.<br/><br/>It is possible to force a model to produce an image similar to a training example. This ability does not constitute infringement.<br/><br/>Some gifted artists can, with great precision, reproduce works of art they have seen. To a lesser extent models trained on copyrighted works may be able to reproduce outputs similar to one or more of their training examples. This is not something that is easy to do. You cannot simply request a specific image from a generative AI model. You can get something similar but to get something which would *substitute* for the original work is extremely hard. Individual researchers who have managed to get such outputs actively guide the models on a pixel level, knowing what output they are trying to force a model to create. The resulting outputs are still of low quality, but sufficiently resemble the original works as to possibly be in violation of copyright. However, almost always you need to possess a copy of the original work of art to force a model to output something similar. This is akin to sitting an artist down with a copy of a piece of art and forcing them to make a copy. The artist may supply the skill, but the individual supplying the copy of the original work and actively requesting the output is the only party in violation.<br/>