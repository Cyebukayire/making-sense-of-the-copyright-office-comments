Please see the attached document to read my full comment, which is direct replies to the numbered questions your office provided. I will paste the beginning of it here:<br/><br/>I am simply a random U.S. citizen who likes to draw in my free time, but I am very concerned with the way applied statistics, or what has been inaccurately termed &quot;AI&quot;, has been developed. I&#39;d like to try and address some of the questions your office has posed.<br/><br/>1. My concern is that there is already a fundamental misunderstanding of generative AI systems in this very question - no one single human author can be attributed to any currently generated images or texts by AI systems, as their datasets have been based on large amounts of other individuals&#39; work, without their permission. The &quot;prompt&quot; process by which one uses AI is akin to the way an individual commissions an artist. When someone commissions an artist, they do not get to equate themselves to the artist, and they almost never acquire copyright of the produced work unless the artist has also sold the commissioner full rights to the commissioned piece.<br/><br/>For the second part of this question, there are already many companies looking to cut down on their staffing in favor of using AI systems (concept artists in China&#39;s gaming industry have already seen a 70% loss). So many people are losing their jobs to something that is 1) unethically built, and 2) inherently biased (to quote the Concept Artists&#39; Guild: &quot;Some of this data is the copyrighted work of artists and the private data of the public. As these models produce derivative works based on probability and statistics, they are prone to reproducing biases, stereotypes, and copyrighted works present within the datasets.&quot;). Additionally, many individuals are already feeling discouraged to enter into creative fields as a result of the increasing use of AI.<br/><br/>4. Italy banned ChatGPT and I think we should do the same for it and any other AI built upon datasets of stolen information and images. There have been photos from private medical records found in some of these datasets. We need to be a LOT more concerned with the way these systems utilize text and images that were never for others to take and regurgitate. We also need to be a lot more concerned with the average person&#39;s complete misunderstanding of copyright and fair use - many think it&#39;s fair game to use any image posted online, simply because it was posted online.<br/><br/>Here is an article on stolen medical records: https://arstechnica.com/information-technology/2022/09/artist-finds-private-medical-record-photos-in-popular-ai-training-data-set/<br/><br/>5. Yes.<br/><br/>6. I&#39;ll quote the Concept Artists&#39; Guild again: &quot;Images and text descriptions across the internet are gathered and taken by a practice called data mining and/or data scraping. This technique allows AI/ML companies to build the massive datasets necessary to train these AI/ML models.<br/>Stability AI funded the creation of the biggest and most utilized database called LAION 5B. The LAION 5B database, originally created on the pretext of &ldquo;research&rdquo; contains 5.8 billion text and image data, including copyrighted data and private data, gathered without artists, individuals, and businesses&#39; knowledge or permission.<br/>MidJourney, Stability AI, Prisma AI (Lensa AI) &amp; other AI/ML companies are utilizing these research datasets that contain private and copyrighted data, for profit. They did so without any individual&rsquo;s knowledge or consent, and certainly without compensation.&quot;<br/><br/>8. With how applied statistics models are currently used, there is no fair use. Any passable image produced by these models are almost always passable because they closely resemble an existing stolen image that was part of the dataset. There is a term for this that &quot;AI&quot; devlopers use, a euphemism: overfit. Here is an article on this as well: https://www.vice.com/en/article/m7gznn/ai-spits-out-exact-copies-of-training-images-real-people-logos-researchers-find<br/><br/>9. Copyright owners of works should definitely HAVE to opt-in before their work goes anywhere near AI. The default should NOT be opt-in.<br/><br/>9.3 I&#39;m sorry, but the practicalities of ethically acquiring consent from copyright owners is something that these businesses behind AI need to figure out. If their business model is impractical, then it&#39;s not a solid business idea and that&#39;s their loss. That shouldn&#39;t result in punishing copyright owners because we&#39;re not just forking over our work to whomever because they want it.<br/><br/>10, 11 - see 9.3.<br/><br/>12. Yes, again, &quot;overfitting.&quot;<br/><br/>13. Again, that&#39;s these businesses&#39; problem. Creatives, artists, writers, photographers, etc. deserve fair and equitable compensation for their work, which required skill to produce. It being expensive for an AI company to acquire licenses is the company&#39;s problem.