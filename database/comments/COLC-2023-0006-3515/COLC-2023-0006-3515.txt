I think organizations that are unable to clearly and completely demonstrate that they have a license for every single piece of data used to train a machine learning algorithm (like stable diffusion or large language model tools), should be severely penalized. The penalties should be a substantial percentage of the revenues of those organizations so that large companies cannot deal with such fines as &quot;cost of doing business&quot;. Doing otherwise enables large companies to ingest the unpaid labor of large numbers of individual citizens without compensating them and then profit directly off of that labor. Not to mention the potential privacy nightmare, the unethical treatment of workers during training and the environmental cost during training and after.<br/><br/>As for whether the output of machine learning algorithms should be able to be copyrighted (assuming the above demonstration of license for such use can be met), I think that the answer is simply &quot;no&quot; until such time that we are willing to entertain the possibility of machine sentience, personhood and citizenship (which I think it risibly distant and possibly not even technically related to existing technological approaches). The parallel that works for me is this: If I wrote a piece of software that took a very large number and converted that into an image (the same number would be the same image every time), and someone else wrote a piece of software to generate random large numbers, and a third person wrote a tool that fed the numbers from the latter into the former... a fourth person who generated a random image repeatedly until they found one they liked has not really done anything unique or interesting. I think there are also substantial questions about &quot;transformative works&quot; that our current legal infrastructure is not equipped to handle at the scale that, say, stable diffusion is prepared to output. The rules of &quot;fair use&quot; are reasonable when applied to the actions of an individual, but the costs of applying those uncritically to the mass output of machine learning algorithms are too high to ignore.