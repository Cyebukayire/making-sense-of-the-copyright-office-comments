I have grave concerns about the use of AI generated content. I do not believe AI generated content should be protected by copyright. AI models are based on data collected from humans, largely without explicit consent from the original sources of that data. Protecting AI content sanctions the automated theft of content, including copyrighted work, of humanity at large. We should be protecting the work of humans over work created by imitative, predictive, automated systems. AI generated content should be flagged for immediate identification so people can choose to engage with it, filter it out, or simply recognize where their information and entertainment are coming from. <br/><br/>I have additional concerns about the use of AI generated content for misinformation, market manipulation, and the potential for AI content to crowd out creative and original work by humans. I am concerned this will damage public trust, social cohesion and communication, and worsen the living conditions of people who will be priced out of markets and economies centered around creative human endeavor. Art, such as music, film, painting, literature, etc., are valuable because of the humanity inherent in those efforts. AI generative art poses a real threat to individual humans and groups trying to make a living in those fields. We should protect real human efforts over AI, especially in fields traditionally concerned with communicating ideas around the human experience and imagination. <br/><br/>AI generated material used for scientific ends, such as identifying molecules for specific applications in medicine or designing forms and systems for efficient energy production and conservation, should be freely available for public use. AI is trained on the efforts of humanity as a whole population. The medical, engineering benefits of its use should be shared with that population, not locked away behind copyright ownership. <br/><br/>I am also concerned about the methods of training AI being susceptible to bias. There is a lack of transparency around what data is used to train many of the current systems. There is a lack of transparency about how current systems generate specific responses or how input data is weighted or used in those responses. This lack of clarity in product generation and lack of clarity in possible faults or omissions in data input for training means AI is likely to be used to create harmful results or results that lack equity for minority groups, or even just groups outside of the architects of each system. <br/><br/>I find the idea of scraping the cultural output of humanity to train systems for profit deeply upsetting. It is immoral. These tools should be trained with a great deal of transparency. They should not be protected by copyright. They are built on the work of all of us. Their output should belong to all of us. It should also be clearly identified for what it is so people can prioritize human work over machine generated productions based on human work. 