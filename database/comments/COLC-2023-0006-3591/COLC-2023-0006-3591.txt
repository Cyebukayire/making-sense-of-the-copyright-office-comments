while i&#39;m not a US citizen i feel very strongly about AI. and how important it is for copyright laws to catch up to it, as it allows easy theft of copyrighted materials and an even more harmful re-creation of a persons voice without their consent. allowing for more sophisticated AI&#39;s to make a 1x1 replica of a persons voice and speech manerisms. which can be harmful and dangerous should the person using the AI wish to create derogatory or slanderous materials (as an example. getting the president of the united states to say something extremely harmful to minority groups)<br/><br/>my hope is that. should the US make moves to protect people from the abuse of AI art, and allow jobs, persons, and groups to be protected from its commercial use. the rest of the world will follow these laws, and hopefully establish an international copyright law to prevent AI art, voice cloning, music, ect. to be used commercially and/or publicly. while many use it as a way to make jokes, or media characters/real people sing their favourite songs. its only a matter of time until someone uses it to spread rampant misinformation, and for bad actors to use it to have important figures spread hatred, racism. bigotry. and possibly even use it as a way to start fights. as AI is already at the point it can re-create voices perfectly, should someone pose as a whistleblower or &quot;leaker&quot; and have an important figure say something insighting hatred or violence against groups nations or peoples, it could cause serious issues. should there be no way to verify if its real or not<br/><br/>AI is a powerful tool that could strip people of their jobs as well, we&#39;ve already seen during the strike period of SAG-AFTRA that companies have used AI to replace the people that are striking so they can continue to make a product. i don&#39;t believe i need to prattle on about how dangerous a slope that is<br/><br/>i hope that. despite not being a US citizen, my comment is considered valid still. as AI affects all of us on an international scale