To be able to create something, specially images with AI, you need to have a gallery of examples and associated them with keywords, people have done AI that replicate the style of artists and it&#39;s obvious because they have to type the name of the artist as a keyword, this is normally done without their consent, and what took them years of work to accomplish is just taken away from them in almost an instant because the model of AI is copying them, it&#39;s not that different from someone replicating a style and later saying the artist with that style did it and try to make profit out of it; this also applies with voice, one of the things we use to rely to identify if it really happened, a screenshot or image can be edited and sometimes traced back to origin but something like audio we&#39;re used to it to be something really true, only a really good imitator could fool voice.<br/>AI is a tool, it can be really useful to iniciate an idea and polish it on your own, to give it the personal touch the one creating has, when the AI is just being a bit to perfect, we will have a lot more problems identifying what&#39;s really true and what&#39;s fabricated, people could get discouraged to try and create new things just because there&#39;s an AI that does something like that and it&#39;s instant, but if you want something that maybe the AI have not been trained to, you will need something to reference to and that&#39;s relies in the creativity and ability of people, that most likely wouldn&#39;t help you if later you are going to use their work for AI training.<br/>That&#39;s just on voice and art, in the voice models sometimes could enter evidence in court that it&#39;s jeopardize just because of this, now looking at models that create you text have something interesting, the AI of Bing tells you references from where its getting some information, something we have been told to do when investigating for a school project, and that&#39;s a good thing, it really works like a tool, giving you easier access to the information you want, it something sounds weird you could look up and confirm it with the reference, the AI of ChatGPT that was public and a sensation some time ago didn&#39;t do this, and AI it&#39;s not perfect we know sometimes it just fails to relate somethings and creates false information that does not even try to tell you where it got that idea, in school in research we were punished if we told an idea and not have evidence to backup it, or just not citing well , careers have been damaged for not citing your own previous paper correctly in your new research, like the president of the university of Aizu in Japan, a relatively recent incident.<br/>If in instances where there&#39;s a physical person that&#39;s going to be punished for not citing correctly, using something without consent of the owner, replicating something or fabricating false information why, in the cases where it applies, when an AI is doing something that technically is that not seen has that?  