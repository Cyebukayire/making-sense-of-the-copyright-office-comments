Lots of folks misunderstand AI to be a type of technology that has the ability to read, understand, and generate thoughts. That&rsquo;s not technology; It&rsquo;s magic. All AI can do is process whatever it is fed and spit it back out. This creates a number of concerns, of which I believe two are the most important: <br/>1. Privacy/transparency: we live in a digital age. Our faces, names, and other important information are often publicly available. There is a serious risk to personal privacy and safety here, especially for minors. Should anyone who has seen a picture of me digitally be able to put my face on any image/video? Should any person I have ever called be able to make my voice say any combination of words? That&rsquo;s how we end up with things like deepfaked revenge porn, or falsified information coming from the mouths of deepfaked public officials. How can we protect ourselves against that?<br/>2. Stolen work: AI has to be trained on something. As artists, writers, and actors around the world have repeatedly noted, these engines are often being trained on their work, without their permission. It&rsquo;s theft. In the case of corporate-owned materials, it&rsquo;s also a copyright issue. It has to stop.<br/>The risks are serious and numerous enough to indicate that AI needs to be regulated. And the companies that profit from AI have already proven that they can&rsquo;t effectively regulate themselves, or else we wouldn&rsquo;t be facing the threats previously mentioned.  I do believe there are some ethical use-cases for AI, but I&rsquo;m mostly, I fear that if we do not make every effort to firmly and fairly regulate this technology now, we will rapidly descend into a future where even things as personal as our art, faces, and voices no longer belong to us, and once that barrier is crossed, how could we ever go back? 