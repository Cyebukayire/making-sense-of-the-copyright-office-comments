Greetings.  We were previously in an era where protecting your ideas, your ip, was difficult and expensive, and only realistic for the rich.  First you have to purchase the protection, which is both expensive and time-consuming (time is money), and then you have to defend the rights this investment has granted you, which is usually even -more- expensive.  For these reasons, the wisdom on the street was that the only way of effectively protecting ideas was industrial secret.  This is not, was not, will never be a constructive state of affairs when one must publicize ones work in order to get noticed.  AI has made this situation 100x worse.  Now it isn&#39;t enough to worry about either your idea going viral or just somebody happening accross your work and steeling it.  Now, you have to worry about automated bots scouring the web and taking everything and bundling it into computer software.  So it isn&#39;t a &quot;maybe&quot; somebody will take the work, it&#39;s a &quot;for sure&quot; somebody will take it, and it&#39;s only a question of the frequency at which this data is collected.  For all I know, it could be continuous.  That the moment I put something online, it&#39;ll immediately get snatched up.  So now, nobody benefits from my work.  I believe it&#39;s of immense value, but I don&#39;t share it.  It&#39;s a big shame.  A colossal shame.<br/><br/>Then there is the question of whether people should even be using these programs at all.  The idea being that things -shouldn&#39;t- be too easy in the first place.  That if something is too easy, it cheepens the whole thing.  I agree with this stance.  Now, I&#39;m writing my own code.  I plan on incorporating ai into it eventually.  The way it will work is that people will make decisions as to what they want it to produce, and it&#39;ll produce it.  Or they&#39;ll tell it to use a random number generator and see what the result is.  One way or another, parameter space will be explored.  As it is explored, the user will tell the computer which results they like, and which they don&#39;t.  The computer will build a map of what is desired.  Somewhere in there will be a deep learning algorithm.  The difference being, the users will use the algorithm to generate all the training data, so it will be fundamentally different from the ones currently under contention.<br/><br/>Even then, who gets credit for the result will be uncertain.  Will it be the person using the software, or the person who wrote it?  In my case, I, the person who wrote it, should take the majority of the credit.  Because I will have made it very easy to create a given type of thing. So for a given thing produced using it, there will have to be two authors, at least:  Myself as primary author, and the user as secondary author.<br/><br/>If a new technology does not have a -net positive- impact on society, it wasn&#39;t worth the effort to devellop.  AI currently fits in this category.  It has brought some benefits, but the negatives out-weigh the positives.  I can think of many many amazing things that could be done with ai that would bring huge net positive impacts.  I can&#39;t believe I&#39;m alone in this.  Most of them being doing tasks that -can&#39;t- be done today except with ai, like medical research, and providing much more of a given product that is needed but there isn&#39;t enough of it.  But taking away work from artists isn&#39;t it.  I refer you to noam chomsky for further commentary.