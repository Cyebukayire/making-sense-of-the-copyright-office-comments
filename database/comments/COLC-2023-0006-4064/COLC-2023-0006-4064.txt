Copyright was made to protect human beings from being exploited - from their labors and creative expression being stripped from them in order for others to profit. AI is neither human nor a program capable of creative expression - there is nothing that AI can express creatively; AI can express the mathematical similarities between all of the stolen training data that it works with, and not intention, message, or skill. Generative machine learning cannot see beyond the boundaries of the content it is given. It can only output an approximation of the various works it has already been given to train on (most of the works, due to the sheer volume of training data required to make a passable AI experiment, uncredited + stripped from their original contexts and authors). Generative machine learning models as we currently know them in their most popular states of being (OpenAI, ChatGPT, Stable Diffusion) depend on the very exploitation that drove copyright to be enforced in the first place. The usage of existing pieces, copyrights, and materials from human artists for machine learning training materials should be &quot;opt in&quot; rather than &quot;opt out&quot; - an artist or creator should be required to enthusiastically consent (and be able to withdraw that consent at any time), rather than deal with what would end up being a purposefully costly, annoying, and near-impossible &quot;opt out&quot; experience.  If it isn&#39;t feasible to gain consent to use someone else&#39;s copyright in the training of a machine learning/AI algorithm, then the piece or media should not be used. We have seen this judgement in other sectors that involve the use of copyright an individual (or company, corporation, or representative) does not own; it is reasonable to assert that if consent is not gained then the copyrighted media cannot (and should not!) be used. 