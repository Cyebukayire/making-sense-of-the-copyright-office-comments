The way Generative AI (including Bard, ChatGPT, LLAMA, etc) functions is that it interprets a initial prompt (i.e. a question or request), and then word by word formulates a response based on keywords or phrases that were contained in that initial prompt.  And the individual words, and punctuation, that are returned by the AI are chosen by mathematical probabilities of what the next word or punctuation should be in relation to the words proceeding it based on typical sentences that it has been trained on - that are related to the referenced keywords and phrases in the original prompt.  Meaning, generative AI would be unlikely to &quot;word for word&quot; copyright infringe a single source without being prompted to do so because it has likely been trained on topics using a wide variety of sources - basically, it will have more words and phrases to choose from that essentially mean the same thing because the AI has been trained using multiple sources of individual topics, that are most likely all mildly different and written in different styles, etc, and any word for word snippets that appear in an AI response are most likely coincidental. In comparison to an AI reponse, if you use a search engine (like Google), exact snippets of words on websites (like New York Times news articles) will appear in the search results &quot;verbatim&quot; as they appear on the web site - which is what would actually qualify as copyright infringement.  Even in an organization like the New York Times for example, there may be multiple authors who work for the New York Times writing about the same topic who will have different writing styles and differing intent/opinions/etc, and other news outlets like USA Today, Washington Post, Associated Press, etc and even podcasters, blog writers, social media influencers, etc also writing about the same topic.  So an AI that has been trained using this wide pool of data is unlikely to copyright infringe on any individual source.  It may be worthwhile to have the AI cite sources in its response and link to originating source material used to generate a response, but in many cases, the citation list generated could be pretty huge.  Conversely, there may be certain topics where there is literally only one single source of information - and in that scenario, a likelihood of verbatim copyright infringement might be more likely, but I can only see that being related to specific scientific papers where there is only one person or team working on very specialized groundbreaking research that they published one paper that was used as a source material for training the AI - or similar circumstances.  Current events, for example, being public already, and reported on by a wide variety of sources, and the AI being trained using those multiple sources, would not be likely to copyright infringe any single source.  In conclusion, AI would probably use common turns of phrase or make the same guesses of combinations of words that might appear in part of any arbitrary article. But, those coincidental chains of words would also likely be made by any human in most cases.