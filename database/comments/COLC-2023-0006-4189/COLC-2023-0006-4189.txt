I think that AI generated content should be copyrightable, with some caveats:<br/><br/>For models which have been trained on public data that has been scraped from the internet, and for which it is unclear what, copyrighted content, if any, has been encoded into the model&#39;s weights, outputs from the model should only be copyrightable in the event that they have been significantly modified by a human, such that it ceases to resemble the original output. For example: someone generates an impressionist painting of a street, and then edits all of the street signs to read a specific message, or turns it into a lyrical music video with the street signs displaying the lyrics of their song.<br/>Examples of these models include: <br/>- OpenAI&#39;s GPT 1,2,3, and 4, <br/>- Stability.ai&#39;s Stable Diffusion, <br/>- Meta&#39;s Llama 1 and 2, <br/>- Google&#39;s Bard, <br/>- Most other models in existence including fine tuned derivatives of these models.<br/><br/>On the other hand, models trained on privately/consensually sourced data&mdash;where it is clearly defined who the copyright holders are, and that they knowingly and willingly contributed their works to the dataset&mdash;should have their outputs be the property of the creator of the dataset. This could allow the model owner to do with the outputs whatever was previously agreed upon between them and the copyright holders of the source data, in particular: licensing the models, or its outputs, for commercial use.<br/>Examples of these models include: <br/>- Adobe&#39;s Firefly (which is trained off of Adobe stock imagery), <br/>- Any future models trained on a dataset which has either been created from data given with the intent of it being used for that dataset/model (and in some cases, the original copyright holder may be given payment in exchange, as is the case for the adobe stock imagery used to train Firefly), or data that has been obtained through an agreement that grants the dataset creator royalty free rights to use the data commercially, or as they please. For example: Meta collects user data from Facebook or Instagram and, due to the privacy policy giving them a broad license to use the hosted data for their own purposes, they have full rights to use that data commercially.<br/><br/>It is likely impossible (within the bounds of the first amendment, at least) to stop people from using or creating models trained on public data, and as these models improve it may become impossible to even tell if they are AI generated in the first place. In cases where it is impossible to prove, it may become irrelevant whether it is AI generated. It is not clear to me what can be done to remedy this, especially with the existence of open source models or models trained in other countries where the government cannot simply say that all models must contain some sort of watermarking system that cannot be legally removed (not that I think enforced watermarking is a useful or constitutional solution in the first place).<br/><br/>I also propose that another possible remedy to the problem of AI art copyrighting may be to consider the parameters used to generate AI content as protected intellectual property. For image generation, this might mean:<br/>- The prompt used<br/>- The model used<br/>- The LoRAs, hyperembeddings, etc. used<br/>- the CFG scale and other misc. parameters used<br/><br/>As these parameters are all determined by the user, they remain the main element of human creativity in a given AI-generated work. The government might also allow IP owners to send DMCA requests to people posting content found to be generated with a prompt containing, for the example, the name of their IP or prominent elements from it. For example: Disney sends a DMCA to a user because they generated an image with a prompt that contains &#39;darth vader&#39;. <br/><br/>They might also send such a DMCA to a user who posted content that, beyond reasonable doubt, appears to have been generated using a copyright-infringing prompt, but for which they did not publicly post the generation info. However, I fear that this could lead to abuse of the copyright system, with large organizations using this as an excuse to bully individual creators&mdash;Disney sees a sci-fi movie made by an art student and posted to their portfolio and DMCAs it, claiming that it &quot;might be AI generated and might have been created using Disney intellectual property&quot; when actually it was made by hand and features no elements of Disney copyright. The art student could legally fight it, but if it costs them money to do so then it is more likely they fold to Disney&#39;s will and take it down. Considering this is something that already happens without AI coming into the picture, care must be taken to protect individuals as much as larger copyright holders, and so these things should be carefully considered by people far smarter than I am.