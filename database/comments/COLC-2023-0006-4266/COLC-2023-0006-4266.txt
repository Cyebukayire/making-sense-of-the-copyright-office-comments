The use of AI to generate content necessarily requires the theft of others&rsquo; intellectual property. It is plagiarism under the guise of technological innovation. Most times, the works used to generate AI content is done without the original creator&#39;s knowledge or consent. If public domain/license-free content was all that was used, it would be seen in a better light. Another instance of ill intent: the use of AI to create false images to maliciously spread misinformation, whether it be about wildlife or news.<br/>As is currently, developers of AI models typically scrape from art and writing from indie creatives and regular people (eg: Twitter/Pixiv/Weibo for art, Archive of Our Own for writing), people who had never provided consent to said scraping of their intellectual property and were given no prior knowledge. Creatives should not have to fear their work being scraped and being transformed in a way that is out of their control. As such, AI work should not be eligible for copyright as it currently is created (through the theft of other&#39;s intellectual property). And if someone tried to, the works that were used to generate the work should be equally compensated, seeing as their efforts were stolen to mash something together.<br/>If one wanted to monetize works that use AI-generated (really, &quot;machine taught&quot; is the more appropriate term for this, intelligence implies it is learning it on its own, and not being fed works from other people) creative content, the database of art that was used as the foundation for the AI tool&#39;s ability to generate art should only contain pieces that are in the public domain or have been given freely or licensed by the artists.