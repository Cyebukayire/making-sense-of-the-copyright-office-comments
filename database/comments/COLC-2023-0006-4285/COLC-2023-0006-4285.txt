I know enough about how generative AIs work to know that if they&#39;re trained on copyrighted material, there is absolutely no way to guarantee that the AI won&#39;t accidentally plagiarize that material. Because of this fundamental reality, there is a strong possibility that generative AIs effectively become &quot;launderers&quot; of copyrighted material &mdash;&nbsp;where neither the user of the generative AI, nor the AI&#39;s owner, are necessarily aware that copyrighted material is being copied. In fact, it&#39;s entirely possible that both the user and the owner of a generative AI want to remain willfully ignorant of any plagiarism that might be occurring. But most importantly: AI users and owners almost certainly do not want to be legally *liable* for copyright infringement committed in this way. Generative AI users and owners will want to be able to claim that &quot;the algorithm did it&quot;, and therefore no one should be liable. Taken to its logical conclusion, it&#39;s entirely possible that generative AI&#39;s potential for copyright laundering &mdash;&nbsp;and the potential lack of liability for it &mdash;&nbsp;is actually its most valuable feature, rather than anything inherently novel about the technology itself. For this reason, it is critical that generative AI&#39;s MUST be trained on material for which they have legal consent, and that the owners of generative AI&#39;s are legally liable for any &quot;accidental&quot; copyright infringement their AIs might commit. Under no circumstance should AI owners be allowed to avoid liability or offload it onto their users or other parties &mdash; especially when their training data is not publicly available and auditable. Thank you for your consideration.