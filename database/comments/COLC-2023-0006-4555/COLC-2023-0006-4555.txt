Let me first say that it is my firm opinion that the copyright office is correct in its current position with regard to algorythmically generated content, whether image, written word, or other format. That is to say that because there is no human authorship, the text cannot be regarded as copyrightable as copyright in principle exists to protect the rights inferred by authorship. If anything ought to hold the copyright, it is the algorythm which produced the image, and algorythms are not a people with the legal right to do so. This is as I understand it is the current position of the copyright office and it is correct in its assessment.<br/><br/>Moving on from that, it is my strong opinion that regulations in the field of so-called artifical intellegences, that is enrealis machine learning algorythms, are frankly about a decade and a half over-do. We should have figured this out and had basic regulations in this sector locked down in 2010, or 2015 at the latest, and the current state of affairs is because we&#39;re late to the party. The regulations I&#39;d most like to see would look at the methodology of acquiring training data, including the informed non-coersive consent of individuals whose information or work is included in that training data, as it relates a moral argument for whether a model trained on sed data should be allowed to legally opperate commercially.<br/><br/>That is to say, all data used to train any given model should be:<br/><br/>1. Publically auditable. The computational requirements for training a machine learning algorythm on petabytes of data are cost prohibative enough to protect in-sector interests against copycats.<br/>2. Have the informed consent of each and every individual whose creative work or image appears in the training data.<br/>3. Compensate each individual who has consented to their work or images being included in the training data whenever a model trained by them is used, similar to the hollywood residuals system works.<br/>4. Be lethally poisonious, such that if any one data point in the training data is deemed in violation, every model trained up on that poisoned dataset, including models based on poisoned models is deemed in-volation and be compelled to start over or exit the sector. Training data once intergrated into the system cannot with our current understanding of mathematics be disentangled from the algorythm. If unconsented data was used the only feasible option to adhere to the above standards is to start from scratch with the offending data removed.<br/><br/>These opinions are based on my deep understanding of how these models work, and how they currently opperate primarily on the industial-scale theft of publically posted but commercially unavailable copyrighted material with no compensation granted to the creatives whose skill and labor undergird the data which drives the endevorer.<br/><br/>Furthermore, I believe there should be regulations in place which seek to limit how much computational power can be used when training and opperating these algorythms, as a non-insignificant amount of power and water goes into training these machines learning algorythms which are crunching petabytes of data through, at a functional minimum, 20,000,000 variable calculus. That scales up quickly and shouldn&#39;t be hand-waved as happening &#39;in the cloud.&#39;<br/><br/>Lastly, I believe that there should be regulation regarding the end user&#39;s use of these algorythms. Because these algorythms as tools massively increase the potential for harm caused by misinformation, I believe laws should carry stiffer penalties if these algorythms are deemed to have been used; similar to how &quot;assualt&quot; and &quot;assualt with a deadly weapon&quot; are distinct charges in many jurisdictions.