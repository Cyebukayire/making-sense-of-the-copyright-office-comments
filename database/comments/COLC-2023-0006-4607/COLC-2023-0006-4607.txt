I am an author and artist who disapproves of the current widespread training of neural networks and deep learning programs on unlicensed creative works that remain protected by copyright.<br/><br/>Creative works should be accessible to the public, both to experience and to draw from for their own works, and I believe strongly in the fair use doctrine; but generative neural networks (henceforth &quot;AI&quot;) do not, to my mind, constitute fair use of copyrighted materials. I am against the effective theft of the creative labor of thousands or millions or artists (the amount necessary to properly train an AI to the point where it can respond to prompts meaningfully) for the benefit of a tech company&#39;s profits. Artists, whatever their medium, deserved to be compensated for their work, and that especially applies if the work is being used en masse to develop a program that the developer intends to make their own profit from. The use of artwork for AI training is not comparable to individual artistic use of copyrighted materials that may (and should!) be permitted under fair use, because neither the AI nor the developers who create it are creating artistic or educational materials--rather, they are creating a program that could not exist without the work of the artists, and that does not creatively transform the work it&#39;s using, treating it rather as raw data for the program to process as its training.<br/><br/>I am also concerned about the lack of oversight about whether private or sensitive information is included in the datasets that AIs are trained on. So far, there is no standardized way for anyone to opt out of having images that they own or that depict them used by AI developers; it is not reasonable to expect artists, who often rely on an internet presence to sell their work, to simply not allow their work to be hosted online or indexed by Google or other major search engines; it is also not reasonable to expect that every person who posts an image on social media but does not want their personal images to be used for training AIs to take action to prevent that. Individuals need a way to protect their work and themselves that doesn&#39;t put the onus the individuals, who may need to trawl through datasets of thousands or millions of images (to say nothing of text used to train AIs), to enforce their copyright against companies that should not be using copyrighted work or images of individuals without permission or legal release to begin with.<br/><br/>Furthermore, there is also a concerning lack of accountability with regards to private data being used and sometimes published as part of these datasets--for example, private medical imagery was found in the LAION dataset (arstechnica, &quot;Artist finds private medical record photos in popular AI training data set&quot;, September 2022) and, due to the fact that the companies using the datasets are not the same as the companies collecting them, and neither of those are responsible for the hosting of the original images, there is almost no recourse for the people whose medical imaging was exposed against the actual users and publishers of those datasets. AI development requires massive amounts of data and that data needs to be regulated to protect both the intellectual property and privacy of individuals.<br/><br/>In short, AI could not exist without artists, and we need to ensure that, in its race to become profitable ahead of any regulation, AI does not wind up damaging the very field it relies on. AI developers, and the companies which collect and publish data training sets, should be required to get permission from the copyright holders of copyrighted works they wish to use as training data, the same way any other publisher who wishes to use creative work as part of their own business is required to do.