Hello! My comment is regarding AI&#39;s use in creative work and scientific advancements. <br/><br/>Regarding creative works: If people want to use an artist&#39;s works to train an AI model, people who seek to train a model should be seeking permission First on a per-creator basis for 100% of their datasets where inputs are not first party. Individual authors should retain rights to their work. The would-be AI generated work is still taking their work verbatim for input and using it to put out what, ultimately, is a combination of other people&#39;s work. Being a combination of other people&#39;s work, especially copyrighted work, there is nothing here that the AI &quot;created&quot; on its own - it simply mixed together real inputs in a way that looks coherent. These usually have to go through iterations of human approvals and revisions before being put to use especially with the public and business partners, that&#39;d also mean the output had to look convincing and satisfactory to someone enough to green-light its release. Then at the end-user level, when a prompt is provided - regardless of how many prompts are given for the request - the result will still be a combination of real works, the prompts given simply influence which works from the dataset would be used for its creation. The real work plays an important role at every step therefore those works&#39; original rights holders should be credited for their contributions; permission to use non-first party works should be agreed upon explicitly before their input into a database for commercial use. <br/><br/>I am not against platforms where people are invited to submit their works willingly for the creation of a 1P dataset where the platform owner(s) and its contributors all have an explicit mutual agreement where consent&#39;s concerned. I am also okay with arrangements where a studio and all of its contributors - where their works and likeness will be used for inputs - have explicitly consented to having their works or likeness used. This should not be a decision that&#39;s made on their behalf at a higher level, and the resulting work should not be viewed as an &quot;original&quot; where copyright is concerned regardless. If there are any parts of the dataset that were copyrighted, then copyrights already exist where applicable. Where first party datasets are concerned, the inputs may be copyrighted and be referenced collectively in the resulting material. The resulting material may not be copyrighted alone as nothing was &quot;created&quot; without human input. <br/><br/>Regarding AI in health and science: Here I have seen how AI can help identify patterns in data researchers haven&#39;t been caught onto yet, and I think work in this area is generally okay where ethically sourced and used first party data is concerned - in a similar sentiment on the previous point, I would not agree with something like a company collecting people&#39;s DNA/biometrics/health data and selling access to it for training models without the individual giving their explicit consent with this being an opt-in scenario where it is not done by default, and no consequence or degradation of service would occur to that individual should they deny the request. <br/><br/>Given that physical samples would have to be collected for building a health data dataset, I would consider that &quot;human input&quot; and view that as a collective first party dataset they could use in their models and to assist in training third party models, but the person who would be used for input has to have consented before its input into a database with the intention to use it for training and if it is to be sold by any of the third party buyers for purposes beyond its intended use, the original person should be solicited for consent before trading hands any further.<br/><br/>For scientific work, I will let people who on the health and science industry side of this discussion speak to that from experience! As someone who&#39;s not a scientist, I do think that AI has its place on the research/computational side of things but papers should still be authored by humans who have vetted the AI&#39;s results. AI outputs should always be verified before accepting them as fact. 