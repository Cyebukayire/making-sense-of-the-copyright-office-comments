As a Vice President of Compliance for a medtech company who also happens to be a fantasy author represented by a well-respected literary agency, I have a somewhat unique perspective on the issues being posed by the Copyright Office. I appreciate the opportunity to address them. <br/><br/>As it relates to the use of copyrighted works to train AI models, I strongly urge the Copyright Office to promogulate regulations prohibiting training of AI models on copyrighted and copyrightable works without proper license and/or payment. Especially as it relates to generative AI, this is a deeply concerning problem to the literary and artistic communities, groups of people who are overwhelming underpaid and underresourced to begin with. Marginalized voices in these communities who have been adversely impacted for generations by systemic problems within the industries involved are further injured by these practices. Bias in tech has long been recognized, but it exists also in publishing and the black boxes of deep learning are deepening these divides even further. <br/><br/>The reach and impact of these unethical training practices is far. While the argument might be that these programs like ChatGPT and the like are offered for free so there is no commercial use, we all know that capitalism and code is a living, breathing thing. These open source base LLMs are being used to create chatbots across every industry. The bots learn to speak human by eating swathes of copyrighted and copyrightable work they did not pay for, then that code is used to train a bot to say particular things about a particular product using a singular tech company&#39;s data and that tech company can profit off that and still feel good about it because they didn&#39;t &quot;technically&quot; infringe. They trained the bot on their data which they obtained legally via license or partnership agreement or otherwise, then they upcharged for a new feature. What happened before the LLM code got to them to teach the thing to sound human is not their concern. <br/><br/>It is mine. And it should be the Copyright Office&#39;s as well. On a personal note, it took me 20 years to get a literary agent. A college education. Thousands of books read. Seventeen books written. Millions of words. It isn&#39;t a single book. It&#39;s decades of knowledge in every book. Decades of free labor. Decades of dreams. Stolen by a robot, eaten, spit out, then capitalized on by thousands of nameless companies across hundreds of industries. The harm is immense and incalculable. It has to be stopped before more damage can be done to an industry where the median income is already only $23,000 a year (https://www.npr.org/2023/07/17/1187523435/thousands-of-authors-urge-ai-companies-to-stop-using-work-without-permission). <br/><br/>As it relates to authorship, I believe the Copyright Office should maintain the position it has historically maintained as it relates to AI and that District Courts are upholding as well: AI cannot be an author and thus cannot hold a copyright. Nothing produced by AI should be copyrightable. How are we to determine authorial intent (as in Andy Warhol Foundation for the Visual Arts, Inc. v. Goldsmith) if the author is an algorithm? On a practical note, what slippery slope does that lead us down when we start saying AI can copyright? What other legal rights does it then have? Is it entitled to payment? To a lawsuit? To open a bank account in its own name? We have human beings living in this country who can&#39;t do those things but we are debating allowing a machine to do them. <br/><br/>Again, I point to the disparity in income between author and programmer. And the purpose of the Copyright Act which is to promote the arts and sciences and encourage people to create new work for the benefit of the public. What benefit is it to the public to take the making of art away from artists and hand it over to programmers? What harm does this do to marginalized groups who are massively underrepresented in publishing and the fine arts, yes, but even more so in STEM? So underrepresented that some AI doesn&#39;t even recognize black faces in facial recognition software? I am unsure we are at a point where we can trust our art, our future, our public with these algorithms yet. Working in medtech, I know we are not trusting them with our PHI. Our genetic stories. So why would we trust them with the ones that create a culture?  <br/><br/>Finally, I will note that as it relates to liability, I believe the tech companies who are blatantly data scraping and training AI on content they know to be copyrighted or copyrightable to train their models should be held to account for the damage they&#39;ve done to the authors and artists whose works they&#39;ve stolen to make their creations a little more human using the fruit of those people&#39;s collective experience. <br/><br/>Thank you for your consideration of this comment. 