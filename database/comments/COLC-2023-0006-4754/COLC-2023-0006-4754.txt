In my opinion, the process of AI training is not comparable to the process of copying data, it is a derivative work at best. As such, all data that is publicly available (e.g. on the internet but, if feasible, other data sources even offline data sources such as physical libraries) should be generally allowed for training AI models. If a specific data source has special concerns, an opt out mechanism like what OpenAI is already doing in their GPTBot, respecting the robots.txt file on a given web page, is sufficient.<br/><br/>Now in regards to the copyright situation with outputs of artificial intelligence. I wouldn&#39;t treat AI much different from other advanced software tools, just because it&#39;s different from tools that previously existed. If a human generates a unique enough output through a clever prompt, a long selection process (same prompt but many regenerations) or even through training models (including techniques such as LoRA) it is copyrightable like any other work that was created simply using an advanced tool. AI isn&#39;t much different from simply a fance typewriter or Adobe Photoshop in that regard. As such, naming an AI system as an author or co author is not valid. The author of a work is the human or organization that operated the AI system.<br/><br/>If an AI model generates a sound, image, video or text that is too similar to an existing work I would also treat it exactly like if a human created this copy by hand. Is it too similar? Then it might be copyright infringement/plagiarism. I would place the burden or making sure that this is not the case on the users of AI tools. If these tools are used to create commercially used content, then these tools should not be treated as toys and a high degree of responsibility placed on the users of these tools. In other words, accidental copyright infringement through AI should not be excusable and it is negligence on the user&#39;s part.<br/><br/>Even if the output of an AI system that runs completely autonomous may not be copyrightable because it wasn&#39;t working off of human input, I would still say the person or organization operating the AI system is responsible for all copyright infringements and other damages that result from the operation of the system and not AI system itself or the organization that created the system.<br/><br/>To help users with avoiding accidental copyright infringement and making adequate decisions I would at least recommend that future AI systems do incorporate mechanisms to allow a user to see a list of references on where the newly generated content was sourced or inspired from as well as other audit mechanisms. The more autonomy these systems may gain in the future, the more we will need those mechanisms. I am not sure yet on how these should work, but it&#39;s something that should be mandated from a lawmaker&#39;s side in the future.