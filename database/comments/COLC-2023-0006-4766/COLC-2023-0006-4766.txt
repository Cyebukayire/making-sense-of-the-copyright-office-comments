Hi folks!<br/><br/>I both work within an industry heavily reliant on the production of art and art assets, and participate casually in a community with a huge focus on digital art production. I&#39;ve seen firsthand both the economically productive use cases for AI-generated artwork as well as the impact it&#39;s had directly on the people whose livelihood depends on it. I myself have worked with generative AI models to see what results I could generate as well as how much effort was involved in their generation, and likewise have spent a good amount of time with text-based models to observe their behavior. What I can say is this:<br/><br/>1. The majority of AI model output is exceedingly reliant on the material on which it was trained and is not meaningfully transformative. The primary reason this conjures any doubt is a lack of familiarity with the original source material. A human reasonably familiar with this material can often readily identify the original source(s), but the sheer scope and scale of the material used to train models is typically prohibitive for any single individual to recall. This applies to art and written works alike.<br/><br/>2. The effort required for the generation of tacitly novel material is significantly smaller than typical human participation. It is reasonable to think of this more as &quot;producing machine configuration files&quot; rather than producing meaningful artistic material. Similar to how such configurations are not presently copyrightable within the realm of e.g. musical synthesizer design, it makes little sense to allow machine configurations to be copyrighted here.<br/><br/>3. The direct social and economic impact of AI models trained on existing copyrighted materials without permission is universally negative. These models are most often used to imitate the styles or output of existing artists with the express intent to eliminate the artists&#39; participation and/or financial compensation. This can be further extrapolated to the ongoing labor dispute within Hollywood, where again the express intent is to AVOID paying others for their work. In short, this use of the technology is solely targeted at circumventing IP law and harming the well-being and ongoing employment of the very people historically protected by it!<br/><br/>4. All that said, where permission is granted for the training material, there are several viable use cases for this technology. In particular, the movie &quot;Spiderman: Across the Spider-Verse&quot; demonstrates this quite well: AI models were trained on material produced by the studio to speed latter stages of production of the film. If permission is explicitly granted for the sourcing of training material, these can be extremely useful tools! And in situations where these tools are used to assist the artistic process, the involvement of a human in the material&#39;s creation is often still obvious to a person sufficiently familiar with both the tools and techniques. <br/><br/>5. I believe the companies stating that attribution is impossible or not meaningful for this technology are mistaken or intentionally providing misinformation. It is without question both technically achievable and meaningful in a majority of cases. Instead, it seems likely that did not account for it in the original training of their models and are refusing to reinvest the time and effort to arrive at a conclusion where due compensation can be justly applied.<br/><br/>6. Several companies have adjusted their terms of service to enable the training of models using user data with little to no notice to their users. This includes several services with reasonable expectations of privacy such as Zoom and Adobe Cloud, as well as other cloud data storage providers. This practice must be prohibited, and companies should instead be compelled only to enable users to opt-in to providing training material. The rationale is obvious: if the models do not produce sufficiently transformative works, users are effectively being cheated out of the entire due process within the scope of IP law by the equivalent of a shrink-wrap license.<br/><br/>In conclusion: I urge you to consider the use of this technology in situations where models are trained on material where permission is granted as both viable and useful, but that the current efforts to legalize this technology are EXPLICITLY an attempt to circumvent IP law with the intent to cause economic harm. Requiring attribution, permission, and compensation in the commercial application of these models is technically feasible, just, and correct, as the material they produce is not alone meaningfully transformative from their sources. The ease with which material is produced alone does not sufficiently involve human interaction to justify granting copyright (the same as with any other machine configuration), while uses of the tools in transformative processes which DO deserve protection largely remain obvious to an expert in the field.