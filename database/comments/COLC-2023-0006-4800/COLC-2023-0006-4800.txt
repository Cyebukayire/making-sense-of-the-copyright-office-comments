While there may be certain applications of so-called &quot;artificial intelligence&quot; (machine learning algorithms trained on blocks of information to provide a result that &quot;appears&quot; correct to those who wouldn&#39;t know any better, such as ChatGPT or Midjourney and other such algorithms) that can benefit people and provide ease-of-use for us, as they currently stand they are nothing but data-thieves that break apart chunks of information and recombine them in ways that trick the gullible or ignorant (willfully or otherwise) into believing they have been answered properly. That alone is unethical, though there&#39;s nothing illegal about telling people untruths and falsehoods. But it&#39;s the way these algorithms currently go about gathering the information they learn from (and recombine into blather). There are currently few to no limits on the information they can &quot;read&quot; for answers, and they are not purely reliant on their algorithms, and often a small group of coders trim and edit the datasets they mine so the algorithms actually get suitable data, and occasionally adjusting the algorithmic code so that the system &quot;learns&quot; the proper lesson from the data. These coders are overworked, underpaid, exploited, and as far as I can tell, the majority of them are from and/or live in foreign countries without many of the protections a worker in the United States might have. That&#39;s only one of the major problems these algorithms have, though. Since they began with few if any limitations on the kind of information they use to &quot;learn&quot; from, that means they could and would access protected data for their own use. Copyrighted data, private information, and other data that those who own it simply have not provided consent of use for the purposes of these so-called &quot;a.i.&quot; algorithms. put the data. Some people, such as voice actors, have had their voices mimicked by a.i. programs without their consent to use voice samples to generate results, and musicians and sound engineers have suffered similarly. Authors have had their names applied to &quot;a.i. generated&quot; novels without their knowledge or consent. There have been steps taken to protect these people after-the-fact, with some companies passing themselves off as including anti-A.I. clauses in future contracts, for example. Which is good and fine for professionals, but what protects ordinary people? What protects, for instance, a student using a cloud-based text editor to write their finals essay, from having that essay plagiarized by a machine-learning algorithm, in any way? What&#39;s to protect someone who left a message on the phone from having that message be used as a data-set to generate an &quot;a.i.&quot; voice? What&#39;s to protect anyone from having images of their physical body be used to generate a virtual avatar that can be used to create a &quot;deep-fake&quot; to make it appear as though they&#39;re performing unspeakable acts or saying hateful things?<br/><br/>Some simple, common-sense precautions can be taken, but legislation would probably be best. Legislation and treaties with other countries, so an unethical &quot;a.i. generated&quot; piece of data can&#39;t simply be moved to another country to continue their unethical (and soon to be illegal) activities.<br/><br/>Recognizing a person&#39;s right to grant or deny consent for the use of their body, voice, image, and information would be a good start. Ensuring that they have the right of copyright protection for unlawful use of such things would help. Criminal punishment for those who flaunt such protections, starting with fines and ramping up even to time in prison, are the most obvious deterrents. But such laws will always be limited by language--if, in the future, those who are trying to generate machine-learning data without those protections find a loophole to exploit. How easily will it be to plug that and any other loopholes? How easily will it be for someone to assert their body autonomy and privacy until those loopholes are recognized? With the speed technology is advancing, it would be best to try to &quot;future-proof&quot; these laws, but human ingenuity is vast, and someone&#39;s going to try something. Obviously, allowing, say, public domain information may placate some of these exploiters, that still doesn&#39;t cover every case. What if a musical performance is public domain, but some of the musicians in that performance are still alive and do not want to consent to allow their part of the performance to be used in the machine-learning data set? I don&#39;t have many answers, and I&#39;d love to live in a world where the honor system keeps people honest, but we don&#39;t live in that world. Rampant greed and resentment of people who don&#39;t want to put the time in--or use the resources--needed to have access to the skills these algorithms supposedly claim to grant for themselves will always motivate people to exploit where they can, and such people would surely be unethical enough to break the laws around this technology when they can.<br/><br/>Thank you for your time.