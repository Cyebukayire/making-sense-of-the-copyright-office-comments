Hello. I&#39;m writing to you as an artist and writer whose works have very likely been used to train at least some of the common generative AI models currently available. I&#39;m deeply concerned over the impact generative AI will have on creative industries. I will mostly be speaking on the impact on creative industries specifically.<br/><br/>1. The sole reason these generators are capable of creating outputs of any notable quality is because the collective creative labour of humanity was used to train them without so much as asking permission. In releasing these generators to the public, more often than not for profit, the responsible parties have effectively created a product using copyrighted works that directly competes with the creators of said work. Consider for a moment the matter of textures on 3D models. I am not allowed to use any photo I want for this; even if the texturing process and shaders can make textures look radically different from the source image, I still can&#39;t just go and take any photographer&#39;s works for this. I have to make my own, use public domain photos or license them from the copyright holders. Why, then, should generative AI be allowed to take whatever they want for their commercial product? I see no major distinction between these cases. And 3D models don&#39;t even directly compete with textures in the marketplace! Compounding the issue is that these generators can, will and already are used to displace the very creative workers whose works fuel generative AI out of their jobs. I&#39;m unaware of studies on the impact at this point, but I&#39;ve spoken to freelancers who were let go by clients explicitly because the client turned to using generative AI. There is very clear potential to large scale harm to the people whose works were misappropriated without consent. This is especially true for generators that allow prompts for &quot;in the style of ArtistName&quot;. There&#39;s nothing ethical or just about this, and the habit of these companies of taking whatever they want whenever they want needs to be regulated out of existence. <br/><br/>9. Opt-out has been floated as a method, wherein copyright holders must provide an opt-out request in some form, but that won&#39;t work. Any capable artist on the internet will have their art reposted on other sites where they have no control over what gets opted in or out. Even if I have my own portfolio site and strictly opt out of everything, it&#39;ll land on Pinterest where it&#39;ll just get reingested by web scrapers. Furthermore, the technology underlying these generators is not secret; anyone with the necessary hardware can train one. Are we to individually opt out of an ever-growing list of scrapers forever? This is not a feasible solution. Only licensed opt-in ensures that generative AI does not take what they are not allowed to. Those wanting to use copyrighted works must negotiate a license for it with the copyright holder.<br/><br/>9.2. As mentioned in 9, there are no technical measures that allow for opt-out to work simply because people can and will remove the works from their original context. Also, these flags are contingent on scrapers following the request, which they may choose not to.<br/><br/>9.3. I&#39;m not interested in questions of feasibility. They can find a way to make opt-in licensing work, or they can simply choose not to train a model. &quot;It&#39;s too hard to ask permission&quot; is not a valid defense anywhere else.<br/><br/>9.4. Companies can invest in research to remove training data from the model weights. Or retrain it from scratch.<br/><br/>8.3. I believe there is data laundering going on. LAION-5B is a popular image dataset for training, and is compiled by a nonprofit--but the resulting models are used for profit. I do not believe for-profit ventures should have the same leverage to use copyrighted works as nonprofit research, nor do I believe that for-profit funding of nonprofits for the purpose of profit really qualifies as &quot;nonprofit&quot; in the first place.<br/><br/>10.3. Absolutely not.<br/><br/>15. Yes. Records should be public.<br/><br/>18. I don&#39;t believe this should be possible. I have commissioned artists over the years, which entails giving them instructions including but not limited to:<br/>-the style I want them to use, if they offer several<br/>-the subject matter I want them to draw<br/>-the composition I would like (I may sketch this as a reference for them to use)<br/>-further details, e.g. text in a speech bubble, face expressions of a character etc.<br/>-tweaks, such as &quot;please make this character&#39;s hair colour a bit darker&quot;<br/>I think everyone will agree that I am not the creator of the resulting artwork and will not have copyright, unless the commission contract involves the transfer of that right. Why, then, should a prompter who writes these instructions in a prompt box be any different? <br/><br/>28. Yes. This is also important with regards to deepfakes.