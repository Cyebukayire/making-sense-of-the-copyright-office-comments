AI does not make me feel safe. I cant post my work anywhere, I do not feel safe showing my work to the communities and companies, nor do I feel safe with the all these companies and rogue individuals scraping my Private information and data, coning me with my own art, my own life, deepfaking, imitating, and training the next me and my IP, without me knowing and agreeing. Even while infecting the other spaces that do not allow them to do so. Google, Meta, OpenAI, ETC. will thoroughly scrap and data launder information that clearly says, DO NOT (copyrighted).  <br/><br/>From what it sounds like Copyright is just a small hill. Privacy policies of the American People sound to be one of the biggest issues. The ability to easily gather information on politicians, masters in their skills and IP, even the data of children are too easy to obtain to be &quot;trained&quot; into swindling others with AI fakes, and largely by the social medias and databases that host this information through data laundering, Facebook, twitter/X, even Microsofts operating systems. There is no safety or privacy for the American people from AI. when every company is gathering and laundering this data maliciously, I believe the fitting term was &quot;hoovering up&quot; everything.<br/><br/>OPT OUT being another one of the biggest problems. Exhausting more effort to opt out than to spend on fixing work and personal studies. I wish it was OPT IN. There is so many AI start ups that have opt out models that when i have to ask that they remove my work from their training. They will fumble, lie, and NOT engage on removing it from the training, They treat it as if its already learned. Then why is there an OPT out? why do regulation not force these AI start ups to build Remove training options. They hide behind double standards, IF &quot;fair use&quot; is what it takes to get my work put back into the training over and over and over again. It sounds like THAT might be another problem that copyrighting my work feels moot or an absolute joke. Protection of data needs to be a large move. Copyright is a bandaid that can easly be ripped off for AI right now. Powerful moves are needed to control/regulate what AI does Build contingencies that regulations should be extremely stringent in what AI should be allowed to be released as. (De-training/De-learning built in, must have a flexible ability to remove content, etc.) Things that will not leave AI running wild through nefarious means of ignorance.   <br/><br/>Training being another of the biggest problem that should be regulated, could &#39;somewhat&#39; easily be fixed by forcing only OPT in models for current and future version of any AI start ups. Of course, the other problem being Rogue individuals feeding copyright and private information into the AI will be something that needs regulation too. Ultimately, Rules will be needed for AI programs/company that are making these so as to prevent malicious actors using these for those intentions, and there is an overwhelming amount of these individuals. <br/><br/> Surprisingly, it sounds like making AI trained off the likeliness of ANYONES data, copyrightable or not, should be illegal and held accountable. Would be the one of the easiest moves. It would put more innovation in subjective tools instead of making AI doppelgangers of their employees. I dont know, but that sounds like the most miserable job, training the next politician that doesnt know alot of ins and outs of politics, or an artists that doesnt know how to draw hands. Becoming a janitor to the process, cleaning the byproduct of AI does not seem like an enticing job and will severely reduce the jobs market as no one want to be called a +human as an achievement to political endeavors or art. AI should not be trained for the purpose of &quot;Replacements&quot; It should be used for analytics, not to impersonate people, individuals, or be the face of creative fields. It will only stagnate fields and favoring the companies, that are reducing jobs, and making the individuals of America that start up a new business without AI, harmful, as they will be trained, and replaced. AI as a Crutch Is more harmful now to innovation as its foundation is wobbly and its purpose is to replace. <br/><br/>I do hope that Regulations can come swiftly, America is currently in a fear state; cautiously walking as to not get sucked up by social media data laundering, or attacked by the parasites that feed on others data, even trust is at an all time low, politically, and amongst communities as witch hunting and even suicides are growing because of AI. Some will say AI is a great. I can see its possibilities to assist in strict areas, But to do everything, That is a Nightmare that should not be unchecked, the ethnical and destructive use of these programs, not forgetting the dependency is harmfuI, because even we as humans do some great stuff, but ultimately very scary and destroying stuff. Replacing the skilled and knowledgeable for a quick buck will only destroy us faster than we destroy ourselves.<br/>