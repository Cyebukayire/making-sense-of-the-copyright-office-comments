If a publishing company employed a group of people to take lines from books or images from works of art and assemble them into new volumes or art pieces without making any reference to the original creators, they would be vilified.  AI-generated works should make it clear what their sources are.  Once that is done, then AI-created art can be evaluated on the same basis as would any derivative work, namely, is it similar enough to the work that inspired it to be considered an infringement, or is it different enough so as to be protected as something original?  Obviously no piece of art exists in a vacuum, but if creators have to cite their sources (through transparency in the datasets provided by the tool), then it will be easier to determine what is and is not original enough to be protected.