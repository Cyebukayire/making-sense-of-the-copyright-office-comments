With the exception of assistive tools such as interpretation services used by the courts and video captioning, modern AI tools have largely been founded on databases consisting of plagiarized work. This has led to issues in various institutions as well as threatened employment and livelihoods as individuals and companies alike begin to rely on this plagiarism in place of humans. <br/><br/>Because the results of AI use are largely auto-generated, information becomes muddy and thrown together without basis. The &quot;AI&quot; does not know how to discern fact from fiction, merely stringing together words that its databases say commonly follow one another. This leads to misinformation and can very well threaten us with a much greater-spread problem that obscures truth in a mass misinformation campaign&mdash;unintended or not. Lawyers and students alike have been found to engage in using AI in ways that leads to this, with case numbers generated that do not exist simply because the AI generated them and plugged them into the work. <br/><br/>With art in all forms, the plagiarism risks their livelihood and ability to work. It introduces the possibility that companies and agents can make use of an individual&#39;s voice, likeness, or artwork (all forms) and deny payment. Humans who do not consent to provide their work and talent will suffer for this like any underpaid employee. Their work and talent is not freely given to be used for monetary gain. <br/><br/>This also leads back to the concerns of &quot;deep fake&quot; manipulations, where images and voices are used intentionally in misinformation campaigns. There can be no denying that this is deeply dangerous, as beyond things like &quot;revenge porn&quot; (which are deliberate mischaracterization of an individual at best), this makes it easier to design things like CSEM or otherwise put people deliberately in danger. <br/><br/>AI that relies on a collected database of images, sounds, etc., that does not have consent of the individual these are taken from at the forefront are dangerous. AI in general is easily misused for the deliberate harm of others in addition to the fact that so much of it is founded in theft and denial of the ability to consent. This current rash of AI are not designed with the purpose of assistance, they are designed with the purpose to cheat and lie and steal and harm, and unless they are otherwise designed to account for that and prevent it, they are only going to continue to be this. 