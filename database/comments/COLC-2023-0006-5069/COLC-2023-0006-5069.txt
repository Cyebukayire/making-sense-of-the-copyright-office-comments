Like my colleague and collaborator Nathan Leigh, who wrote the below statement, I too have serious concerns about allowing generative AI systems to exist without heavy regulation. In addition to what Nathan wrote below, which I countersign, I am also deeply concerned about the criminally underpaid and psychologically exploited pieceworkers who are employed to cull / filter data for those developing AI generative systems to be kept &quot;clean&quot; (filtered for hate speech).<br/><br/>I have serious concerns about allowing generative AI systems to proliferate without heavy regulation. The ability to plagiarize material, create misinformation at scale, and devalue the labor of working artists, journalists, and programmers present unprecedented challenges which our current set of regulations around copyright and fair use on the internet are ill-equipped to address. Additionally, the mass volume of material that is currently being generated poses an existential threat to the internet itself, as previously reliable sources of information are now either clogged out of search results by low quality AI generated content or have had their own reliability watered down by the introduction of AI generated content. Moreover, the ecological risks presented by these systems and the massive amounts of energy and water they require to operate are unconscionable at a time when our climate is perilously close to irrevocable damage. I strongly recommend that both the data sets and the material generated by generative AI algorithms such as the Large Language Models used by OpenAI and Meta be considered outside of Fair Use doctrine and regulated to the fullest extent possible.<br/>