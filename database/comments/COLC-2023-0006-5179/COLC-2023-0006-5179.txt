From various datasets used to train these AIs there has been a noticable pattern among a few of the ones who have publicly had their training sets released, one such being LAION. As discovered by many who have looked through it, there have been hundreds of thousands of human made works that were not directly permitted to be used to train AI. Additionally, many users were also not personally requested to have their works be used, they were not compensated, and most importantly, were not even informed that their media was used to train AI until recently. <br/><br/>Additionally, it has been found that Adobe&#39;s stock photo platform has also been distributing paid access to AI generated images while also misattributing artists as contributors to the creation of the work via the tags, this likely could mean that Adobe could have trained their AI using non-liscenced media. <br/><br/>I think it is only fair that while these systems remain reliant on training using previously existing works, that there should be a requirement for an independent contract that contains written consent been the artist and the person training the AI in order for the artist&#39;s works to be used to train an AI. Please ensure to disallow the usage of TOS or other extensively long documents to cover consent over this as well, otherwise companies may exploit potential loopholes (such as tricking users into consenting by hiding a small clause in a contract) to legally steal works of human authorship. 