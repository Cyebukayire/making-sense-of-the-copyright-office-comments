I am deeply concerned about the direction media industries are heading in now with regards to AI, which even setting aside other problems of companies doing their best to use it to cut as many humans (that they would have to pay) out of their creative process as possible, creating work that is bland, derivative, and in the case of nonfiction avenues, often filled with misinformation, sometimes extremely and dangerously so - even setting aside the rest, the current iteration of AI has been trained on creative properties without the consent of their creators, does not need to disclose when it does so, and does not need to disclose when a work *was* made by AI. There is a world in which AI creation can be done more or less ethically, where it learns only from pools of works it is expressly permitted to use, where it must disclose when its work is made by AI - but that&rsquo;s not the world we&rsquo;re living in right now, and if *this* world is allowed to continue down the path we&rsquo;re going down now, I fear greatly for the consequences this will have on a great many facets of our lives. Can photographs be trusted anymore, when AI can be used to create any situation for any purpose? Can virtual helplines be trusted, if you&rsquo;re speaking to an AI which can be fed poisoned data and give you harmful advice? I beg of you - do not allow AI and other machine learning systems to go out into the world unchecked. The damage it would do to us is critical.