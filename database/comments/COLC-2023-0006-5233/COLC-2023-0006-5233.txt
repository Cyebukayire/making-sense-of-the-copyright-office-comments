This is a continuation from my last comment so as to answer more question.<br/><br/>As a further comment, I would like to add: Any usage of material that was created previous to an AI model&#39;s creation needs to have consent given. Right now, websites are changing their terms of policy to posthumously give themselves copyright for the sake of AI, where most users are not consenting to this.<br/><br/>6. I don&#39;t know, because there is no way to check. Even if you tell a model creator not to use your material in their training, there is no way to enforce that it is not used.<br/><br/>6.1. I don&#39;t know. I have heard of sites like Twitter or DeviantArt changing their site policies to say &quot;we now own everything posted on here, and can use it to train our AI models&quot;.<br/><br/>6.2. I have not heard of this, and I would not expect any model creator to be licensing copyrighted material, since it costs so much money. I have heard of authors of legal documents or voice actors being asked to provide material to train a model, which will be used to generate much more material for the people who hired them. Essentially, they&#39;ve been asked to provide material that will be used to put themselves out of work, indefinitely. And once they do, they have no copyright protection on their own voice or words or anything.<br/><br/>6.3. I would guess non-copyrighted material is used as much as possible, since there&#39;s no need to worry about copyright. I would much prefer not to see any non-copyrighted material in AI artwork, so as not to see someone&#39;s likeness or voice being used after their death.<br/><br/>6.4. I believe material is retained, but I don&#39;t know.<br/><br/>7.1. As far as I know, training an AI model is done by giving it material. For example, if you had a folder full of images, you would give them all to the AI. Then, one by one, you would tell the AI what is in each image, in order to teach it what each image contains. You could also give it a lot of images in a particular style, and it would pick up on this style. These are all things that it would then try to replicate later. You teach it what an apple is by showing it many different pictures of apples, so then when you ask it to give you an apple later, it can create an amalgamation of those images later in order to create what it thinks &quot;an apple&quot; is. That&#39;s a rather basic way of putting it. In terms of voices, I would imagine it uses a person&#39;s individual timbre (or vocal tone), the specific frequencies and overtones of that person&#39;s individual voice, in order to have a basis for generating more. Then, a voice recording of someone else entirely can be &quot;tuned&quot; to that simulated voice, the frequencies and overtones shifted, so it sounds like a different person is saying those things. It&#39;s like autotune, but for a person&#39;s specific voice.<br/><br/>7.3. I don&#39;t know. I would hope it&#39;s possible to unlearn inferences. Say, in response to a takedown notice because of a violation of copyright.<br/><br/>7.4. I don&#39;t know. That&#39;s the sort of thing that is subjective and based on a person&#39;s own intuition. And that&#39;s why I think AI models need to be relegated and very transparent about exactly what they&#39;re using to train their models. Otherwise, it&#39;s a matter of opinion.<br/><br/>8. Hobbyists, at best. Certainly not cases where a human could have been paid by a company or business to create something.<br/><br/>8.2. If they&#39;re distributing copyrighted material for usage in training, they need to have the consent of the copyright holders. Otherwise, I don&#39;t see how this changing of hands or redistribution isn&#39;t just more theft.<br/><br/>8.3. I would imagine you would need to contact individual copyright holders and they would need to reach an agreement on a price for licensing of their work.<br/><br/>8.5. I don&#39;t know how exactly to measure that. But it would certainly create a lot of competition. Right now anybody with access to technology can be a threat to the market for or value of a copyrighted material being used to train an AI model, even if just a small one. If this were humans we were talking about, there would absolutely be a non-compete clause involved. How is it that AI generation is allowed to go around that?<br/><br/>9. They absolutely should need to opt-in. There should not be any automatic enrollment into AI model training. It should be consensual at every level. If there is going to be AI generation done from someone&#39;s work, they should be blatantly told so and give blatant consent.<br/><br/>9.1. Commercial uses. There should be metadata of some kind to say which AI model is used, so one could verify they were not being used commercially without consent.<br/><br/>9.2. If you had to do an opt-out approach, it should be easy to do and remove any trace of their work from the AI model, with the ability to verify that it was removed. Metadata indicated an AI should not use it should be mandatory on all images, to avoid image scrapers that collect vast amounts of images online.<br/><br/>I&#39;m out of space and time, apologies. Thank you for reading.