Through the lifetime of AI Writing, AI Art and Large Language models, I have seen the work of human beings stolen to be used as fodder for these engines. People who make these engines require a large body of reference material to even vaguely put together something reminiscent. With AI Writing, oftentimes people do not know their work has been scraped and is in use. With sites like Archive of Our Own (AO3), which is a non-profit site, there is no ability to monetarily profit off of writing published in the site to allow for the community to not fall under specific copyright laws, as is my understanding. Because the work is public and can be downloaded, any person can steal the language data of the fanworks and profit from it. The same works for large art sites. <br/>So long as the data can be pulled, the data can be used in the generative engines, even when the people creating the base work cannot profit.<br/>The work that is created, because it is built upon stolen data and how output is generated, is neither new nor derivative. What is created is a Frankenstein&#39;s monster of work. If you blend chicken with pork and beef and shape it into a chicken, it is neither a real chicken nor is it palatable. <br/>As it stands, there is no moral compulsion for creators of AI generation engines to not steal to create databases. There are published authors whose work was stolen and fed to AI and found out after the fact. You will find them demanding that their work be taken out of the dataset. You will be hard pressed to find a creative on the Internet that hasn&#39;t had their work uploaded to a generative engines. There is no AI on the Internet that claims that their dataset was collected completely willingly or ethically. A team cannot create enough data for use. Even large companies like Adobe have quietly slipped in changes to their policies under their users noses to scrape the data from their users while using their software. There is no ethical way to build an AI. 