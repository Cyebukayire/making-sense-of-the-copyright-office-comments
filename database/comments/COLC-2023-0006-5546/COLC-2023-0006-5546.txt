Using AI, especially AI trained on material without express permission, in place of human writers, artists, and actors poses many existential threats to the livelihoods of creatives and the foundations of our work. There should absolutely be legislation prohibiting AI trained on copyrighted works and without permission at a bare minimum. AI models should only be trained on permitted materials. <br/><br/>I also personally believe AI-written material needs to be VERY explicitly labelled, because of the dangers posed by nonfiction works written by a language model rather than a human being. We have already seen major cases, like the false citations in legal trials where lawyers used ChatGPT, where the words of a language model were taken as fact without question. There are nonfiction books &quot;written by&quot; AI on subjects like foraging for edible mushrooms, which is extremely dangerous without completely accurate information. Decisions built on false foundations can endanger lives, and too many people have no understanding of how models like ChatGPT actually work - including, in my experience, many people who actually use the models.<br/><br/>As a writer, I am strongly anti-GPT in professional settings. I understand it&#39;s not realistic, but my ideal situation would be a long pause on the legality of AI-written fiction and nonfiction stories for profit. I currently believe our society does not have a sufficient understanding of the risks posed by replacing human writers and fact-checkers with generated text. 