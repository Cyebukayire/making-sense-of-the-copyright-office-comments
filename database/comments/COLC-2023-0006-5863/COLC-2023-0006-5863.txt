Artificial intelligence as of current usage is infringing on the rights of those who have created content in the past and are currently creating content. A bit of searching and you&#39;ll find people taking missing children photos and turning them into different photos entirely, all without the consent of the families involved, and some of those photos are being used in a derogatory manner. Then there are AI companies that profit off of turning regular everyday photos of individuals and stripping them of their clothes (again without the original person&#39;s consent). There are also instances where AI will make up fake information in a report on current events or historical data and people assumed it was true. Then there&#39;s also the art community (including videogame and performing arts), who are vocally and with reason protesting the use of AI and wanting clear outlines of the usage of their likeness in future projects. We need stricter AI regulations that address all of these issues and possibly others that have yet to be put into words.<br/>Every person should have their own unique copyright as an individual. This will prevent nefarious characters from stealing and abusing the already existing works, and should stop situations where someone pretends to be an already existing artist and degrading the artist&#39;s reputation by spamming AI works under the artist&#39;s name (this happened to an author already and they could not get Amazon to remove the books as the author did not copyright their own name). <br/>There needs to be a clear consensus on what AI is and what is being used to create the content. If we can state the different levels of AI in layman&#39;s terms and in legalese such that no one can be confused as to the terms and agreements of contracts or services, then people will be able to have an educated opinion as to which contracts or services will be beneficial to or best protect themselves.<br/>There needed to be an updated and stricter policy on revenge porn that includes the usage of AI. Doing so will make people feel safer posting pictures of themselves and not have to worry as much about their photos being used to strip them of their worth. This would also mean all photos must be opted out of common crawl and AI specific scraping by default, and that each time a person posts a picture they are asked in clear and not misleading statements if they want to opt in. If a group photo is taken and one person opts out, the entire photo should be automatically opted out. This could help with the situations regarding AI and missing children, and with AI and being lewded without consent.<br/>AI opting out for all forms of art should also be the default unless specified otherwise. Dead people consent to organ donation while alive, so why do dead artists not get the same treatment with their works? Punishing companies that already forgone asking for permission is also necessary, and they must redo their work from the start of the testing.<br/>For medical usage, it&#39;s harder to say how to regulate and keep patient/participant data secure. Once something is in an AI, it can&#39;t be removed unless you restart the whole AI from scratch, which makes protecting the source data harder. I see the usefulness of AI in helping people find items in a store without needing a human interpreter, or helping deaf people hear by analyzing the pattern of brain waves in those who can hear and transferring those patterns into deaf people. When there&#39;s a breach traditionally, there is a specific authority which is required to be notified regardless of the severity of the breach. That authority might not have the expertise nor experience nor legal capabilities to protect people in the situation we&#39;re in now. <br/>I hope this has summed up most of the current debate on AI and explains the nuance needed to protect people from malicious negligence or nefarious characters.