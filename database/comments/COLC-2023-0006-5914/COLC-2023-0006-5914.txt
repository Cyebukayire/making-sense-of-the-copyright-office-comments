Generative large language models, or &quot;AI&quot;, rely on analyzing vast datasets of content. Most of the large, commercially available AI services are built on content that the owners did not have the rights to use. We must protect the rights of artists, authors, and other copyright holders: their work should be protected from being wholesale fed into these models without their consent.<br/><br/>Proponents of this technology sometimes argue that the way their models &quot;learn&quot; is similar to how humans learn, and we allow humans to learn from being exposed to each others&#39; work, so therefore they are justified in this kind of largescale &quot;scraping&quot; of content from the internet. BUt this is fundamentally incorrect, and even if it were correct the differences in scale are too vast to treat them the same: a human artist can &quot;study&quot; another artist&#39;s work carefully, over time, work for years to approach another given artists&#39; style, and their output will occur at human scales and speeds. An LLM can be fed millions of examples quickly, and then generate millions of images that are built on the images fed into it. <br/><br/>If we allow this to occur at the will of the large technology companies who run these LLMs, freely, without compensating artists, then artists of all types will cease to be able to live off their art in our society. The fundamental goal of copyright is to incentivize and protect artistic creations: allowing LLMs to freely steal work dramatically undermines that goal.<br/><br/>