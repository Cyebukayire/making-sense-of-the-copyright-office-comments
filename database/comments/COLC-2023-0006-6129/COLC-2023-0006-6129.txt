The spectre of LLM&#39;s being fed my IP, scraped from the web, makes me so angry. All my work, to be masticatd and spat back out in some mashup a) for money! and b) unattribited! and c) not identified as an AI-product!<br/><br/>I&#39;ll look for ways to shield my data. But this will have us hiding content, not sharing it. I want the onus to be on LLM/AI providers for TRANSPARENCY -  declaring attribution of contributions, just as we stringently demand of university stidents who synthesize existing material into new forms. AI products must NOT be easy to mistake for human products. And images must he at least watermarked. Agreements must be negotiated with creators of training data *in advance* and explicitly, with non-damaging opt-out. <br/>To do otherwise is irresponsible, disrespectful and destructive to the very creators who feed the LLMs - the Golden Goose, if you will, who lays the golden egf.