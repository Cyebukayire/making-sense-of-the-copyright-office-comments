I&#39;m a professional artist working in the entertainment industry. The negative effects of generative AI on me and my fellow creatives are already evident in the WGA + SAG-AFTRA strikes- corporations seeking to use the technology to, at worst, replace human beings in the creation of movies, video games, etc.- and at the least, create a system where they can claim that a machine did the bulk of the work in order to pay human artists pennies to &#39;revise&#39; its inevitable mistakes. As a human appealing to fellow humans, I first ask us to consider what the point of art and culture in our society would even be if it&#39;s all created by machines. As an example, I don&#39;t care if an AI can generate a perfect version of the newest Guillermo del Toro movie. I want to see a movie made by Guillermo del Toro, to see his creative vision, ideas he felt so strongly about that he needed to express them through the hands of creatives who are proud of their craft. <br/><br/>Now from a less emotional standpoint, I recognize that sometimes new technologies upend industries. Objectively, I&#39;m not against the idea of generative AI itself- it can help streamline the work that I do, as well as give non-artistic people or low-budget productions a quick answer when they don&#39;t have the means to hire artists. HOWEVER, generative AI in its current state is an ethical and legal nightmare. The only reason AIs like Midjourney and Stable Diffusion are powerful is because of the massive datasets they&#39;re trained on, the vast majority of which was scraped from the internet without consent. Many of my peers have had their artwork stolen and churned through these AI models, so much that a Google of their name produces more AI-generated content than their own artwork. I have a friend who is a voiceover actor, and her lines from a video game were scraped, funneled into an AI, and used to generate pornographic audio. Celebrities are having their images and voices taken and used to generate offensive photos, voice clips, and &#39;evidence&#39; of things they&#39;ve never done.<br/><br/>It&#39;s a massive invasion of both ownership and privacy, and as of right now, almost completely unregulated. Just because information is publicly obtainable, does not mean that it should be allowed to be fed into these systems, PARTICULARLY now that the companies creating them are aiming to commercialize. You can&#39;t buy a DVD, and suddenly claim you have the authority to alter, copy, distribute, and sell the content within. If you steal 1000 cars, break each one down to its parts, and build a new unrecognizable car from those parts, you&#39;re still guilty of stealing 1000 cars. What these companies are doing is exactly that at a much higher magnitude- millions of images and audio clips, endless text. The fact that they use the sheer magnitude of their data scraping as an excuse- i.e. they aren&#39;t aware of copyright violation in any one specific example- is laughable. It&#39;s still theft. Many online platforms allowed their images to be scraped for months before implementing any sort of opt-out system--by then, it was too late. Those images are already in the datasets.<br/><br/>We cannot allow these companies to continue operating on such a &#39;do first, ask permission later&#39; philosophy- i.e. opt-in as standard, people must actively opt-out of having their data taken for AI training. They are counting on the majority of people to be unaware, or at least unaware until their data has been taken and therefore opting out essentially does nothing. They are counting on us to be sufficiently dazzled by this shiny new technology, enough that we overlook the fact that the hard work of human beings--who received no request for permission, credit, or compensation--is the only reason their machine works at all. And all the while, all of that stolen, uncompensated work lines the pockets of the small few who run these companies.<br/><br/>If generative AI companies want to present this technology as legitimate and ethical, there must be FULL transparency as to how their datasets are obtained. They must be opt-in by default. Every piece of data used to train these systems must be obtained with consent, credit, and compensation. If they cannot provide evidence of this for their existing datasets- whether it be by reason of sheer volume, the automation of its collection resulting in lack of human oversight, etc.- those datasets MUST be purged and started anew. These processes have to be regulated by parties without conflict of interest, and written in law. Antitrust is already such a big issue in the tech sector, and we cannot trust these companies to self-regulate or hold themselves to ethical standards, not when such an explosive commercial opportunity is present. This is very much a moral issue, and stands to have a huge impact on our society as a whole.<br/><br/>I hope that the U.S. Copyright Office will take these comments in a positive light, and take actions to protect the rights and privacy of everyday Americans. Thank you.<br/><br/>