As an artist who&rsquo;s work would inevitably be thrown into the AI database without permission, I am extremely concerned with the lack of regulation involving AI - mainly whether my individual copyright over my own work will be nullified if someone were to use them to generate products to sell without seeking permission. This is a large loophole that could be detrimental for both individual artists and corporations alike if not sealed properly. Already there are generated images on Google&rsquo;s search browser that flood out the very real sources that people would be searching for, and since there&rsquo;s no way to flag these images as generated by AI they will continue to overload the search bar with misinformation. If Google has already become clogged with generated images, imagine what could happen if someone were to generate a fake trailer for a nonexistent movie using data from real corporations. At best the rumor gets squashed, but at worst anyone and everyone who&rsquo;s tied to said AI generated product would be called to question.<br/><br/>I believe there&rsquo;s too much at stake with AI as it is now without any proper regulation or distinction. If this were specifically AIs meant to make work life easier (auto-filling someone&rsquo;s outline, generating distinct strokes and effects in between frames of animation, and so on) this would not be an issue since the data is coming from people who have consented to inputting their work to make production easier. This particular system in question, however, is something that indiscriminately scrapes any and all data it can reach in order to generate an output that the prompter may or may not want in the first place - all without any permission or consent to anyone who&rsquo;s data would be scraped from. There needs to be regulations set to prevent any harm from whoever&rsquo;s data gets caught within the system&rsquo;s database - not just artists and corporations but regular people who decide to share anything with friends via online. It needs to happen NOW.