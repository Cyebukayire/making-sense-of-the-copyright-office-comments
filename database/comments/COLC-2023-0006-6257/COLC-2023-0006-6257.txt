The only appropriate and ethical use of generative AI is creating limited and controlled data sets for a discreet purpose (for example Across the Spider-Verse creating an in-studio tool trained on their animators&#39; art to aid the production of that specific movie). In all other cases everything generated is coming from a tainted data set. The creators of these AI tools routinely ignore requests for transparency and the right of authors to exclude their data. New models claiming to be ethical are still using the older versions as their basis, starting from a stolen foundation. Until regulations exist which demand active consent from authors of all data used, the creators of generative AI tools will use &quot;there&#39;s no law against it&quot; to shamelessly steal and misuse creative works against their author&#39;s wishes.<br/><br/>The ability to mimic an artist&#39;s style can also lead to mass generation of content &quot;in their style&quot; with themes and context the author would strongly oppose. Being able to curate your image and online presence is vital to building a career as a creative. Being recognized for a certain type of works is how artists get new clients and commissions. This is completely undermined by a flood of content existing outside of that curated context. The artist of course cannot fully control what happens with their publicly shared art, but the issue is SCALE. Few viral memes and social media posts can ensure that an artist is more commonly associated with an offensive or &quot;funny&quot; AI image than with their actual art.<br/><br/>Generative AI content should not be copyrightable. It is wholly dependent on the current version of the tool used, not on the authorship of the &quot;prompt engineer&quot; or any particular skill or creative intent. A minor change to the tool or inclusion of new data in the data set renders the only arguably creative part of this process (the prompt) useless, returning unrecognizable results and making their replication impossible. <br/><br/>This technology can also be used to create convincing deep fakes, which to date have been widely used to generate child pornography, non-consensual pornographic images of real persons and deliberate misinformation. This is possible due to use of unrestricted data sets in these tools and is extremely dangerous. <br/><br/>Another example of the danger these tools pose are the &quot;AI plagiarism detection&quot; tools, themselves using AI technology. They are used to verify legitimate authorship of school assignments, academic papers and creative writing submissions. They are wildly unreliable and often falsely claim that a text written by a human is AI-generated. Lack of knowledge in this area can severely impact academic or professional futures of individuals dealing with a misinformed professor or employer, rejecting their submissions based on false claims of plagiarism. Again, this can impact the ability of an author of the text to copyright and benefit from their own works.<br/><br/>Continued use of these tools in their current form can have a devastating impact on the job market for creatives. If the generated works can be copyrighted, it&#39;s an incentive for businesses to use them, especially for low-level, low-impact commissions, instead of hiring a writer or an artist. If they cannot be copyrighted, the business risk of losing control of branded assets will discourage widespread use of AI-generated content. 