I am a screen actor whose livelihood is directly threatened by this technology. The last year has been a morass of existential dread about the future of my profession, spurred on by AI companies&rsquo; clamoring to put as many artists out of work as possible, and culminating in the most important labor action in my industry&rsquo;s history. <br/><br/>However, I&rsquo;m recently heartened by the newly discovered phenomenon of &ldquo;model collapse&rdquo;, whereby an AI model trained on its own generative output loses its predictive capability leading to a rapid degeneration in the quality of its content. This phenomenon seems to suggest that AI is fundamentally dependent on (even parasitic of) human work in a way that AI companies are not being forthcoming about - and the argument that AI is &ldquo;learning from&rdquo; or &ldquo;being influenced by&rdquo; the art it absorbs loses any credibility. When humans absorb other artwork they go on to produce wholly original works of art, which themselves can be absorbed by future generations. This is because human beings are fundamentally creative. Not so for AI. Generative AI needs to absorb *human* art to function because it&rsquo;s own output is nothing more than obfuscated theft. It&rsquo;s no wonder Google is suddenly keen on watermarking AI created content; without the ability to distinguish AI art from human art, companies like Google will no longer be able to train their algorithms by stealing our hard work. <br/><br/>I&rsquo;m including links to relevant articles about these recent developments. Thank you for your time.<br/><br/>https://www.businessinsider.com/ai-model-collapse-threatens-to-break-internet-2023-8?amp<br/><br/>https://amp.cnn.com/cnn/2023/08/30/tech/google-ai-images-watermark/index.html