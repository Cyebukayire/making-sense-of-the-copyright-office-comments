As an artist, creator and business owner, there are a significant amount of problems with generative AI systems as we know them, and especially as they aim to be without significant management, regulation and frankly - *correction* - in how they&#39;re being opaquely handled to date. I will address a number of the supplied questions in making my point.<br/><br/>- First, a paper discussing the impact of AI Art on artists: https://dl.acm.org/doi/10.1145/3600211.3604681<br/><br/>- To get to one of the most critical issues up front. Attribution to the creators of the material data used to train the growing, countless amounts of generative AI tools is going to become absolutely critical to future information trust. At this moment you can see for yourself that trusted search engines like Google, or accumulative sites like Pinterest are growing to display pieces or false photos generated by AI. If journalists, websites, and even the courts have to search for usable imagery, is it not important that it is clear whether or not the -source- is clearly able to be determined as &quot;real&quot;?  The companies creating these tools have no intrinsic motivation to provide such information. It doesn&#39;t serve them. Self-regulation is know well enough to be prone to failure. Legislative action *must* be taken for things to be handled properly. Does it not seem obvious when a company asks for itself or its own tools to be regulated *and* to want to be the one that lays out the guidelines?  These types of circumstances lead to instances like the tobacco industry being able to maintain and organize the message that its *clearly unsafe* products are safe, etc<br/><br/>- Generative AI as-is fundamentally can&#39;t do any of its job without having the data of the owners of imagery, text, etc. By its nature, there&#39;s no way for it to be as good as what we want it to be without using copyrighted material, and the developers admit as such, up to the point that they feel the need for permission and attribution to the material that fundamentally makes it even plausible to create their &quot;tools&quot; is a hindrance. To re-frame that position, if *your* data and personal information was needed to make their tool work, they see it as an -issue- that *you* would want proper say in how *your* information is used. Now expand that to encompass the general public.<br/><br/>- The increased use of AI-material already is actively eroding the value the general public *and* employers see in the work and effort of creators. Not only that but the active increase in harassment coming from those who feel entitled to full freedom to use AI to create content in the name of the creators in many ways that can be damaging to said creators.  Examples: voice actors whose voices are used to say things they&#39;d never support. Photos of *individual private citizens* corrupted into non-consensual pornographic material. Or relative to me, art attributed to artists that were never created by them.<br/><br/>- For image generative AI, datasets are being scraped and acquired from the very websites creative go to share their personal creations with each other, such as DeviantArt, and sites developed with industry networking and portfolios in mind, such as Artstation. In both cases the allowance of AI has overwhelmed the overall userbase with more imagery than users can create, and get-rich-quick grifts of hundreds of generated pieces of &quot;reference material&quot; as they&#39;re claimed for mere dollars, much less undermining the general trust that the most high-profile location to gauge the abilities of creators now fundamentally leaves those abilities in doubt by nature. <br/><br/>- To the above situations, it is fundamentally unknowable just how much (thanks to the increased capabilities of generative AI) is something already created by the computer, without actual input, and how much is the actual creators&#39; work, leading to extremely plausible and occurring situations where companies now have to spend more time than before vetting whether or not the &quot;creator&quot; is actually the creator, costing more time and investment than would have been necessary before, when it was more assured that the work was representative of the creator&#39;s actual skill. Obviously, exceptions have always existed, but predominantly have been self-filtering, but generative AI has fundamentally changed the nature of the situation.<br/><br/>- As information is currently given, it is *not* possible for an AI model to unlearn what it&#39;s been trained on. It can only be completely redone from the ground up.<br/><br/>- I firmly believe that it is in the best interest that copyright owners should as a standard be asked to *opt in*. The only basis for the developers of the tools to push for *opt out* is simply the ease of asking forgiveness later after the damage has been done and to acquire the benefits faster, but it gives no respect to those incapable of having a choice about how their material is used, such as the simply unaware in the moment, those who&#39;ve left platforms being scraped, or the deceased<br/><br/>