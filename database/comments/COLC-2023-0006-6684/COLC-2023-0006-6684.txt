In the current environment, AI has been overwhelmingly trained on copywritten works, without permission of the creators of those works. An algorithm is not sufficiently transformative to qualify this as fair use. Current techniques to get data for AI training involve indiscriminate data scraping, with no regard for where data came from and what copyright that data was under. Anything created by an algorithm using copywritten work should be considered copyright of the creator of the original work(s), not of the algorithm writer nor of the person putting a prompt into the system. AI should not be trained on copywritten works without express and specific permission of the owners of the original work(s). Failure to do so will create plagerized work, and make it difficult for the original creators to sell their work, as the AI-derivatives are able to flood a market much faster than an individual can create. Data sets used to train AI need to be transparent in the works they use; failure to do so should be considered an implicit breech of copyright. <br/>Based on previous rulings, an algorithm cannot be copywritten, and AI is merely an algorithm shuffling data around. If a data set contains only fair-use material, the resultant output should be considered equally fair-use. If a human modifies that output, the human modifications should be able to be copywritten, but not the original output. Due to the speed and ease of creating AI derivatives, they can quickly outpace human creations. If AI works can be copywritten, they will disincentivize original creations, as there will be no legal benefit to creating work without AI. 