Though I cannot answer all of the questions posed, I am an individual with vested interest in this issue. I was a first-year college instructor teaching ENG101 for two years, and AI generated content was a strong deterrent for making that career path sustainable for me. Since there are no identifying marks anywhere in or on AI-generated text, nor any government/institution-recognized database to cross-check the text, there was no feasible way for me to raise concerns to a student whom I suspected used ChatGPT or other machine learning text-based system. There is no way to prove whether a student used AI-generated text or if they simply write using short, nondescript sentences (a common writing style in my experience with first-years). I spent considerable time as an educator grading, and the sheer volume of responses that I suspected were influenced by ChatGPT made me feel like my time was wasted with no recourse.<br/><br/>I believe, in the case of text-generation AND other programs which generate a composite through machine learning, programs like these should absolutely hold a database of their training set, and it must be mandatory that interested parties can access, either through the company (with government oversight and regular auditing) or through a government entity, which can cross-reference a piece of text and confirm whether or not AI generation was used. Plagiarism is difficult enough to catch and manage, with online services to purchase essays and archives that students will copy large swaths of text from, but at least those have viable recourse. AI-generated content has none.<br/><br/>Due to this factual description of machine learning generation as &quot;composites&quot; from a larger existing dataset, I do not believe they can be copyrighted. No amount of unique query development can claim originality, especially if my suggestion above, that text and imagery can be cross-referenced with a transparent dataset, is implemented.<br/><br/>I also, on a more personal level, think that it&#39;s absurd that AI art continues to exist unregulated. If videos on YouTube can get copyright strikes for clips of songs or movies, even in commentary settings where Fair Use is at play, I don&#39;t see how AI generated art can be allowed to exist under its current iteration. From my understanding, these sites train their AI using images from social media, Google Image Search, and internet archives. I believe this should be highly regulated. Public works should be allowed to enter the training set, as well as any royalty-free images available, but if the image has been posted by an individual on social media or if it contains a watermark, it should be submitted directly to the company for use in their training set (opt-in). It&#39;s duplicitous and needlessly complicated to have artists and writers opt-out.<br/><br/>Transparency is the key to success with machine learning. We already see bias at play in other machine learning systems (face ID recognizing white faces with more accuracy than people of color, medical training data recognizing male symptom presence more so than female, etc). There are no shortage of examples of this bias in AI art (the New York Times has articles with relevant studies linked, all behind paywalls, otherwise I would link them directly).<br/><br/>I am concerned about the number of jobs which might be eliminated due to the program&#39;s implementation. This is something I don&#39;t have answers for but, in my current role at a university developing content for their venue and production management department, I wonder if my job will still be relevant in ten, fifteen years (maybe even sooner). Will my skill as a writer become obsolete in the face of a cheaper product?<br/><br/>Finally, I do not think all machine learning is bad. In cancer research, there are machine learning programs which are identifying clinical trials for patients much faster than a human would be able to. This is, of course, a good thing. I think that in the cases of health and wellness, machine learning can be an extremely valuable tool (as long as training sets are made transparent and available to ensure the program is accounting for and trained against bias).<br/><br/>I am impressed and grateful that the copyright office is seeking comment from the public on this issue. Thank you for your time.