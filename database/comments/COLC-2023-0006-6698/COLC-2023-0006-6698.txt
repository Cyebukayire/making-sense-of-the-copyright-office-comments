I am a scientific illustrator and PhD in biomedical science - it is simply not possible to replace my job with generative AI, no matter how much it seems like it might be, and therefore, why should generative AI be considered in the same vein as human-made design? To start with: generative AI has no discernment inherent to itself and no expertise it can look back on to guide future decision. This is easily demonstrated if you ever attempt to direct an AI system back to a previous topic. As such, it&#39;s something of a misnomer to call it &quot;intelligent&quot;, it has no intelligence - it&#39;s just playing a game of statistical probability. This presents a huge problem on the use of AI: it does not and cannot understand what truth is or what reality is. Previously, many people have had a good laugh about how generative AI creates images of people with six fingers, despite the fact that that is not a typical thing for the vast majority of humanity. But when considered in the context of applications like mine, scientific illustration, where illustration is used to properly document and detail the world around us and can be used in scholarly published works, it becomes deeply horrifying. If scholarly works are published with AI-generated components, held to the same regard as human-generated work, with copyright protections, etc, they can then be used to impact policies that affect everyone. I am not against generative AI as a concept, there is surely something to be said for its use, but there needs to be much stricter regulations about what data it is allowed to scrape, what we allow its use for, and ensuring that human-generated creations retain their legally documented precedent as the only holders of copyright.