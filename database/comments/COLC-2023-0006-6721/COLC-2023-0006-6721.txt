I believe that AI work should not be protected by copyright itself, and that AI work should be vulnerable to copyright claims if the work it was based off of was not gathered willingly. I believe that artists should be able to revoke permission to have their work used in AI projects, since many social media sites have changed their policies to include AI training without explicitly telling their users and enable it without explicit consent (I think DeviantArt did this.)<br/><br/>a. Why AI art shouldn&rsquo;t be protected by copyright: I have always seen copyright&rsquo;s intended purpose as a type of protection for creatives. It was a way to incentivize creating work, since the artist had a window of time before it could be plagiarized. This was to help guarantee artists some sort of stable income from their effort when forgeries could be present. AI does not need these protections, as it 1. is not a human needing stable income and 2. does not put in a significant amount of time/working effort to produce its results.<br/><br/>b. Why AI works should be vulnerable to copyright claims from artists: AI works via mimicry and synthesis. While this may seem comparable to the learning process of a human, AI do not have access to the resource of real life, which is what provides the true inspiration to make artists artists. Without that, the AI is left to remix things it has already seen. Generative art and writing AI are often trained on datasets produced by artists who are unwilling to share their artwork for an AI. There are no repercussions to stealing work in this way at the moment, as evidenced by artists taking things into their own hands with tools like Glaze (https://glaze.cs.uchicago.edu/) to actively fight off art theft. Furthermore, AI may sometimes spit out near-replicas to artworks fed into its dataset, which many artists consider direct art theft.<br/><br/>c. Why artists should be able to revoke permission to have their artwork used in a training dataset: I believe that a lot of artwork used for AI was collected in shady, unclear ways. Opt-out programs like those seen in some places on the internet are harmful because 1. once an artwork has been used in an AI&rsquo;s training, that can&rsquo;t easily be undone, and this usage can occur before the artist is notified and has the chance to opt out; and 2. individuals who have abandoned old social media accounts should not be considered as consenting to having their art used for AI training. If a law gives artists the right to revoke their art from AI training, with consequences if this revocation does not affect the AI, it will incentivize companies to only use art from sources that have clearly consented. Retraining an AI takes a lot of resources so I&rsquo;d hope threatening database changes will make the playing field more fair when it comes to what goes in the database in the first place.