As a writer and teacher in the field of business data management, I&#39;m very concerned about the impact that AI LLMs, such as ChatGPT, will have on my work. Many of my concerns are described in the attached article, which I wrote and published on the TDAN.com website. Here is a brief summary of my concerns:<br/><br/>1) Truthfulness. ChatGPT and similar AI chatbots have a disturbing tendency to make up information and present them as facts. For example, ChatGPT will tell you that I&#39;ve written articles for the New York Times, the Wall Street Journal, and Fortune, none of which is true. More disturbingly, input prompts to these AI bots can be deliberately manipulated to produce and disseminate misinformation on any given subject, and this misinformation will likely be taken as authoritative.<br/><br/>2) Plagiarism: As described in the attached article, ChatGPT will parrot back nearly verbatim definitions of terms and concepts I&#39;ve coined in my books and articles (e.g., &quot;Logical-Physical Divide&quot; and &quot;Virtual Data Layer&quot;). However, it will not acknowledge me as the author of this work or cite the sources from which those definitions were obtained. When I write a book or article, I&#39;m required to cite all my sources and acknowledge their authorship. If I fail to do this, both I and my publisher can be held liable and sued for damages. This is true even if my use of the material constitutes &quot;fair use&quot;. <br/><br/>3) Recognition: A Google search on material I&#39;ve written will bring back links to my books and articles so that people can get a better understanding of the points I&#39;m trying to make. But with ChatGPT, people assume that the AI bot is the author of the material, and people will not be directed to the books and articles that would explain the material further. I write books and articles for the purpose of contributing to the body of thought and knowledge in my field, and also to help establish myself as an authority in this field. ChatGPT and similar AI bots undermine these efforts. <br/><br/>4) Income: I also depend on my books, articles and lecture fees for income. Even in cases where I may not be paid directly for an article (as with my TDAN.com articles), they help establish my name and reputation in my field and lead directly to speaking opportunities (for which I do get paid). I also get royalties from my three published books. If ChatGPT and other AI bots give people access to my written material for free, and without citing my works or crediting me as the author, this deprives me of potential revenue opportunities.<br/><br/>5) Context: Another concern of mine is that the material that ChatGPT and other AI bots plagiarize is always taken out of the context of the book or article in which the material appears. Therefore, the plagiarized material may appear to be making a point completely at odds with the author&#39;s intentions. Imagine, for example, if material from my books and articles was taken out of context to make the point that sound data management practices were unnecessary in an organization!<br/><br/>6) Commoditization: As explained in the attached article, AI has a very real potential to cheapen the value of expertise in any given field. Since AI bots run off databases of information obtained &quot;for free&quot; from the Internet (much of which may be untrue, outdated, or self-serving), the output generated from these programs is probably mediocre at best, and reflects (at best) the conventional wisdom on any given subject. However, both individuals and corporations will increasingly make use of this &quot;free&quot; bot-generated information and over time this will devalue, Gresham&#39;s Law style, the expert knowledge for which experts expect to be paid. For example, ChatGPT can be used to generate computer code, but this code will likely not be correct, performant, or maintainable over time. ChatGPT doesn&#39;t know how a SQL query optimizer works. But I do.<br/><br/>What we can expect from these LLMs, over time, is an intellectual &quot;race to the bottom&quot;, where expert knowledge is increasingly replaced by chatbot-generated falsehoods and the endless re-parroting of misinformation and conventional wisdom. We&#39;re also seeing an increasing number of cases where LLMs, fed on input generated from other LLMs, go berserk and begin spouting nonsense. This is referred to as &quot;MAD&quot; (Model Autophagy Disorder), and is similar to what happens with &quot;Mad Cow Disease&quot; when cows are fed beef. Since LLMs have no conception of reality, and cannot tell truth from falsehood, sense from nonsense, or even reality from fantasy, we may rapidly get to a point where we cannot distinguish information from misinformation (or disinformation), and this will paralyze our ability to create effective and sensible rules, policies and processes in our schools, businesses, governments and other public institutions. What we saw happen in our country during the Covid pandemic is just a small example of what we can expect to see happen in the future, and our society will suffer for it.