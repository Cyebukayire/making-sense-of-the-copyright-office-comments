I am strongly of the opinion that almost all ML/LLM (&ldquo;AI&rdquo;) as currently available is illegal (or rather, their output is illegal to use, redistribute, etc), and that AI providers/operators should be required to provide an auditable documentation of what their exact, full &ldquo;training data&rdquo; is so that the end result can be deemed not illegal (to use/redistribute/etc&hellip; is now always implied; I&rsquo;m aware that playing around with those works for one&rsquo;s own use likely falls under academic and other exceptions from copyright).<br/><br/>I base this opinion on the following:<br/><br/>I know how computers and programs on computers operate and have basic knowledge of ML. I know an &ldquo;AI&rdquo; is just a computer program run on a deterministic system, that is, its outputs are a reproducible function of all of its inputs. (Some AI platforms may include pseudo-random data so an end user cannot in practise reproduce the exact same output, but that&rsquo;s just part of the input to the program that is hidden from the end user.)<br/><br/>An &ldquo;AI&rdquo; functions as a program that&rsquo;s in the middle of a lossy compression/decompression algorithm and a compiler/mixer. Input (training data) is lossily compressed and stored, mixed using the &ldquo;prompt&rdquo; as base, and then the output is produced, a derivative work of all of its inputs (although in most cases only a small percentage of the input are reproduced in the output in copyright-worthy amounts).<br/><br/>However, it has been proven possible, for both image-outputting and text-outputting models, that it is in fact possible, with suitable prompts, to reproduce recognizable originals (a good three quarters of a painting COMPLETE WITH AUTHOR&rsquo;S WATERMARK, the remaining quarter filled in by the system; for texts, entire subsections of Wiki articles about fictional weapons from role-playing games (instead of information about historical weapons that would have been appropriate for the context) that are easily recognizable as plagiarized).<br/><br/>Therefore, it must be assumed that any given &ldquo;AI&rdquo; output *always* contains significant amounts of *at least* one of its inputs (&ldquo;training data&rdquo;) and is therefore subject to the input&rsquo;s copyright restrictions and license conditions (if any; otherwise, the work enjoys the Berne Convention&rsquo;s automatic protection).<br/><br/>I myself am directly in a situation where I get damaged by the current lawless use of &ldquo;AI&rdquo;: I produce &ldquo;copycenter&rdquo;-style software and other works (free sheet music, for example), i.e. under permissive licenses, which basically gift the work to the public under the condition of attribution. With a grant this broad, the attribution requirement should weigh more than it would in a work under a more restrictive licensing (either &ldquo;copyleft&rdquo; or traditional/commercial licenses). Reuse of AI output derived from my work (e.g. from Github Copilot) directly infringes my rights by reproducing my code but not my attribution (or that of the others whose code is mixed into their output).<br/><br/>I do hope I have proven my point, so that courts will follow current law and this interpretation (based on an understanding of how computer programs work) and policy makers will not loosen up the laws in an attempt to help &ldquo;AI&rdquo; (which will only worsen commercial exploitation of the creatives, those copyright law is supposed to protect).<br/><br/>While I do not have a background in law, I&rsquo;ve got extensive background in Open Source licensing (both software and non-software) and have been a member of the OSI license discuss and review boards for years, all in my spare time, and I&rsquo;m the current software licensing expert at my place of employ, and I&rsquo;ve read up to extend this knowledge to pastiches and the Free Sheet Music movement. I&rsquo;m also a computer programmer with 33 years of experience (35 years of computing experience, including building computers and their operating systems from the ground up).