I&#39;m an artist who became unable to draw due to a disability. Because of this, I&#39;ve been making greater use of digital tools to create artwork.<br/><br/>I use 3D modeling, procedural materials, photo editing filters, and digital painting. And more recently, I trained an AI model to render images in my style. All of my work involves several of these tools. Ultimately my goal is to convey specific ideas and concepts, so it doesn&#39;t matter what tools I use as long as the end result is novel and compelling.<br/><br/>On the subject of AI and copyright, there are two issues I would like to comment on:<br/><br/>AI in principle:<br/><br/>Generative AI is a type of procedural generation tool. There is extensive precedent for the use of procedural generation tools in digital art, CGI, videogames (Rogue 1980, The Elder Scrolls II: Daggerfall 1996, Spore 2008), and even creative writing. There are physical analogues as well: drip painting, marbling, automatic drawing.<br/><br/>However, despite its long history, procedural generation is not widely known to the public, and this causes misunderstandings about authorship. The current consensus seems to be that if I create a work in Blender or Houdini, the work is assumed to be mine; but if I create a work using Stable Diffusion, it is assumed to be the work of a computer. This is clearly an oversimplification and ignores decades of art history. This is not surprising; it has happened every time a new technique or tool has emerged that challenged our notions of art: Jackson Pollock, Andy Warhol, Photoshop, digital art tablets, CGI movies... Can&#39;t we take a moment to look back through art history so we don&#39;t rehash the same debates about authorship over and over?<br/><br/>When it comes to AI, the degree of creative control involved can vary widely. For example, Stable Diffusion supports complex multi-step workflows (SDXL+ComfyUI, ControlNet) that allow for a considerable degree of creative control. This puts it in a similar category as 3D modeling programs such as Blender and Houdini, which support a range of workflows from fully handmade models to complex node-based procedural generation sequences. From a subjective standpoint, it feels like being an art director, and giving instructions to a team of 2D artists, 3D artists, and technical artists.<br/><br/>The bottom line is: AI isn&#39;t that different from what came before. Therefore, the discourse and regulations around it, specifically about copyright and attribution, should be consistent with those of other similar disciplines, workflows, and tools.<br/><br/>AI in practice:<br/><br/>There are many loud voices claiming that all use of AI is inherently bad and upon the work of artists. This is factually wrong, since artists themselves can use AI, as I do.<br/><br/>In practice, however, most AI work being done today uses a pre-made model as a base. In AI art, this is usually Stable Diffusion; in text generation, it&#39;s GPT-2+. These models are trained on copyrighted works. This poses the risk that all AI works created from these models may be derivative works.<br/><br/>In this state of affairs, how can we reconcile AI and ethics?<br/><br/>Currently, one of the few major &quot;ethical&quot; models is Adobe Firefly, an image generation AI tool trained on stock images owned by Adobe. Firefly is only available within Adobe software, which is paid.<br/><br/>In theory, any individual or entity can do what Adobe did: grab a dataset that they have the rights to, and create a model from it, through the publicly available stable diffusion technique.<br/><br/>In practice, no one has bothered to curate, download, and validate a large scale fully public domain dataset of decent quality, let alone LAION-2B quality. And no one has offered to pony up the $600,000 in compute costs it takes to train a model like Stable Diffusion 1.5. There is no incentive for anyone to create ethically sourced models. In the current landscape, ethics is unprofitable.<br/><br/>Likewise, there is no incentive for individuals to use ethically sourced AI models, because it&#39;s hard and/or expensive, and the unethical ones are easy and cheap to use.<br/><br/>Finally, there is no incentive for artists to enrich AI with their works and their creative input.<br/><br/>This, right here, is what regulations exist to address. Make it easy and profitable to do the right thing. And make it hard and unprofitable to do the wrong thing.<br/><br/>Make it easy and profitable for entities with capital to create open-source, public domain, non-copyright-infringing AI models.<br/><br/>Make it easy and profitable for individuals to access, use, and modify these models.<br/><br/>Make it easy and profitable for individuals to reap the benefits of AI without forfeiting authorship. Make it easy and profitable for individuals to claim and enforce attribution for the part they played in the creation of a work.<br/><br/>Make it difficult and unprofitable for corporations like Stability AI to commit large scale copyright infringement. Create a landscape where AI companies can compete on ethics.<br/><br/>It&#39;s a question of incentives and penalties.