Generative tools should never receive any of the very authorship protections that their proliferation is violating en masse. Legitimizing mass information theft would be a mass invalidation of human rights.<br/><br/>The biggest datasets that companies like LAION trained their diffusion algorithms on were assembled  through massive fraud in the EU. They obtained government permission for a massive data trawl on the condition of non-profit research, scraping everything from art to medical data. However, the resulting datasets were then just transferred to for-profit companies that even had the same name.  Those datasets then became commercial assets for the business of diffusion tools, and that brazenness fostered entire communities that copy art without consent.<br/><br/>Stable Diffusion/Stability AI was especially brazen, because they use the same name for both companies, and they set their model up in a way that shows they know what they&#39;re doing is wrong. Their music version of this system is only trained on copyright-free music. Writing and visual art don&#39;t get that treatment. So it&#39;s about the crimes they can get away with, not about the rights of artists. They even avoid the word &#39;artist&#39; in their entire product description.<br/><br/>https://openai.com/blog/openai-lp/ Open AI goes a step further and tries to pretend that they came up with a &quot;capped-profit&quot; model as justification for commercially using information obtained for non-profit purposes.<br/><br/>Patients throughout the EU have even found their private medical information on these datasets through the https://haveibeentrained.com/ tool.<br/><br/>Even should future regulation somehow ensure that only tools that have not PRIORLY been refined through unethically obtained datasets are spared the rod (A verification task that would be utterly impossible), allegedly ethical tools could still be used to exploit human artists of all types. The products of these tools are, plainly put, counterfeit of sufficiently intricate complexity to pass scrutiny from those who either do not stop to consider the violation being performed, or rushing ahead of the law while the technicality allows.<br/><br/>A case could be made for the use of such tools to create smaller components of a much larger piece, such as digital brushes, or textures to be corrected by a human hand in the process of modeling a simulated 3-D landscape. <br/><br/>However, it must be stated unequivocally that refining pattern-imitating tools through the unauthorized use of an individual&#39;s work is nothing short of that: Counterfeit. It&#39;s not akin to a conscious being studying another&#39;s craft in order to improve their own, but akin to stealing their property to feed it into a template-creating machine. No authorship or originality should be recognized, because the creation of a piece through generative AI is a method inherently meant to avoid such.<br/><br/>