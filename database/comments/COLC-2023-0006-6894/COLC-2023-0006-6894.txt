Hello, I have been keeping track of the AI discussion for a while and I&#39;ll be frank: AI generation will exploit artists, creatives, and people as a whole. Industries have already begun to use these machines in favor of cutting things shorter for their own greed and I do not want to keep seeing people&#39;s livelihoods ruined. This is the thing that deserves to be heavily scrutinized because if we have serious claims when it comes to sampling music, not crediting people properly in papers, and straight up fraud - AI should automatically be given a wide berth and more. There may be AI art defenders who insist that this is a harmless practice, but if that was the reality, we wouldn&#39;t be seeing so many people in these AI communities try to hide and disguise the fact that all of it is AI. They&#39;ve developed other processes to make it look like they&#39;re actually creatives and not openly stealing from actual artists. They&#39;ve made a thing in which it is possible for the machine to make a &quot;process&quot; for the generated art and have actively started rephrasing AI art in other terms in order to fool the people and gain monetary value. If generative AI is to ever be used, I think that these projects involving AI shouldn&#39;t be allowed to profit at all and should be public domain the moment they start using it. Nothing should be profited from this type of technology, especially with how predatory many companies are. The SAG-AFTRA strikes are a good example of how many of these big corporations will not let go of any means of shortcuts regardless of how lower quality it is and will continue to sink even lower in their ethics if we allow these things to happen. We live in a society that actively preys on the vulnerable but we should continue to fight back, if we want a better future for everyone,  for both consumers and creatives. Look at all the strikes that have been happening these past few months and please, let&#39;s strive for policies that fix the disparity and exploitation of these technologies. 