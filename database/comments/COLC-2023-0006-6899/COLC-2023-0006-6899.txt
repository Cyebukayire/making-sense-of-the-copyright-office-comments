I understand networking and software. You&#39;re asking the wrong question, because machine learning is not at a state where it can produce AI. <br/><br/>There is no current model of machine learning, even the weighted bias systems currently known as &quot;AI&quot; and &quot;Neural Networking&quot;, that allows for independent creation. It&#39;s all predictive, based on previous training. It cannot train itself, it cannot provide anything but the statistically probable answers to questions it is given, and it cannot create anything for itself. <br/><br/>While this alone would preclude it from copy rights (being that it is both not making original works and not even making collages so much as deciding what is most probably like that thing you asked it for, and thus, having no volition to create), the fact that most current models and training sets have been created by scraping entire galleries that are not their own, and not paying any of the artists for work that they are now asking other people to pay good money for, indicates that they are not, in fact, acting in good faith when having the Copyright Office consider this question. <br/><br/>In short, they have already committed mass plagiarism, and are now asking the Copyright Office to change the rules to allow this plagiarism without reserve, because it has stolen from too many sources. <br/><br/>This is not to say this cannot be used responsibly-- in some ways, the use of neural networks to handle work better rendered by machine is well-known-- but this is far from the most famous uses and not ones that would come up as violations of copyright in any case (interpolation immediately comes to mind.) <br/><br/>As for who should hold liability when an AI is shown to be plagiarizing, there are two possible liabilities-- the company or companies that produced the AI, and the end user who requested it. I would venture that both are liable, but that the company or companies that produced it more so. 