I feel that computer generated content will have a negative impact on the creative industries.<br/>It&#39;s made me scared as an amateur illustrator to open up commissions because I will likely receive even less requests for commissions than I would if AI image generation did not exist, because instead of a tool to help those who create, AI is being used as a complete replacement for the artist themselves.<br/>It&#39;s already unlikely that I&#39;ll be able to support myself on commissions, but AI generated content being used as a replacement for artists is definitely not helping.<br/><br/>I do not believe AI generated content should be copyrightable, and I believe it should be legally required to state when unaltered or minimally altered AI generated content is used. In many cases, the data to train AI models is taken without the consent of the people who created it in the first place.<br/>Perhaps it should be legally required to publicly announce when you are looking for data to train an AI model so that all of the data collected can be submitted instead of stolen, such that the data was given with consent.<br/><br/>The way AI generated content is used now is a threat not only to the creative industry, but individual artists like myself who do not wish to join the industry and sell or are planning to sell commissioned art just to get by.<br/>This is devastating to me as someone who sees the potential for AI generated content to be used as a tool to help creatives, but like I said earlier, it is instead seen as a replacement.<br/><br/>AI generated content should not be legally allowed to be a replacement for the human artist. This goes for illustrators, graphic designers, actors, voice actors, and writers.<br/>Please do not let AI generated content become copyrightable. This will play a part in the death of the creative industry and ruining the lives of individuals.<br/><br/>I apologize for any incoherency in the comment, I am very distressed about the AI situation and I am also generally not good at communicating.