Below are answers to selected questions from the Artificial Intelligence and Copyright document.<br/><br/>1. AI systems have already started harming creators in many fields. This harm is most obvious in the art field. I know of artists who were banned for plagiarism on platforms like DeviantArt because their art was too similar to AI-generated pieces, when the AI had used those artists&#39; work in its training set. This shows the danger of AI being able to scrape data and use it to generate material without creator consent: It denies creators the option to defend themselves and their own, original material. AI creates an impossible case of &quot;the chicken and the egg.&quot; What came first? How can an artist prove that a new piece of art, which doesn&#39;t predate the AI-generated material, is rightfully theirs? How can they prove that using their own style in their art isn&#39;t a violation of a machine&#39;s copyright? Protections must be put in place to prevent this situation from continuing.<br/>For voice actors, AI poses a serious threat. Not only can AI replace them by mimicking their voices (an especially heinous theft, in my opinion, as their voices aren&#39;t just material they create, but a part of them), but it can harm them in other ways: One voice actor I know of had someone used her voice in an explicit, AI-generated song, a song that then posed a threat to her future ability to find work, as potential employers could find the song and reject her application on the basis of inappropriate behavior---behavior she never engaged in and had no control over.<br/>On a larger scale, AI-generated works harm creators by devaluing their work. This is obviously present in art generation, as discussed above. It&#39;s also highly prevalent in word generation (my field of experience, as a writer). Already, many workplaces are turning their writing staff into editing staff: Instead of directly writing content, the employees edit AI-generated material. This frequently means employees are given less time and compensation to produce the same amount of material, as the AI is theoretically completing the majority of the work (I discuss how this theory is frequently false in my answer to question 21). Other positions have been replaced entirely.<br/><br/>9 &amp; 15. Copyright owners should have to opt-in to the use of their works, and developers of AI models and training sets should be required to collect, retain, and disclose records regarding the materials used to train their models. If a person plagiarized a group of creators and tried to pass the combined result off as their own work, they wouldn&#39;t be provided the protection of copyright---why should programs that do so on a larger scale be given that protection? When AI developers aren&#39;t required to track whose materials they&#39;re using, the law displays a blatant disregard for creators and copyright, as it makes it more difficult for creators to prove their claims (the &quot;chicken and the egg&quot; issue discussed above) and makes it easier for plagiarism to continue unhindered.<br/><br/>21. I do not believe that giving AI-generated material copyright protection would promote the progress of science and useful arts. If anything, giving AI-generated material that level of legitimacy could harm the progress of science and useful arts. The company I work for has been experimenting with ways to incorporate AI such as ChatGPT into our work processes, primarily by asking for information on a certain topic, along with sources. We have found that these AIs are accurate barely one-third of the time. Most of the time, the AIs generate faulty, inaccurate information and invent false sources. For example, it generated a citation of a scientific journal, complete with issue, page number, and all other information needed to make the source look legitimate. However, when my coworker investigated the scientific journal, locating the issue and page number cited, the article that actually existed was about a completely unrelated topic. Further searching showed that the article cited by the AI had never been published by that scientific journal. This &quot;deep fake&quot; trend is extremely concerning for the progress of science and useful arts, as it encourages people to view these AIs as trustworthy sources of information, while providing no real legitimacy and creating misinformation. It also reinforces the issue with writers being demoted to editors (discussed above), with higher workloads and lower pay: My coworkers found that it actually took more time to fact-check AI-generated material than to research and write the material themselves, which means these employees are even more overworked and underpaid.<br/><br/>25. The developers of AI systems and models should be liable for copyright infringement, not the end-user, as the developers are the ones collecting and incorporating the materials, as well as presenting the AIs as licit.<br/><br/>28. AI-generated material should be publicly labeled, as a label would make it easier to identify and support real creators.