I&#39;ve skimmed most of the preliminary material, but I&#39;m only going to give very specific comments/answers. I come from the technical perspective who has done research on trying to understand what machine learning actually learns.<br/><br/>My first comment is I see ML evolving over time from purely memorizing content to reasoning, creating, and even thinking. When, if ever, AI reaches &quot;human-style&quot; cognition, then I would think that laws as applied to humans would also apply to AI. As a simple analogy, humans consume copyrighted material all the time, but will often then create novel material that doesn&#39;t infringe on copyrights. In some small percentage of cases, humans do produce derivative works or even plagiarize, but this can then be detected and the copyright owner can choose to pursue.<br/><br/>The challenge is that we do not have good metrics or analysis tools to determine what is happening inside a ML model, whether it is simply displaying memorized content or derivatizing to a large degree. Right now, I think copyright owners are recognizing their content in AI-generated work as either exact duplication or close derivatization, which I assume (and I&#39;m not a legal expert) tilts in favor of copyright owners. In other words, the current laws should protect them.<br/><br/>The next question then becomes if the AI, for now, is more of memorizer/derivatizer, should the models be trained on copyright content, knowing full well that a good percentage of their output will be copyright violations, especially if the output will be used for commercial purposes? I&#39;d say we need to allow the training of models that include copyright content for research purposes, but at the same have some guard rails to protect the copyright owners from misuse of the output. It could be as simple as a &quot;warning&quot; like Meta uses with its LLaMA models where they say &quot;you can use this model for research, etc, but not for commercial use&quot; I assume Meta has this restriction mainly because they trained on copyright material, but I don&#39;t know for sure. It could also be restricted by selective pursuit of &quot;license violators&quot; - people that egregiously use output of generative AI models that have been labeled as &quot;trained on copyright material&quot; to make money.<br/><br/>Lastly, I&#39;m sure I&#39;m not first to think of this, but copyright owners could create a &quot;pool&quot; not unlike songwriters do with ASCAP. If anyone chooses to use generative models trained on copyright materials for commercial purposes they pay a tax to this pool. The pool proceeds are then distributed to all of the copyright owners based on their fractional contribution of material to the pool.<br/><br/> 