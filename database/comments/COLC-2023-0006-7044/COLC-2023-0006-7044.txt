I&#39;m a US government researcher who has worked with generative AI for ~8 years now. I have no problem, in principle, with generative AI - if it&#39;s trained on proprietary, licensed or copyright-expired data. A company should not be able to externalize all of the costs of creating the training data, then turn around and copyright or profit from the trained model, and the onus should be on the developers to prove or certify that their model was created only with licensed data. If a person&#39;s work is used to train a generative model, they should consent to and be fairly compensated for the use of their work. Yes, this will make it more expensive for companies to train new models - but it will also foster more healthy relationships between creatives and tech users, which have historically been very one-sided. The concept of &quot;fair use&quot; is inherently subjective, and based around the concept of fairness. A business that justifies its unethical data-scraping practices as cost-effective is in the same position as a business who fights unionization. Unions provide leverage for workers to bargain for fair compensation for their work. Requiring companies to obtain permission from creatives and compensate them for their work will not stifle innovation; rather, it will allow creatives the same type of leverage. There is a VAST wealth of non-copyrightable material out there that these companies could use to train their generative models, if they wanted. The fact that they haven&#39;t already done so is very telling. It&#39;s already very difficult to make ends meet as a writer, artist, musician, etc. - there is no justification for allowing tech companies to profit from these people&#39;s work without obtaining their permission and providing fair compensation.