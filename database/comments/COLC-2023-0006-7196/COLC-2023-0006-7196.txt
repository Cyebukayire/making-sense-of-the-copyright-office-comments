Generative AI (genAI) is being touted as a benevolent technology that can improve society, but the reality is that genAI is causing widespread harm and is emboldening tech companies to push ethical boundaries.<br/><br/>First, LAION5B has been proven to have the faces and names of real people in their datasets as well as addresses, emails, and bank accounts. Stable Diffusion and Lensa took users&#39; private medical data and facial biometrics without the users&#39; consent. The founder of Stability AI has stated that if public data would be exhausted, bypassing firewalls would be the next option (i.e. hacking users for their private information). Currently, Google has changed their privacy policy that allows Google to scrape users&#39; private data to train Google&#39;s AI projects-but again- without users&#39; consent and no prior notice to allow users to wipe their data.<br/><br/>What about the dangers of genAI being built from this data and having this technology available for everyone to use? Thanks to the scraping of biometric data, it is possible for users of genAI to create massive quantities of pornography based on real people without their consent (this extends to children as well). Despite what AI advocates may say, this data cannot be unlearned without replacing current AI models with older versions. What that means is the identities and likenesses of these people will inevitably resurface as AI develops, even if users do not intend it.<br/><br/>Another concern of AI is how it contributes to spread of misinformation. But before that, it must be understood that AI is not actually intelligent; it only resembles human intelligence. That is why if one were to ask ChatGPT-for example- &quot;What does 2 + 2 equal?&quot; ChatGPT may get it right, maybe even on the first try. But ask again, and ChatGPT may respond with 5. Or one can simply insist the answer is 5, and ChatGPT will eventually agree. AI is incapable of being intelligent because it is unable to conceptualize ideas like mathematics. AI can only make approximations based on the data given, and AI ingests data indiscriminately.<br/><br/>Therefore, it would be unwise to have AI at the forefront of most logical or creative endeavors unless the AI models in question were carefully trained in closed environments by professionals. But most models like ChatGPT are not trained like that. Even more concerning, tech companies are insistent on selling users these public models on the premise that AI can do almost anything: journalism, therapy, movie directing, policing, etc. We have already seen cases of how unreliable or dangerous AI can be like a lawyer using an AI for assistance only to discover the AI fabricated court cases. Or how one user committed suicide when encouraged by an AI. <br/><br/>Lastly, there is the issue of how AI relates to the workforce. Another common selling point of genAI is how it can be a tool to aid workers with menial labor. While I could go on to dispute how such claims do not hold weight in creative fields like writing and digital art, the more important point of the matter is that AI is not being used to help workers but to replace them altogether. We can see this overseas where the Chinese video game industry has laid off nearly 70% of their artists in favor of AI. Voice actors are under threat of Hollywood replacing them with AI trained with their voices. ChatGPT is capable of creating fully-fleshed stories in minutes, and online stores are flooded with AI created content. And artists have been seeing a steady decline in online commissions which are crucial to an artist&#39;s livelihood. It is evident that AI is taking far too many jobs than creating them, and we could see a surge of unemployment in the coming years unless adequate AI regulation is drafted and enforced. <br/><br/>When discussing AI regulation, it would be irresponsible to disregard these facts. Bearing that in mind, here are some of the regulations I would like to see:<br/><br/>1 - Require websites to tag AI content<br/>2 - Enforce a reasonable limit on AI usage for companies to ensure stable human employment<br/>3 - Restrict AI models to be trained opt-in only<br/>4 - Full public disclosure of the datasets AI models were trained on<br/><br/>But above all, it is paramount to have real artists, writers, and various workers affected involved in these discussions of regulation. They would offer even greater insights to what regulations are needed to have AI ethically exist in our society.