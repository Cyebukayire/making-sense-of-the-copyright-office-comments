1. AI has the potential to be a fun reference or inspiration point. It also has the ability to cause damage to person or reputation by falsely imitating a human, or replacing the work by a human. Plagiarism and self plagiarism is not appropriate, why would asking a computer to take another humans work and turn it into something you can claim as your own be appropriate?<br/><br/>2. As a curriculum developer, educator, and performer, AI is something to keep an eye on. While not yet a threat, in the future AI could be used to write curriculum based on my work, imitate my voice or likeness in educational material, or reduce the need for creative professionals in my field.<br/><br/>5. Yes, new legislation should be considered. On a mass level of AI trained on humans intellectual or copyrighted property without their knowledge, consent, or compensation. And on an individual level , eg, AI books generated with false information or under false pretenses for monetary gain.<br/><br/>6. It is my understanding any public work is being used to train AI. Books, amateur writing, news articles, home videos, paintings. I assume they get these documents from the internet or scan them in, and feed them to the AI. This seems to be done without or contrary to the original copywriters consent.<br/><br/>7.To my knowledge, AI are given materials and told what it is and learn to replicated based on those parameters. I do not know that they can &quot;unlearn&quot;, but it seems likely they can &quot;relearn.&quot; It is possible to spot influences and biases in the original training based on the completed generation.<br/><br/>8. I can&#39;t think of a circumstances in which the unauthorized use of copyrighted works to train AI models would constitute fair use. If a computer that compiles data points counts as AI (where the researching is comparing different studies to their own to come to a conclusion) then that might be a circumstance.<br/><br/>9. Copyright owners should have to affirmatively consent (opt in) to the use of<br/>their works for training materials. No assumed consent. No opt out. Only an opt in, only asking for consent. Without a doubt. It should be required for all uses of AI training, and they must opt in to each training model. Each company should ask each copyright owner to opt into their training, instead of a blanket consent for all models.<br/>9.2. An &quot;out out&quot; method is impossible. How is every copyright owner supposed to be alerted of the option to opt out? How do they fill out a convoluted form with each company? What then when they miss the opt out period? What when their work has already been used and they dispute it, does that ruin the date for the AI, or does the owner lose their work and gain nothing? No, opt out is not an option. <br/>9.3. Likewise would be difficult to gain consent from copyright holders. However opt in is easier and less damaging than opt out.<br/>9.5. As my profession for an example, the curriculum I make becomes property of the university I create it for. Therefore they can opt into my work being used for AI training and I do not have the ability to opt out. While I may not like that, as current copyright law stands it makes sense.<br/><br/>15. Yes, developers should be required to retain and and disclose everything that their models were training on, including information on the developers themselves.<br/><br/>28. Yes, AI generations should be clearly identified as AI including what program they were developed with. Both the publisher and person responsible for the generation should  make this clear. Works already contain copyright notices in one form or another, adding identification of AI generation shouldn&#39;t be an issue.<br/><br/>32. There should there be protections against an AI system generating outputs<br/>that imitate the artistic style of a human creator. Everyone should be eligible for this. Should an output that imitates the artistic style of a human creator, be style, voice, features, ect, their explicit consent must be obtained first. If the human is dead, consent can no longer be obtained and it should be assumed that they do not consent to their likeness or style being replicated for someone else&#39;s&#39; gain.<br/><br/>Other thoughts:<br/>If authors can&#39;t read fan theories or fanfiction of their work, (to avoid &quot;stealing&quot; ideas from the fans), why should an AI be allowed access to all of that information to build something on with no credit to anyone?<br/><br/>AI should not be used to imitate an an artist, performer, or other persons likeness, voice, or features. It should not be used to pass off a work &quot;done by that person&quot; or claim the person (living or dead) did or consented to the work produced. Certainly not when the person being imitated receives no credit, acknowledgement, or monetary reconciliation.<br/><br/>How do we address biases in AI? Racial and ableist biases are already being recognized.