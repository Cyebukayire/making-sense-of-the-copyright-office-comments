In regards to question 9 in the &lsquo;training&rsquo; section. <br/><br/>Copyright holders should have to affirmatively consent to have their works used in training materials. Consent to have their works used is important. For many artists, their distinct style (entirely human and their own) is their livelihood. If someone is able to reproduce it with a machine, it could cause a confusion of authorship. If that author is still living and producing work, it could draw people away from their practice. Engines that allow their products to be in commercial use should always be opt in. Those purely for personal use could be opt out. Opt in also protects authors without the ability to agree, like those who have passed away. Opt in allows artists to be in control of their work and how it is used, particularly if the entity using it is making money off of it. <br/>Many people who create art have licenses on their works, for example Getty images holds copyright protection on their photos and has the ability to license them. If an AI is trained on these images, why would anyone go to Getty images when they could make something similar with the AI image generator and then claim the copyright without any compensation to Getty. Getty has filed a lawsuit against Stability AI for just this reason (Brittain, 2023). Stability claims that the engine constitutes fair use. This is its own issue that is highly debatable. Litigation is still underway on this issue as many factors are at play in line with act 107 of US copyright law. An opt out methodology seems like a good way for users to get around the copyright system and get around paying creatives for their work. <br/>Opt-in allows for artists who want to contribute to contribute, and for artists who don&rsquo;t to hold their entire copyright duration. Once a piece enters public domain it is fair game, but before that there should be protections in place for engines that are producing works for commercial use. If a program is opt-out, there needs to be distinct notification to the copyright holder of a particular work that their work is being used in an ai dataset. This way they actually know that their work is being used and can make the decision to revoke the rights to their work in that function. Transparency is key in these instances. It should also be easy to opt in or out. Currently many engines use an opt out model and artists have to actively take down every single piece of artwork, which is a lot of extra effort to not have their art trained on (Xiang, 2022). <br/><br/>Brittain, Blake. &ldquo;Getty Images Lawsuit Says Stability AI Misused Photos to Train AI.&rdquo; Reuters, Thomson Reuters, 6 Feb. 2023, www.reuters.com/legal/getty-images-lawsuit-says-stability-ai-misused-photos-train-ai-2023-02-06/. <br/>Xiang, Chloe. &ldquo;Ai Is Probably Using Your Images and It&rsquo;s Not Easy to Opt Out.&rdquo; VICE, 26 Sept. 2022, www.vice.com/en/article/3ad58k/ai-is-probably-using-your-images-and-its-not-easy-to-opt-out. <br/>