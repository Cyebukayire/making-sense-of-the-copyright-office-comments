To me it seems imperative that the public have control over the way that ai is used so that companies like Disney, Amazon, etc cannot use AI to disempower humans. For instance, I think artists and creators should have final say over whether or not their material can be used to create generative models or AI. Likewise I believe that if a persons creative output, likeness, or other personal identifying characteristic is used in the creation of AI, generative models, etc, the original creator should be duly compensated with royalties commensurate with the goods or services provided. Importantly, I believe that if your content was used to create a generative model, you should receive partial ownership of the output or profits from the model.<br/><br/>I have used Ai or generative models to complete a wide variety of tasks:  assisting me with work for my job, as a peer to work on computer science projects, and to generate images and text for creative projects. Largely, I find it to be incredibly useful, but I fear that the wrong parties profit from the services that I use. Particularly when generating code with AI, I can only assume that the code on which the Ai was trained must have been plagiarized; for something as syntactically specific as computer programming, what is the difference between using an AI to write code and simply copying it from someone on the internet?<br/><br/>In short, I think the many versions of AI that we see today and will continue to see are valuable tools for humans, but I think it is vital that humans and creators be able to profit before companies who might own or employ the AI. While it goes beyond the scope of copyright, the rapid development and potential benefits or costs lead me to believe AI should be nationalized and strictly directed by the public. 