&quot;5. Is new legislation warranted to address copyright or related issues with generative AI? If so, what should it entail?&quot;<br/><br/>The tech sector stands to profit immensely off the labour of the creative sector, which was already chronically underfunded. At the very least, there should be an &quot;art tax&quot; imposed on companies training (or using?) generative AI, with the proceeds going into supporting writers, artists, et al., be it via grants, scholarships, events or other avenues.<br/><br/>&quot;9. Should copyright owners have to affirmatively consent (opt in) to the use of their works for training materials, or should they be provided with the means to object (opt out)?&quot;<br/><br/>It should have been opt-in from the beginning. This ship has largely sailed, since OpenAI and co. have already fed innumerable works into their models without consent. If it becomes opt-in now it will just serve to gatekeep the technology and lock smaller players out - but even with these concerns in mind, I believe it should be opt-in. I&#39;ve witnessed the kind of chaos and subterfuge that companies are willing to inflict on consumers when implementing &quot;opt-out&quot; policies (cf. the deliberately obnoxious and convoluted cookie popups after EU&#39;s GDPR).<br/><br/>&quot;15. In order to allow copyright owners to determine whether their works have been used, should developers of AI models be required to collect, retain, and disclose records regarding the materials used to train their models? Should creators of training datasets have a similar obligation?&quot;<br/><br/>Absolutely, they should be made to disclose their datasets. Vince Gilligan rightfully called generative AI &quot;plagiarism machines&quot;, and the lack of transparency makes them even shadier and more immoral. As far as I understand, it is impossible to trace the precise sources of a given AI-generated product, but we should at least have access to the overall training data. (Some of the datasets that have already been leaked, like Books3, have been pretty instruuctive.)<br/><br/>&quot;25. If AI-generated material is found to infringe a copyrighted work, who should be directly or secondarily liable&mdash;the developer of a generative AI model, the developer of the system incorporating that model, end users of the system, or other parties?&quot;<br/><br/>The developer of the model.<br/><br/>&quot;28. Should the law require AI-generated material to be labeled or otherwise publicly identified as being generated by AI? If so, in what context should the requirement apply and how should it work?&quot;<br/><br/>I believe all AI-generated works should feature a watermark, in the same way that authentic dollar bills feature a &quot;watermark&quot;. In the case of both art and text it could be a particular pattern (of letters or pixels) that can be verified through the use of a specific tool.