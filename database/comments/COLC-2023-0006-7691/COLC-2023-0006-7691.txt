Whether considered a buzzword or a bad word, AI has become a topic of conversation recently. But AI is not a monolith. The average American drives to work with a GPS directing and redirecting the route. At work, the computer pings a reminder to make a phone call, which a flat voice answers before putting them on hold. To pass time, the worker plays chess on the computer, ignoring the surprisingly-tempting ad. Few realize how frequently they use AI already, or that these mundane, specialized uses of AI are closer to what AI professionals anticipate than the pop culture understanding of AI.<br/><br/>Even for a given AI tool, the implications differ based on the specific application and process. For intellectual property issues, there is a relevant distinction between generating text, versus images, music, computer code, and most anything else. Text is predictable. No matter how creative, about 7% of any English text is just the word &quot;the&quot; itself. Along with other functional words (like &quot;at&quot;, &quot;be&quot;, and &quot;that&quot;), that accounts for about half of all words. Any comprehensible, grammatical prose will follow these rules. In all languages the frequency of words follows Zipf&#39;s law&mdash;the second most common word will be about half as frequent as the most common, the third about a third as common, and so forth. This predictability is the basis of technologies like spellcheck and autocomplete.<br/><br/>Generative AI is a subset of machine learning, a form of AI where computers are given data and a task instead of instructions, and the computer detects mathematical patterns in the data. The fewer possibilities, and the more data, the more mathematically predictable the result is. Only 26 letters, 5 punctuation marks, and spacebars can compose poems, novels, and textbooks without any noticeable loss. In contrast, most phones take photos with at least 12,000,000 pixels, each with 3 values for color. For video, multiply by at least 24 frames per second to appear continuous. And not only is training text generation simpler, the volume of training data is much more vast and less likely to involve copyrighted material&mdash;most of what has been written in modern English belongs to the public domain, with copyrighted works locked behind paywalls or not online, whereas high quality digital images are largely from the last couple decades and more likely to be accessed online, with watermarks to indicate copyright status.<br/><br/>Therefore, there is a high risk of AI-generated images mimicking the quirks and signatures of individual creators in such a way that threatens intellectual property (or, ironically, add the Getty watermark itself). By comparison, text generators are highly unlikely to plagiarize or even resemble an individual author or text. In fact, no human being could read anywhere near the 45 terabytes of data (360 trillion bits), which is about 10 trillion words&mdash;about 8 billion hours of reading to only around 1 billion hours in the longest ever human lifetime (122 years). Arguably, our individual styles are more likely to accidentally resemble another person&rsquo;s by chance (Larry Potter and His Best Friend Lilly by Nancy Stouffer came out in 1984), not even considering that the texts we read are more likely to be copyrighted than texts readily available to train AI models, such as obscure public domain documents and Wikipedia. Stylistically, the hallmark of AI-generated texts is predictability, to the point where ChatGPT detectors look for texts with higher predictability, lacking the idiosyncrasies expected from individual human beings.<br/><br/>Though generative AI is much less problematic in practice than in theory, there is risk. Copyright also exists to make creators feel secure from theft when sharing their hard work, motivating productivity. Regulatory actions to protect individuals include limiting where training data can be obtained, requiring permission for certain uses (such as commercial generative AI), allowing opt-out for individuals or organizations, and mandating/incentivizing transparency in AI training. <br/><br/>By the same token, users of AI text generation also deserve copyright protection. Hype has obscured the simple truth: it is advanced autocomplete. AI doesn&rsquo;t &ldquo;know&rdquo; anything. It is a &ldquo;stochastic parrot&rdquo;&mdash;like a parrot echoing the words it hears most often without comprehending them. It&rsquo;s a convincing illusion, especially with randomness leading to new, unpredictable results. But it only becomes content once a human observes meaning in the randomness, like a photographer noticing a beautiful view. The photographer doesn&rsquo;t create the landscape, but the choice to photograph it, the framing, and other stylistic choices turn it into art. One photography was considered mere observation, a shortcut for producing images without bothering to train as an artist. But while the camera facilitates the process, it is not the camera or manufacturer, but the photographer who deserves credit and responsibility.<br/>