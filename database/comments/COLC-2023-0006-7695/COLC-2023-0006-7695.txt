1. Generative AI sees patterns; it is not capable of true analysis. One example from the medical field was that of a pattern AI found that was consistent will all the cancer biopsies it &ldquo;analyzed&rdquo;&mdash; the presence of a metal ruler near the sample. This is a very obvious example, but without intensive human oversight, generative AI will create very flawed solutions to problems without accountability if implemented. As an artist in the entertainment industry; I create art which is used in the production of movies, games, TV and books. AI steals patterns of shape and form created by artists and creates a simulation using prompts (an average of 13 words) provided by the user. AI steals the art styles of artists and uses their work to create new work in a tiny fraction of the time it takes a human to do the same. The man-hours and manpower it takes to create art with AI is a tiny fraction of what it takes humans to create similar results. The work of artists and artisans will be rendered unnecessary with this technology. Movies will be created with a few minutes of typing&mdash;basically creating a new passive income stream for the investor class and distributors and destroy jobs for artists. Free work. Artists cannot compete with free. The value of their work will drop to nothing. Artists, art teachers, and all industries used by artists will become irrelevant. Our jobs will go away.<br/><br/>2. AI uses our art to train the programs that will replace us. It&rsquo;s comparable to American workers training the workers who will outsource them. At least overseas outsource workers are humans that get paid. AI works for free. Artists cannot compete with free. We&rsquo;re poor enough already. <br/><br/>3. https://www.youtube.com/watch?v=9xJCzKdPyCo&amp;t=17s<br/><br/>4. We have built civilization on the bartering of skill and labor. Have we stopped to think what would happen in a society in which labor is suddenly no longer necessary?  AI in the wrong hands is completely nihilistic. Regulation is absolutely necessary.