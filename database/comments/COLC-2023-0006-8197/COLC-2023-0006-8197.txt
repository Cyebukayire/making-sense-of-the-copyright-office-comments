When a painter creates a work, the brush does not hold the copyright, the painter holds the copyright. It is not different with &quot;artificial intelligence.&quot; If a painter copies someone else&#39;s style, that&#39;s a copyright violation. It doesn&#39;t matter what tool the painter uses. If someone uses an AI model to copy an artist&#39;s writing or drawing style and publishes the result, if this does not fall under fair use, that&#39;s a copyright violation - it doesn&#39;t matter what tool is used.<br/><br/>Because &quot;artificial intelligence&quot; is such an efficient violator of copyright, because there is no way to identify an AI model&#39;s sources, and because it is impossible to delete a work from an AI model it is both appropriate to insist on an opt-in model for works used to train an AI model and insist that model builders keep records of what works are used to train their AI models.<br/><br/>Because AI models are statistical models, their output is not reliably accurate; like a human simply making up writing for its sound and persuasiveness, they can be wrong but persuasive. AI models can also &quot;hallucinate&quot; - produce content that is similar to that of a delusional or brain-damaged person. It is therefore important that AI output be flagged, lest people trust it and endanger themselves.