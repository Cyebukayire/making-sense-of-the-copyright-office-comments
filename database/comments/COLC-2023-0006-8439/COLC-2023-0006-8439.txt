I believe that current ML techniques rely on massive violation of the rights of creators. Training effectively fragments copyright protected works so that they can be &quot;reintegrated&quot; into derivative works that often directly compete with the original. If this is allowed to continue, there will be no incentive for humans to produce works.  However, AI works are ultimately statistical pastiches of human works. Generative AI, as it currently exists, will not produce new styles or ideas.<br/><br/>It is worth noting that current AI companies and researchers are attempting to establish &quot;facts on the ground&quot; which completely disregard copyright. They are attempting to make their models popular and common enough that they can never be held responsible for massively violating copyright since &quot;it would be too economically and socially disruptive.&quot; It reminds me of Napster.<br/><br/>Moreover, many of these companies talk of creators being allowed to &quot;opt-out&quot; of AI training, yet none of them have implemented effective mechanisms for this, and all these companies ignore website terms of services which already prohibit data scraping.  &quot;Opt-out&quot; is only a smokescreen, intended to distract from traditional copyright protections (&quot;opt-in&quot;) through offering an apparent solution which is meaningless in practice.