1. I only see risk when it comes to machine generated systems. Risk of career loss, various places being flooded with slop and scams, risk of a stagnation of creativity in a world where everything is automated and regurgitated.<br/><br/>2. Job loss and devaluing of the industry <br/><br/>4. I would need to do more research.<br/><br/>6. People&#39;s art, photos, medical history, music, voices, videos, etc. They mass download these materials by using Common Crawl robots on the intermet.<br/><br/>6.2 None<br/><br/>7.1 AI datasets contain links to their training materials, the likely also store and compress the data used in storage somewhere. It&#39;s been demonstrated that AI can completely recreate the materials it&#39;s been trained on.<br/><br/>8. None at all<br/><br/>8.3 It&#39;s not fair use because you&#39;re using materials made of other people&#39;s work. I would say it doesn&#39;t make a difference because that for profit AI company still intends on making profit off whatever AI systems they put out.<br/><br/>8.4 They use billions of training materials. It shouldn&#39;t be fair use because using more content than any person can compete with that&#39;s made up in part by their own works doesn&#39;t sound very fair at all.<br/><br/>9. Affirmative consent or opt in should be the only way a copyright owners&#39; works should be used in AI training materials. AI users and the AI companies they get their software from are known liars and are to never be trusted.<br/><br/>9.5 Yes<br/><br/>15. Yes<br/><br/>18. No, you aren&#39;t a chef for ordering at a resturaunt.<br/><br/>21. No<br/><br/>25. All three.<br/><br/>28. Yes. Deepfakes and AI images of real people should definately come with a clearly visible logo that can&#39;t be removed or hidden. Audio &amp; video should come with a disclaimer at the very beginning of it that is clear to read and is stated at a normal pace.