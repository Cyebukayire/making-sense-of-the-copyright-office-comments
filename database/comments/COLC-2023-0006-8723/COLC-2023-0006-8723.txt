Generative AI systems require massive amounts of data to function. The more data, the higher quality the output. In order for these models to produce an output of acceptable quality, the datasets must be so large that copywritten works will inevitably be contained in the dataset. <br/><br/>Many generative AI advocates will insist the training process of these models are in some way analogous to human learning, thus not infringing on copyright. This notion represents a fundamental lack of understanding of both machine learning (AI), and cognitive science. These &quot;AI&quot; models are not learning anything, there is no emergent sentience in the model enabling this learning process. The training process which many allude to as &quot;learning&quot; is best described as a mathematical model of computational statistics, with the explicit goal of reproducing the input training data (images, text, audio, etc.), any beginner course or introductory youtube video to machine learning will sufficiently explain this.<br/><br/>Given that these systems are not sentient persons nor are they actually learning in any capacity, it cannot be the case that they are allowed to use copywritten works without explicit license to do so. Companies and individuals building these models are incentivized to ignore this notion, as their models require access to large amounts of copywritten material in order to produce outputs of acceptable quality. If these companies and individuals are allowed to ignore protections of copyright, they will continue developing increasingly powerful systems that will threaten and eventually supplant creative markets, creating an inhospitable environment for professional creatives. 