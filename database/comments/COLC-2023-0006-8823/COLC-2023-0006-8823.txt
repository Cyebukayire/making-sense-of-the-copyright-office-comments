As an English professor and literary critic as well as a published author, I understand respect fair use and the excerpting or manipulation of copyrighted texts in classrooms and/or in literary analysis. However, it seems to me that ChatGPT and other generative AI programs are pushing fair use too far, to a degree that is harming the public interest. When I teach a copyrighted text in my classroom, or write about it in a peer-reviewed journal article, I am increasing the visibility of that text in the public&#39;s eye. Even when my students do not buy a short story, they become familiar with the author via the story&#39;s use in my classroom and every semester, some seek out the author&#39;s other works and become paying readers and fans. From an author&#39;s perspective, I may not be paid for a story taught in the classroom or quoted in a journal article (a form of &quot;research&quot; use), but I know that my original text is likely to gain readers from its increased exposure. The use of pirated books to train generative AI does not benefit me in any way, and instead seems to harm my interests insofar as it decreases paid writing opportunities and/or claims to mimic my style. As a researcher I&#39;d note that the blackboxing of generative AI is a core issue here both from the literary researcher&#39;s and the author&#39;s perspective. The fact there&#39;s no citational practice embedded in Chat GPT to help me determine if a sentence from ChatGPT is &#39;original&#39; or plagiarized, or to determine where CHatGPT is getting a phrase or a statistic *from*, represents a problem with this technology and its usage. I think regulation is needed, and that the interests of human authors, the incentivization of human acts of creation, and the importance of being able to detect copyright infringement , should be taken into account.