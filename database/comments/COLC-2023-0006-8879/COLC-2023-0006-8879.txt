I see generative algorithms as a threat to artistic creations, human skillfulness and brain development.<br/><br/>I work both as a teacher and a freelance illustrator. My area of focus is drawing and design.<br/><br/>Threat to artistic creation:<br/>This one is quite simple. Algorithms that can digest any data, and produce close, yet different enough copy of that data discourages people from sharing their creations. Less movement in artistic communities means less exchange of ideas, techniques, processes etc, leading to less artistic experimentation. Some may suggest, that generative models offer a way of experimenting too, but that is not really the case, which I would explain later. For now we can assume and see already, that artistic communities become gated, fractured, scared and constantly on guard.<br/><br/>Human skillfulness<br/>I like to think about abilities that we as humans acquire as modules, or tools, that not only give us new options to transform reality around us, but also change our perception of that reality. Person trained as a firefighter analyzes any room they are in, in the context of fire event, looking for shortest ways of escape, vulnerable points and people etc. The same is true about drawing, composing music, designing etc. How dose it relate to AI? Generative machine cheapens the result of hard work, by competing with them in the market context, where value is tied to time and capital needed for production, rather than quality or ethical concerns of the overloaded, overstimulated consumers. Design suffers, if designers are less qualified, but the reality of bad design will reveal itself much later. And making skill less valuable (for example drawing, sculpting, composing music, singing) decreases the chances for artistic breakthroughs. Not only that, flooding the space with derivative content, makes it harder for creative endeavors to be noticed and recognized as valuable to society. It makes all of us poorer, by robing us of unique perspectives and ideas, overshadowed by never-ending slide of synthetic data. Making people numb to any artistic expression, human or synthetic.<br/><br/>Speaking of which, we don&#39;t fully grasp the impact the internet, or even more recently the social media, have on our brains. We are already oversaturated with information, overstimulated and unable to focus our attention. Adding to this even more noise cannot lead to any desirable societal effects.<br/><br/>I am writing all this to point out how much of an issue these algorithms can be. It affects society as a whole, not only creative professionals. It also lessens the copyright as a concept and law. What role is there for copyright, if anything can be copied through essentially a digital filter? What incentive do creatives have to share anything with wider public on the digital platform, knowing that any data they put out can be taken, and used by unknown actors for unknown purposes? What role dose copyright have in the world where someone can create thousands of versions of paintings, songs, voice recordings, and soon other media, based on works of living and working professionals, without them knowing, consenting or being compensated? How could we, as creatives, prove any infringement, if there is no way of knowing what happens inside of the machine&#39;s brain, or even what datasets where used to train the models? How could you ensure, that no AI work will receive copyright, if there is a staggering progress in the quality of output of these machines?<br/>Of course I understand that there is a Fair use case, but this window of freedom is there for humans to be able to enter into a dialog with an already existing piece of art, not for machines to break down everything down into parameters and produce multiderivative avalanche of content, which exist without any attributions, compensations, or even ability to trace what happened with our data, or how much dose it influence the machine&#39;s output. Industrial scale fair use was not the idea behind that doctrine, and we all know it. <br/>For these models to be less dangerous for society, for creatives to feel safer about their work being respected and for law to hold any power, it should be required of AI companies to get Consent from the creative workers, tied with Compensation and Attribution. Currently existing models should be destroyed, and training for them should be done on a basis of understanding of their capability and risk involved with mass media creation. 