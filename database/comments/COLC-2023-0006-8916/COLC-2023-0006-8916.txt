With the rise of deepfakes and other possibly harmful bits of slanderous material being generated by various sources of &quot;AI&quot; leads me to believe that as it stands, a technology that is primarily the source of a lot of harm to others and built on the content of others is just a legal mess. I imagine most people don&#39;t want their content used to spread lies about a person or used to make inflammatory statements or content that could lead to people getting hurt. And when AI can cause damage on such a large scale, I think about the smaller scale as well. People&#39;s content being taken to train these LLMs is able to cause harm at about all levels of severity. So guidelines on these models becomes absolutely necessary to protect the copyright of creators and their art and content from being used maliciously by people who want to make a quick buck, or cause harm to others.