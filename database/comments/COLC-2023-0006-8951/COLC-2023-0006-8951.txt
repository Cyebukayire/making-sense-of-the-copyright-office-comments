I am a visual digital artist working in games industry for over a decade. Here are my views regarding Generative AI and answer some of the questions stated in Notice of Inquiry document.<br/><br/>1) What are your views on the potential benefits and risks of Generative AI systems? How is the use of this technology currently affecting or likely to affect creators, copyright owners, and the public?<br/><br/>The potential benefits of generative AI systems are the creation of new type of visual culture. For artists the output from generative systems can be treated as custom made inspiration or reference material that can help aid creator closer to his/her vision. They can help in finding new ideas. If the data for the training was legally obtained then the output could also serve as building block material for the hand made creation that can make the process faster.<br/><br/>However generative systems as we have today remove the human part, take creative input from numerous artists without their knowledge and then are used as a commercial product that serves imitation of artists&#39; works. As a result they displace whole group of professionals while feeding off them to make the product even more competitive.  <br/>Because there is high level of competition in commercial art, the use of generative systems by artists will force them to race to the bottom when it comes to providing some value and contributing something personal. It won&#39;t just affect artists but can have negative effect on the development of digital art culture.<br/>In order to push art world and culture forward there need to be people who experiment and try new things. It takes years of knowledge about art foundation and tons of creativity to do it. When there will be only a group of people or companies who are just leeching from whatever they find from artists it will kill motivation for anybody who want to go the hard way and actually push the visual arts forward.<br/><br/>Currently a lot of creators are withholding sharing of art from fear of being exploited and sharing art in community is important for growth. Sharing is also important for self promotion and creating identity but generative systems as they are today create environment where main driving force is exploiting each other and diluting that identity trough oversaturation of media. When it comes to public the generative systems remove the boundary between what is human and what is artificial. They also devalue human effort to some extent.<br/><br/>9) Should copyright owners have to affirmatively consent or &ldquo;opt in&rdquo; to the use of their works in training materials, or is it enough to be provided the means to &ldquo;opt out&rdquo; of training?<br/><br/>As far as I know &quot;opting out&quot; is technically not possible as it&#39;s not possible to unlearn a training model. Therefore &quot;opt in&quot; would be the only option that doesn&#39;t allow for exploitation of the copyright owner.<br/><br/>9.5) In cases where the human creator does not own the copyright&mdash; i.e. they have transferred rights or the work was made for hire&mdash;should they have a right to object to an AI model being trained on their work?<br/><br/>Yes. It should be possible for creators to object to an AI model being trained on their work even when they transferred the rights or the work was made for hire.<br/><br/>15) In order to allow copyright owners to determine whether their works have been used, should developers of AI models and/or creators of training datasets be required to collect, retain, and disclose records regarding the materials used to train their models?<br/><br/>I believe that if the AI model is open to use for public use it should have all the datasets disclosed.<br/><br/>18) Under copyright law, are there circumstances when a human using a generative AI system should be considered the &ldquo;author&rdquo; of material produced by the system? Is selecting what material an AI model is trained on and/or providing an iterative series of prompts sufficient to claim authorship of the resulting output?<br/><br/>I believe transforming the output of the generative AI where as a result most of the transformation work was human would be enough to claim authorship. Selecting what material an AI model is trained is not sufficient to claim authorship on the resulting output. If all the training material was coming directly from the author including the creation of the generative AI system then it could be sufficient to claim authorship of all the resulting output (at the moment that is not possible from what I know but it could be in future).<br/><br/>28) Should the law require AI-generated material to be labeled or otherwise publicly identified as being generated by AI? If so, in what context should the requirement apply and how should it work?<br/><br/>For those generative systems that are non-open source there could be some invisible watermark that would be detected by internet platforms or specific tools. Additionally it might be also essential to mark authentic content as it is done with Content Authenticity Initiative (for example).<br/><br/>