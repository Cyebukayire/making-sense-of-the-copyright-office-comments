It&#39;s hard to see generative AI being used for anything other than facilitate crime and replace workers in multiple fields. It&#39;s already causing multiple creator to be laid off in favor of using generative AI that runs on their own work, without any sort of consent to do so.<br/>Increasing the use of generative AI is most likely to further increase and cause problems in any industries due to its tendency of unpredictable bias and to hallucinate information, this is due to its nature as a machine learning algorithm.<br/>The US should avoid policies pushing to give any form of legitimacy to this tech, as currently it runs on indiscriminate theft and dishonesty, both from its developers and its proponents users. The importance of international consistency is because this tech would be use to abuse for outsourcing to a country that doesn&#39;t enforce strict regulations or ban this tech.<br/><br/>The models used by generative AI are usually undisclosed, but by the developers own admission, they are trained on scraped data from across the internet, this ranges from copyrighted to private and protected data.<br/>Given how those systems work they tend to use the pools of that that yield the best results, and this usually means that it pulls from industry professionals more often. This is because the more a certain image or images are approved by a user, the more likely they are to be used again in another generation. <br/>The users of this tech having a tendency of making custom models based on the work of specific creators only worsens that problem.<br/><br/>I think a image generated by generative AI can never be considered fair use. It depends entirely on the materials used on its training data to generate images, all forms of fine tuning of a generated image always fall onto something similar to directing commissioned artist, never direct approach, and it will always compete with the very creators it pulls from on their own field, and if not used on their own field, its being used in some form of scam, misinformation or other criminal act.<br/><br/>A for-profit developer producing generative AI models for &ldquo;noncommercial or research&rdquo; purposes is clearly an attempt to circumvent laws and abuse the protections given to real research projects. Its deceptive and scummy. <br/><br/>The amount of data used for AI training will never make it fair use. It using larger amounts of data used should make it hard and impossible to claim fair use. Because currently the amounts of data used are too big to be reasonable to reach out to every person they scrapped. In addition, as there are no agreements whatsoever between copyright holder and the AI model developers, the developers can choose how much to pay for the data use. That&#39;s not how licensing should be, and those developers such as Adobe Firefly, already shown they would pay ridiculously low rates to the people whom they abused. In addition most if not all of those developers haven&#39;t upheld their &quot;opt-out&quot; policies and seem to have no intention to, the process is also extremely slow and costly to the copyright holders. The data should always have been opt-in. However given the lack of any real positives in this tech, no one should ever consider offering their data to any generative AI system. <br/><br/>In the case the copyright was transferred for hire, and the work is being used to something they didn&#39;t agree to on the transfer, in this case generative AI, yes, the original creator should have the right to object to having their work used for gen AI even if they have transferred rights.<br/><br/>The datasets should always be transparent, hiding them only shows intent to avoid accountability and legal repercussion.<br/><br/>No AI of any kind should ever be allowed to hold copyright, and a user of generative AI should never be considered copyright holders of anything outputted by those systems.<br/><br/>The ones who should be found liable for copyright infringement by the generative AI should be both the developers and the end users.<br/><br/>Any content made by generative AI should be labeled as such.<br/><br/>On the topic of AI generated voices, or any form of deepfake AI, be it commercial or for impersonation, they should be illegal.<br/><br/>The law should ban this tech and enforce such ban, with greater repercussions falling on to its developers. As mentioned before, this tech has no real benefits. When attempted to be used in a more legitimate capacity, its prone to error, and always will be, and should never be allowed to replace workers. It is however largely used as means to facilitate multiple forms of crime. And if this tech is anything other than straight up banned, it will only continue to be used to facilitate and increase crime.