Generative AI systems pose a stark challenge for the US Copyright system, and the myriad cultural workers who rely on it. If handled incorrectly, GenAI has the scale and power behind it to overwhelm, undermine, and destroy copyright outright. This is especially true for small makers and creators who rely on copyright, but lack the power and wherewithal to defend themselves against bad actors. &lsquo;Move fast and break things&rsquo; is the mantra of the Silicon Valley elite, and indeed it seems truer than ever for copyright law, with truckloads of AI companies looking to cash in during this &lsquo;wild-west&rsquo; period of AI development. In order to both preserve the rights of American creators while not sacrificing progress, I believe that domain-specific rules may be the answer. <br/><span style='padding-left: 30px'></span>Currently, AI companies are exploiting what they believe to be a giant loophole in Fair Use. Such a broad interpretation of Fair Use for GenAI is not sustainable, it tramples the copyrights of anybody who has posted any of their work online, had work reposted, or have works present on illegal piracy sites. I doubt the accommodation for Fair Use, as intended, can be interpreted in this broad way. GenAI cannot and should not be allowed to engulf the entire concept of copyright. Transformer and Diffusion models are reliant on using existing works to produce generated works. More and more, we see these amalgamations often used to commercially compete directly and overshadow the very works that they are trained from- this is a problem! It would be beneficial to all copyright dependent creators, and industries, if there were a way to stipulate or clarify that GenAI systems cannot be trained on non-consensually scraped data and then also be used to usurp that same copyrighted data in that data&rsquo;s original market. For example, LLMs trained on an author&rsquo;s books couldn&rsquo;t then be used to write books that would be competing against human authors in the book market. As Yann Lecun recently wrote on X/twitter: &ldquo;One thing we know is that if future AI systems are built on the same blueprint as current Auto-Regressive LLMs, they may become highly knowledgeable but they will still be dumb. They will still hallucinate, they will still be difficult to control, and they will still merely regurgitate stuff they&#39;ve been trained on. MORE IMPORTANTLY, they will still be unable to reason, unable to invent new things, or to plan actions to fulfill objectives.(10/28/23)&quot;  Yann is the Chief AI Scientist at Meta, If he says LLMs &lsquo;regurgitate stuff they&#39;ve been trained on&rsquo;, i&rsquo;m inclined to believe him!<br/><span style='padding-left: 30px'></span>GenAI should not be viewed as a net-negative, as it is appears both useful and promising in many diverse applications and fields. It is being deployed in advanced applications for health care and drug technology, protein folding and cancer research, rocket engineering and design, as well as climate change mitigation studies, for example. But it is also currently being used to bully, harass, and disempower people. It enables bad actors to create fake media at such scale and with such speed that it threatens to weaken our trust in one another. As we have seen, GenAI can and has been used erode the rights and principles of our democracy. Lots of regulation and enforcement across the entire government will be needed if we are to meet this moment. To that end, the USCO can help to re-establish and/or clarify protections for copyright holders, and at the same time foster a more consensual and responsible approach to the use of high quality copyright protected data. This not only allows, but encourages truly innovative and beneficial uses of this tech to expand and flourish. If well regulated, we can achieve a best possible outcome for our society. However, if we fail to protect people&rsquo;s rights (inclusive of copyright), we risk losing more than we could ever gain from this technology. GenAI may present an immense, unique challenge, but if we can safeguard ourselves, we avoid most bad outcomes.