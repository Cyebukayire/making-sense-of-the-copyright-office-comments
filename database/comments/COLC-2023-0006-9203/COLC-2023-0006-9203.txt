I am increasingly worried by the level of fraud committed in the AI space. Many artists, writers, musicians, and more have already expressed outrage over their works being used -- without consent -- to train AI models which then produce pieces that are barely distinguishable from the originals. Two deceased artists, Qing &quot;Qinni&quot; Han and Kim Jung Gi, have had their artwork used to train AI art generators posthumously, in situations where neither they nor their estates were able to provide consent. Multiple websites where creative works are uploaded have either been scrapped for AI training content (e.g. ArchiveOfOurOwn) or have covertly changed their policies to allow for the scrapping of user content to train their own AI models (e.g. DeviantArt). In almost all cases, the creators of this original content have explicitly stated that they do not consent to their work being used to train AI models, however this has not stopped AI programs/collectives from scouring the internet for content to use and reproduce. Sometimes this is done legally, but with little transparency (such as in the case of fine print policy changes). Other times, this is done without any regard to artist consent purely because little to no legislation currently exists.<br/><br/>AI &quot;artists&quot; will argue that they are bringing equity to the field by providing everyone with the tools to create. They state that they are producing unique, creative pieces based on the prompts they generate and feed into the program. However, when the program itself is trained by taking the work of individuals who have already invested time, energy, and money into honing their craft and creating pieces from scratch, it is hard to argue that any level of creativity is taking place. It is the difference between someone making a home cooked meal from scratch, and another person taking the leftovers of those meals, heating them up, and claiming they cooked the meal themselves the next day. It is the equivalent of writing a report and having a colleague take that report, edit parts of it to suit their own needs, and turn it in as if it is 100% their own work. AI is NOT, in fact, truly independently intelligent. It can only train on pre-existing models and regurgitate content in an arrangement that makes sense while mimicking what it learned from. As such, AI art/writing/music/etc. cannot truly be considered intellectual property, as no independent and creative thought is used in the generation of content.<br/><br/>In addition, the emerging prevalence of deep fakes honed on AI presents a concerning problem for the future. Already we are seeing the voices of dead musicians being resurrected for music they never created, and the likenesses of people both famous and not are being used to say and do things they have never said nor done. We have seen several cases of young people whose faces have been superimposed onto bodies in pornography, or AI being used to artificially remove the clothes of individuals and fill in the blanks of what their body looks like. It does not matter how fake it is, either, as this is a violation and misrepresentation of individuals. And I also posit -- what happens when people on the internet start doing this to images of children?<br/><br/>I implore the U.S. Copyright Office to come down hard on AI generated content. It is currently a wild west where companies, groups, and individuals are doing whatever they want to see how much they can get away with. I do believe that there are good implementations of AI -- such as animation teams using programs trained in-house and with consent to make their jobs easier and allow for more creative expression -- however these positive aspects cannot thrive so long as AI is being used to steal the content of others. The intellectual property and individual integrity of individuals is currently at stake, and the United States is in a unique position to set a precedent on what is acceptable within this space.