To put it plainly, Large Language Learning models, are a great tool to help get the ball rolling. However to obtain the data necessary to make this happen, was grabbed by folks who did not consent to have their creative works used to help teach these programs. These programs impact creators means to make a living, as their content is scrapped to feed into algorithms. Whether those rules are stipulated in the terms and conditions of sites is irrelevant as they are often buried in legalese. Make it plainly worded if a site will allow data scraping to occur so that consumers and creators can make an informed decision about uploading their content to a particular site