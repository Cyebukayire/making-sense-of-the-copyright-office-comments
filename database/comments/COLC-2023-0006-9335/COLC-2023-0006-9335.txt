- The data AI image generation is based upon includes sensitive images such as photographs protected by HIPAA and graphic footage of terrorism and executions. These are now baked into the models and they cannot be removed unless the model is destroyed and retrained from scratch on a dataset that no longer includes those images.<br/><br/>- AI of all types is subject to a phenomenon called &quot;overfitting&quot;, where the software outputs an exact copy of training data. With the inclusion of private or copyrighted information, users of the software may believe they own an image when it is actually an unauthorized reproduction of existing artwork or, worse, a serious privacy violation.<br/><br/>- AI datasets and image output are not comparable to a human artist taking inspiration from existing works. Diffusion models work as extremely advanced de-noising interpolators. Existing images in the dataset are blurred, and the AI uses its training to guess what it could be, guided by human prompts, to unblur the . This means that an image generation AI cannot produce novel artistic compositions and can only mimic the layouts of existing work. The ability to do so is a foundational skill for human artists. While the mimicry of composition and style is not infringing, this information is included to show that machine learning models are not in any way sapient or sentient and therefore cannot process inspiration and make informed decisions about its output.<br/><br/>- LAION-5B and Common Crawl were created with research purposes in mind, allowing them to legally scrape more data than would be acceptable for commercial purposes. AI models trained on the LAION-5B dataset are now being used and marketed for commercial purposes despite using data that was explicitly designated for noncommercial research applications. This is called &quot;data laundering&quot;. Corporations using the data for commercial purposes direct complaints requesting removal of sensitive data towards the nonprofit or educational institutions, who in turn assert their right to use the data non-commercially and direct the complaint back to the corporation in an endless circle. The everyday citizen has no recourse to remove sensitive medical data, revenge porn, or other such privacy violations from these services.<br/><br/>For the reasons listed above, I believe that AI-generated works should NOT be protected under copyright law.<br/><br/>Copyright law regarding art styles should NOT be expanded. The law is often used as a cudgel against individuals and small businesses by corporations who can afford the legal expense, producing a chilling effect that stifles creativity at the grassroots level. I believe that making the output of generative models ineligible for copyright protection is the best way to disincentivize infringing uses of AI.<br/><br/>Relevant sources:<br/><br/>Overfitting<br/>https://www.vice.com/en/article/m7gznn/ai-spits-out-exact-copies-of-training-images-real-people-logos-researchers-find<br/><br/>Privacy violations<br/>https://arstechnica.com/information-technology/2022/09/artist-finds-private-medical-record-photos-in-popular-ai-training-data-set/<br/><br/>Data laundering<br/>https://waxy.org/2022/09/ai-data-laundering-how-academic-and-nonprofit-researchers-shield-tech-companies-from-accountability/<br/><br/>How diffusion models work<br/>https://www.youtube.com/watch?v=1CIpzeNxIhU