I&#39;m a firm believer in human creativity and human ingenuity. Currently, a large majority of AI systems are trained on vast amounts of knowledge, taken by creators without their knowledge or consent, and then those inputs are put through a machine to create a derivative work.<br/><br/>I believe for something to be considered for copyright, the following items should be considered:<br/>- A human was involved in a vast majority of the creation of the work. I believe this should extend beyond modification of AI work, and copyright should require a human do the majority of creation. Creation in this sense is directly contributing to the result and output. This means in cases like generative text, simply providing inputs to a machine does not provide enough to be copyrighted. If a user is writing something, the output should be 75% human-written and 25% AI-written or modified. This helps enforce somewhat that AI can be a tool, but it cannot create by itself.<br/>- A human must attest whether AI was used in the creation of the work, and how significant of a role it played. A human should be doing most of the work to apply for copyright.<br/>- Any AI systems used in the process need to have training sources available, with appropriate consent from all sources used in the data set. Without the list of sources and consent, copyright should not be granted as they cannot explain the foundation of what was used in the project.<br/>- Any company that stores user data should default to an opt-in method for user collection and training for AI. This ensure all participants are willing and consent, and go beyond a massive corporation controlling the data for their users and making a profit from them.<br/>- Companies where users can submit user-generated content of any kind must provide an option for individuals to opt-in specific creations they made, or if applicable, anything under their account as a blanket opt-out, even if they previously opted in. Users must have the choice of the work they submit to sites with user-generated content.<br/>- If companies are selling or using the data they own, that information must be made public and explicit, with the data sources they&#39;re offering be available to the public be plainly stated on their website. Potentially a new AI Policy companies must provide.<br/>- Companies must keep records of any content that has been used or sold in a training model, for record keeping purposes, and the public should be able to see these data sources provided.<br/>- In the event a user later opts-out after opting-in, it will apply to new models and updates going forward. I believe all companies should be required to make reasonable and frequent updates to content, including processing opt-outs of content they may have previously used to train, so you don&#39;t have a company sitting on an older model with significant amounts of opt-out content still being used.<br/>- If a user opted out after previously opting in, any existing copyright works could remain, unless the user who opted out could prove some other copyrighted work was explicitly and strongly similar to their own work. There are potential cases for bad actors here though, but I think there needs to be a way for users of human copyright to challenge AI derivative copyright if it&#39;s potentially malicious.<br/><br/>In short, humans needs to have consented at every step, and humans need to have a super majority of creation, and modification of the works.<br/>