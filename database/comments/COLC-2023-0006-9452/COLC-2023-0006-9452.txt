Dear U.S. Copyright Office,<br/><br/>I appreciate that you are taking the time to listen to input from the public in regards to AI and Copyright. I want to focus my answer mainly on why AI should not be trained on copyrighted material without permission.<br/><br/>First, despite being called &quot;AI&quot; most generative AI programs are not artificially intelligent - they are simply basic applications of machine learning. None of these programs have any capacity to be &quot;intelligent&quot; and all the content they output is done without any intention; in the simplest terms they are mostly random and only depend on probabilities of what appeared most often in the training data. <br/><br/>The &quot;training&quot; process involves making a guess, then shifting parameters around that will shift the guess closer to the training data, and if the process runs long enough it will eventually converge perfectly to the training data, known as &quot;overfitting&quot;. Since copyright relates to &quot;copying&quot;, then it should be noted that the training data is being copied at several stages of this process - the full training image must be stored in the computer&#39;s memory in order to compare it to the guess, and after a certain amount of guesses the model will be able to replicate portions of the training material, until it eventually converges to a perfect replication. A machine learning model trained on a very small dataset will almost always overfit to all of the images used in training, and to mitigate this AI developers took the approach of training it on millions or billions of images, so that the copying becomes more hidden as the contribution of each sample becomes less.<br/><br/>Even so, it is still very much possible to extract verbatim copies of training data out of most popular AI art models. This paper describes an attack to extract training images out of Stable Diffusion and Midjourney:<br/>https://arxiv.org/pdf/2305.08694.pdf<br/><br/>This proves that the machine learning model is indeed copying portions or even the entire training image during the training process, rather than taking &quot;inspiration&quot; and making something completely unique as is commonly stated. This is false, there is nothing that a machine learning model can produce that wasn&#39;t present within its training data. The only way for the model to reproduce a certain artistic style is to train on images of artists with those styles.<br/><br/>Most AI models are currently being developed from the mass-scraping of creative works on the internet with no regard for copyright and IP protections. I don&#39;t believe that this should continue to be allowed under copyright as the training process is indeed &quot;copying&quot; portions of the training images. Additionally, if this practice continues to be allowed then it would work counterintuitively to the purpose of copyright, which is to encourage the continued creation of creative works by ensuring that author&#39;s can get paid for their work. If AI training on an author&#39;s work is allowed, then it would allow people to easily create robotic forgeries of their work at such a great scale that it will definitely harm them financially. It would also incentive less people to post works publicly to avoid having their work being fed to the &quot;AI machine&quot; without any consent or receiving credit for it.<br/><br/>I believe that copyright should exist to incentive human creators, rather than AI developers, so AI training on copyrighted works without permission shouldn&#39;t continue to be legal. There are millions of public domain and copyright-free works that AI developers could utilize, and I see no reason why the usage of works that are currently protected by copyright is necessary. If this continues to be allowed the only outcome that I see occurring is that the internet will be mined of creative works for financial profit of AI developers, and as the incentives for human creators to produce new work decreases, the number of human creators is going to greatly diminish.<br/><br/>Comparisons made between human learning and machine learning are also misleading, most importantly because of scale - a human is incapable of ingesting and memorizing nearly perfectly billions of images, but it is quite easy for an AI system. If it might be acceptable to take a log out of a forest, should it also be acceptable for a company to cut down all the trees in that forest? While both actions might be similar on the surface, the scale of the action makes a large difference and leads to different consequences. <br/><br/>I sincerely hope that you consider my proposal and do not allow AI to be trained on copyrighted material without permission. If this is allowed, I can only imagine the impact on creative industries being disastrous. Please take action to protect human creators rather than AI developers. Thank you!