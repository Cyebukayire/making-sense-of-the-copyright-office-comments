Under the &#39;Fair Use&#39; principle, people can use the work of others without permission if they are able to make something new, or transformative, from using that work. Latent Diffusion Models do not replicate the digital images it learned from its training sets 1:1 or close to it, and generally are able to create new works after finishing its machine learning process phase. So, AI LDMs are following the principles of fair usage through using preexisting work to create something new.<br/><br/>Note: The particular topic regarding stealing people&#39;s artworks is a widespread misconception. LDMs and other types of image-creating software programs do not have any artwork assets within their database. These models are also static, and do not update themselves on any new information; only learning once during their machine-learning phase.<br/><br/>Note 2: Within Stable Diffusion models, AI&#39;s role is to function as a pattern recognition system. When in its machine learning phase, it analyzes art from its training sets to look for patterns within a vast amount of images. Watermarks and signatures are patterns. The AI software isn&#39;t capable enough to tell the difference between a watermark/signature and the art itself. All it sees is a pattern it can recognize, one that is present over and over in multiple images.<br/><br/>This is why things like Getty Images watermarks are less distorted than random artist signatures. The Getty Images watermark is consistently in the same locations, consistently the same size, and present in many many images. Instances of patterns being recognized too much by the AI software are considered overtrained patterns. Models with overtrained tendencies function worse in image quality as well as creativity, and are unwanted features within the AI model. Finding overtrained image instances and removing them from within the software is the general route people go through when using AI models (especially because what people want from AI models is its ability to create novel or new images; not creating identical digital images or substantially similar digital images already in existence). Artist signatures are often in the same areas, but they&#39;re not as numerous and there is way more variety in them.<br/><br/>So when it comes time to make an image, the AI sees the Getty Images watermark as a consistent pattern. Something is present in every image of a certain kind and so it replicates that pattern as it &quot;belongs&quot; in the art. Artist signatures are also recognized as a common pattern, though one of significantly more variance, so the resulting pattern in the generated images is more varied.