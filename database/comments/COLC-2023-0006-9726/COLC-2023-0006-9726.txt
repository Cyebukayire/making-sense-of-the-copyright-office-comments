Name: Eleanor Marney (author name: Ellie Marney)<br/>Found out today that at least one of my books (White Night, 2018, Allen &amp; Unwin) released by my Australian publisher was added to the Books3 dataset, used to train AI language models. If I dig around, I&#39;m sure I&#39;ll find that some of my other books - ten titles in all, released by my Australian and US publishers and by myself independently - have been scraped and added to other datasets, if not this one. I was not informed or compensated for any of this, and gave no consent - and you can be sure that my traditional publishers, including my Australian publisher, gave no approval. So now it appears to be open season on using any author&#39;s creative work to feed into the AI churn. No copyright protections for authors, regardless of which country their material is sourced from. No compensation, no notification, no consent, no acknowledgement of the years of work involved by authors or the organisational teams that publish them. We are just supposed to shut up and take it, because somehow the rights of techbros to teach their AI models supersedes the right of every other individual on the planet who engages in creative work, or indeed work of any kind that AI may find &#39;useful for learning&#39;.<br/>So far as I can see, AI models are not &#39;artificial intelligence&#39; - they are just plagiarism machines, already hugely powerful, utterly unregulated, and used by people who are quite comfortable stealing from millions of hard-working, unpaid authors and artists globally to create profit that benefits no one but themselves. What they&#39;re doing is wage theft, IP theft, copyright violation, licensing violation, and an insult to any individual author or artist who has ever worked their 10,000+ hours to acquire the skill necessary to actually express a personal vision artistically. They&#39;re destroying the livelihoods of artists, authors, and other creative industry workers. And they&#39;re doing it all with input they&#39;ve been getting &#39;for free&#39;, because no one has had the guts to stand up to them.<br/>AI plagiarism machines are built off free labour - including *my* labour. There was no &#39;opt in or opt out&#39; - I was never offered such an option. There is perhaps no recourse for my Australian publisher in this case, as the Books3 AI dataset involved in the theft of my book operates under the legal framework of another country. There appears to be no recourse for any author or artist who discovers their work has been scraped or absorbed in this fashion, as individual authors and artists have no power to make demands of or control AI models, or the people who create them, because there is no oversight, no regulation, and apparently no laws (national or international) to put a stop to it.<br/>AI won&#39;t prevent me from writing - it won&#39;t stop me from creating new work, from developing my craft, from wanting to evoke an emotion or express something human. But it will inhibit my desire to share something of my humanity with others in an artistic way, knowing that sending it out into the world is considered an invitation to techbros to freely exploit my work for their own profit. And it will vastly inhibit my ability to make a living from the work I produce, as AI models make further inroads into a publishing industry that is already teetering after years of pandemic disruption. Like any freelance author or artist, I live from book payment to book payment and rely on the income from my labour to pay the bills. If AI continues to be given free rein, that income will eventually dry up - and the profit from my work will end up in someone else&#39;s pocket.<br/>I cannot adjudicate on the &#39;copyrightability&#39; of something created by AI - there are others who are better versed in the mechanics and process of it all who are better able to answer such questions. But if we allow the current lawlessness and lack of oversight of AI models to stand, what happens next? And what does all this say about our society? Rather than using AI to solve *actual* problems - like engineering for climate change, improving global quality of life, or solving medical conundrums - we&#39;ve done something else: we&#39;ve allowed AI organisations to target the low-hanging fruit of largely un-unionised artists and authors, &#39;solving&#39; a problem that didn&#39;t exist in the first place. Instead of investing money in the arts and authors and artists, we simply rob creators, spew out uncreative mimicry for executive profit, destroy artists&#39; industries and livelihoods, and develop easier ways for machines to keep sucking up and spewing out more and more mindless &#39;content&#39;.<br/>So far as I can see, this road leads nowhere but down.