I&#39;m both a professional photographer and the webmaster at a small private university. I believe companies developing AI models and any other content harvesting should be required to recognize and follow a standardized tag in the header of websites that would permit or deny harvesting data for any purpose, including training AI models. Preferably, the tag would require opting in rather than opting out.<br/><br/>Robots.txt provides an analogous standard developed by the community, but lacks practical enforcement. It has no teeth to prevent bad actors from scraping sites without complying with the wishes of the site owner and rights holder. Copyright law and regulations are the only hope we have to not face a similar ineffectual mess as the for-profit taking of content without consent explodes. Currently, several companies have come up with different different instructions to deny their software access to a site, but it&#39;s still like playing Whack-a-mole as each requires a different tag.<br/><br/>As a webmaster, I see the server logs. There are many days our website gets more traffic from bots scrapping content than legitimate users. We are paying for the bandwidth, server resources and creative content their business models require without any compensation, benefit or opportunity to consent. <br/><br/>The default behavior of the bots should be to look for consent. The tech industry will propose a standard requiring rights holders to opt out, but that is not how copyright works in any other situation. Permission to harvest data should not be presumed. That is clearly theft, and any standard that requires opting out penalizes novice webmasters.<br/><br/>In conclusion, there needs to be a standard tag enforcible by law to opt in to data harvesting. Any harvesting of sites that do not give explicit should be considered theft. 