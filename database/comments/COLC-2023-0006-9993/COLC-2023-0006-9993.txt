Generative AI technologies built on large language models owe their existence to the writings, artwork, and unpaid data labor of thousands if not millions of people. These technologies mimic, aggregate, &amp; regurgitate derivative language, stories, style, and ideas. Millions of copyrighted books, articles, essays, artworks, etc. have been fed to Large Language Models without compensation to or the consent of their originators. Many of these derivatives in terms of art still contain faint traces of watermarking or signatures from the original artworks they&#39;ve borrowed from without compensation. Considering the Supreme Court&#39;s ruling in Warhol v. Goldsmith (2023), AI aggregate works should not be considered original or novel pieces, but variations built from unpaid and unacknowledged original work(s). Large Language Models and Generative AI would not be able to produce these derivative works without vast ingestion of &quot;training data&quot; which has been confirmed to contain copyrighted works. These generative models benefit from and are enriched by this copyright protected material without justly compensating original creators and obtaining permission. It is also worth pointing out the argument made by Arrieta-Ibarra et al. (2017) [DOI: 10.1257/pandp.20181003] that data is a form of labor, and that OpenAI and other LLM/Generative AI foundries are benefitting from the data labor provided through testing, refinement, and interaction with/of their product by the user without adequately compensating the user and creator for their data labor. In fact, in the case of OpenAI and LLMs like GPT-4, users pay to access Generative AI features trained on vast data arrays/libraries where originators are not compensated, supporting theft.<br/><br/>I urge you to consider the danger these AI pose not only to creators and their works, but to that of data security, the data labor of the individual, and to the fabric of our society as a whole. The current structure of Generative AI is already built on a foundation that is inequitable at the root.