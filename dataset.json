{
    "comments":[
        {
            "comment_id": "COLC-2023-0006-0006",
            "comment_title": "Comment from Anonymous",
            "document_url": [
                "https://downloads.regulations.gov/COLC-2023-0006-0006/attachment_1.pdf"
            ],
            "document_name": [
                "A Sui Generis Approach to AI-Generated Works Protection Balancing Innovation and Authorship (Final)"
            ],
            "document_title": "A Sui Generis Approach to the Protection of AI-Generated Works: Balancing Innovation and Authorship",
            "document_size": 272732,
            "word_count": 4603,
            "authors": [
                "Benjamin Hardman",
                "James Housel"
            ],
            "document_content": "A Sui Generis Approach to the Protection of AI-Generated Works:  \nBalancing Innovation and Authorship \nBenjamin Hardman1 and James Housel2 \nAbstract  \nAs artificial intelligence (\u201cAI\u201d) reshapes creative production, debates intensify around the \nprotection of works authored by or with AI (\u201cAI -generated  works\u201d). The debate over whether to \nprotect these works under the copyright system is a complex and ongoing discussion that raises \nsignificant legal, ethical, and practical considerations. The consensus is that works generated  by \nor with AI are not protectable  simply because copyright only protects the creative works of \nhuman authors. The current debate would then leave such works with out protection. One issue \nthis presents  is disincentivizing the use of AI in the creation  of books, art, or music.  \nHowever, just as with  human -created works, consumers can enjoy the art or prose of AI works, \nand thus these works have the same intrinsic value. Generally, the creation of value is a worthy \nsocietal and economic goal \u2014hence the clause in the U .S. Constitution that refers to promoting \n\u201cthe Progress of S cience and useful A rts, by securing for limited T imes to Authors and Inventors \nthe exclusive Right to their respective Writings and D iscoveries.\u201d  \nIn addition, the current consensus is  undervaluing human inputs into AI-generated  works that \ninitiate and/or enable the work\u2019s creation . For example, if a human  gives the AI a plot and \nwriting style details and then tell s the AI  to write a short story, the resulting work is only created  \n \n1 www.linkedin.com/in/benjamin -hardman   \n \n2 www.linkedin.com/in/james-housel -b4b3b118/   because of that human\u2019s  inputs. Therefore, merely as a matter of equity and fairness, the human \nshould be rewarded for initiating the AI-generated work, thereby creating value . However , this  \ndoesn\u2019t mean that  copyright protection should apply in such a case.   \nIndeed, it is this last point where  we have been  missing an opportunity . Debate in this area has \nbeen limited to the idea that  there are only two possible outcomes , namely, c opyright protection \nor no copyright protection. This article hope s to open the debate surrounding the intricate terrain \nof legal protection for AI-generated works  by proposing a sui generis framework  for such works . \nThis framework, characterized by limited protection terms, well- defined rights,  a registration \nrequirement , a notice requirement, and a system providing a source of funds for public good, \nseeks to address the major obstacles to a way forward on solving the AI/ copyright debate . \n  Introduction3 \nThe emergence of artificial intelligence as a creative force4 brings forth a captivating paradox. \nOn one hand, AI\u2019s capacity to generate art5, music6, literature7, and more has ignited new realms \nof artistic possibility, redefining the scope of what human creativity can achieve. This integration \nof AI into the creative process is transforming how creators approach their work and enabling \ninnovative possibilities.  \nThis very progress has sparked complex questions about authorship, ownership, and the essence \nof artistic expression itself. As AI algorithms learn, adapt, and compose, they challenge the long -\nheld premise that creative endeavors stem solely from human inte llect and intention. This \n \n3 Much of this sec\ufffdon was dra\ufffded with the help of ChatGPT.  \n4 The examples in th e footnotes  below where the result of a query to ChatGPT as to how AI  is being used in art, \nmusic, and literature.  \n5 Genera\ufffdve Art: Ar\ufffdsts harness AI algorithms to co -create artwork. They input certain parameters, allowing AI to \nproduce unique visuals inspired by established paterns or styles. The output o\ufffden combines AI's insights with the \nar\ufffdst's intent, yielding fresh perspec\ufffdves.  \nStyle Transfer: AI algorithms analyze the stylis\ufffdc elements of one artwork and apply them to another, leading to a harmonious fusion of ar\ufffds\ufffdc aesthe\ufffdcs. This process results in cap\ufffdva\ufffdng visual blends that challenge tradi\ufffdonal \nno\ufffdons of ar\ufffds\ufffdc crea\ufffdon.  \nInterac\ufffdve Art: Creators construct installa\ufffdons with AI components that respond to audience engagement. By interpre\ufffdng human inputs, these installa\ufffdons o\ufb00er personalized and dynamic art experiences, blurring the lines \nbetween creator and viewer.  \nAR and VR: AI enhances immersive experiences in augmented and virtual reality realms. Ar\ufffdsts cra\ufffd digital worlds \nthat interact with viewers in real \ufffdme, allowing for unparalleled engagement and explora\ufffdon.  \n6 Music Composi\ufffdon: AI algorithms trained on vast musical databases assist composers in genera\ufffdng original \npieces. This ranges from classical composi\ufffdons to innova\ufffdve electronic tracks, expanding the horizons of musical \ncrea\ufffdvity.  \nMusic Produc\ufffdon: AI serves as a crea\ufffdve partner throughout the produc\ufffdon process. It suggests instrument \nchoices, mixing techniques, and arrangement varia\ufffdons, enabling musicians to explore diverse sonic landscapes.  \nMIDI Genera\ufffdon: AI can translate non- musical inputs, such as textual descrip\ufffdons or visual cues, into musical \nscores. This dynamic approach transforms the way music is conceptualized and materialized.  \n7 AI-Generated Wri\ufffdng: Authors collaborate with AI models to facilitate content crea\ufffdon. AI generates dra\ufffds, aids \nin idea\ufffdon, and even cra\ufffds varia\ufffdons of sentences, streamlining the wri\ufffdng process and inspiring new direc\ufffdons.  \nLanguage Transla\ufffdon: AI -driven transla\ufffdon tools bridge language barriers, making literature accessible to a global \naudience. This capability fosters cultural exchange and dissemina\ufffdon of stories across borders.  \nEdi\ufffdng and Proofreading: AI -powered tools analyze text for errors , inconsistencies, and stylis\ufffdc improvements. This \nitera\ufffdve process enhances the quality of wri\ufffdng and contributes to a polished \ufb01nal product.  \nPlot Genera\ufffdon: AI assists writers in developing storylines by sugges\ufffdng plot twists, character arcs, and narra\ufffdve \nstructures. This augmenta\ufffdon of crea\ufffdvity sparks new possibili\ufffdes in storytelling.  juxtaposition has unfurled a dynamic discourse at the crossroads of law and technology\u2014a \ndiscourse that transcends traditional boundaries and necessitates innovative legal approaches.  \nIn an era where artificial intelligence is res haping the landscape of creative expression, a \nprofound conundrum emerges for legal scholars and policymakers alike: how to effectively safeguard and preserve works generated by AI, especially in the context of creating a sustainable economy which has full y integrated the potential of AI. As the intersection of technological \nadvancement and artistic innovation becomes increasingly intricate, the conventional frameworks of copyright and intellectual property law find themselves facing unprecedented challenge s. \nWhy Not Copyright\n8 \nThroughout modern history, creative works have found their safeguard in the realm of copyright laws, offering authors the exclusive right to duplicate, distribute, and present their creations to the public. The overarching goal of copyright protection is to spark the flame of creation by \nendowing authors with a means to derive value from their artistic endeavors. This established \nsystem has grown and flourished over the course of centuries, contributing to an expansive reservoir of music, films, software, art pieces, and literary works . The fruits of these labors \npermeate our lives, easily accessible through the screens of our phones, the int erfaces of our \ncomputers, and the hallowed aisles of public and private libraries.  But providing copyright \nprotection to AI-generated works would come with overwhelming cost and challenges.  \n \n8 Despite what you\u2019ve learned on the Internet, not everything goes in the square hole.   \nhtps://youtu.be/6pDH66X3ClA   The idea that AI, computers, and robots  be allow ed to compete with humans in the realm of \ncreativity is viewed as profoundly unfair. First, there can be no doubt that AI can  generate a new \nwork of literature, music, or art, just as humans can. However, an AI generates works in a \nfundamentally different way  from how humans create works. The AI copies  and recall s virtually \ninstantaneously  a large amount of  digitally stored  works of human creativity , spanning thousands \nof years , and then can genera te, over a very short time period, hundreds  of millions of photos, \npoems, books, songs, and even sculptures (using 3D printing technology)  that would vary in \n\u201cquality .\u201d But we can be certain of one thing : the best works that AI generates will be at least as \ngood, if not better , than its human competitors. For evidence of this, one need only look at the \nperformance of AI -generated works in  international art and photo competitions.  \nConfounding the  issues further , recall that copyright protection is automatic in the vast majority \nof the world\u2019s countries. If AI-generated works are given copyright protection, some enterprising \nentrepreneur s will begin mass creation  of works, including songs, images, and literature, and \nmake a b usiness of su ing large numbers of defendants under copyright law  for substantial \nsimilarity. Alternatively, or additionally, because of the ease of using AI to generate new works, \nthe current creative economy that has been built around human- created works could collapse. \nThe entire market for licensed images  and licensed songs  could go extinct. Why buy when AI \ncan generate a photo or song for free? Why risk capital over the span of months or years hiring \nscreenwriters, actors, camera operators, and the thou sands of others that contribute to the making \nof a movie, when AI can generate an entire movie on its own, perhaps in a matter  of minutes? \nThese are real fears already expressed by those in the creative industries.  \nIn this context, there is an inherent tension between humans and AI. This tension can be explained at least in part on certain, considerable advantages that AI enjoy over their human counterparts. These advantages include the amount of material accessible (and accessed) and \nretained in memory (limited solely by what has been stored digitally), an ability to perfectly  \nrecall such material at a speed humans cannot come cl ose to, and, most importantly, an ability to \nquickly process, merge, and assimilate diverse material into a single work.  \nOne way around the bar to non- human authorship is to conceptualize AI as a mere tool of the \nhuman author, like any other technology us ed by humans to assist, facilitate, or enable the author \nto create an expression of their idea. A human author uses AI to generate any number of  works, \nsuch as images, literature, and music.  Copyright protection, it is argued, should attach because \nthe human is the author, i.e., the party responsible for the creation of the work. As an example, consider photographs taken by a human. Current law protects such photographs under copyright. In this case, the human uses a camera as the tool to create the photog raphs. In a similar way, if \nthe human uses AI as a tool to create an image in the style of a photograph, why shouldn\u2019t the resulting image also be protectable by copyright? There is something simple and logical about \nthis analogy, but we think it ultimatel y fails.  \nFor the authors, the ultimate downfall of the AI -as-a-mere -tool began by framing the issue \nbeyond photographs. If a camera is just a tool, then what about a piano or pen and paper? All are necessary elements to enabling the author\u2019s expression of their idea: A photograph could not \nexist without a camera; Piano music could not exist without a piano. The technology, the equipment, the tools were required for ultimate creation of a work \u2014the expression of the \nauthor\u2019s ideas. Unlike these tools, AI isn\u2019 t simply a tool guided solely by the hands of the author. \nThe inputs into AI do not equal, and in fact are less than, the output generated by AI. This is both the true value of AI -generated works, but also the very reason why such works have not been \nfound to enjoy copyright protection.  Before AI, the author of a photograph selected all the variables necessary to the creation of the \nphotograph, including location, angles, lighting, composition, etc. In essence, the author guided the camera to express nearl y exactly the author\u2019s idea or vision of what the photograph would \nlook like before using the tool to create the work. With AI, human inputs do not dictate the output.\n Imagine, for example, the inputs providing more and more detail. Create an image of a \ncat, black, sitting on a chair, mouse in the corner by a small hole in the wall, in a library room of a house, red curtains, ray of light through the window. Even with all these details as inputs, the resulting AI -generated work cannot be the product of the author  because there are infinite ways \nfor the AI to apply these inputs to an image.  \nThe adaptation of traditional copyright frameworks proves inadequate, both because  AI lacks \nconsciousness, emotions, and intrinsic creative intent ,\n9 and because of the imbalance in \ncapabilities between humans and AI.  Notwithstanding all the other arguments for not protecting \nAI works under copyright, we believe  that the human factor is a dispositive and absolute barrier . \nThe US Copyright Office has consistently maintained a human author requirement for creative \nworks.10 Given the imbalance in abilities discussed above, this rejection of copyright protection \nfor AI- generated work should be maintained. However, that does not mean that AI -generated \nworks cannot and do not create economic and social value. Therefore, rather than continue to \ndebate extending copyright protections to AI -generated works, it\u2019s time to look for alternative \nsoluti ons to protecting such works. In doing so, our goal should be to incentivize the creation of \n \n9 Whether AI may one day possess consciousness, emo\ufffdons, and intrinsic crea\ufffdve intent, and any other atribute \nwe atribute to sen\ufffdent life, we know it currently does not. We leave for another day how to treat AI -generated \nworks when such a day arrives. However, even if one day AI becomes sen\ufffdent, we believe that such enhanced \ncapability would increase, rather than decrease, the inherent tension that exists between humans and AI.  \n10 The U.S. Court of Appeals for the Federal Circuit, the court with patent jurisdic\ufffdon, has similarly held that an \ninventor must be a human (natural person) in order to qualify for patent protec\ufffdo n. Thaler v. Vidal , 43 F.4th 1207  \n(Fed. Cir. 2022), cert. denied . such works, while maximizing the combined economic and social benefits of both human-\ncreated and AI -generated works. \nWhy Not \u2018 No Copyright \u2019 \nIf we accept the conclusion that AI -generated  works should not be protected under copyright , \nthen the current debate would leave us with no protection for such works. There are at least two \nfundamental problems with that scenario . \nFirst, laws should incentivize the creation of value and public goods ; however, a lack of \nprotection for AI-generated works  necessarily  discount s and trivialize s the value that is created . \nIt is undeniable  that AI-generated works  have value , or at least the potential for value, in the \nexact  same way that human created works have value.  \nSecond, providing no protection also  undervalues the way in which the work was created.  Think \nof the inputs into an AI algorithm  as \u201cideas\u201d. You have an idea for novel  that would include \nvarious characters and their personality traits, a setting or location for the novel, a plot or theme for the storyline including what generally happens, and perhaps  an idea of a writing style . You \nprovide these inputs to the AI algorithm, which then effic iently (and quickly)  writes the novel . \nWithout your (human) input, the novel never gets  written . Under copyright law,\n11 ideas, \ndisembodied from their expression,  are devalued and are explicitly excluded from protection . We \nthink this makes sense. The U.S. Constitution recognized this by explicitly allowing Congress to \nmake laws that promote the progress of science and useful arts by giving authors and inventors the right to their creations. It was well understood that ideas themselves have no intrinsic  public \n \n11 Ideas are also devalued under patent law  and are explicitly excluded from protec\ufffdon. Under both copyright law \nand patent law more is required; copyright requires expression and patent requires reduc\ufffdon to prac\ufffdce.  value unless placed in a form suitable for consumption and commercialization by the public . The \nidea need s expression or reduction to practice \u2014to be translate d into a book or an invention, for \ninstance.  \nThroughout our creative history , a small percentage of the population would/could have an idea \nfor a creative work, such as a book, whereas the majority  has neither the time, interest, nor \ncapacit y. However , of that small percentage of conceptualists, perhaps less than  1% can express  \nan idea  (e.g., writing a book)  in a way that people attribute value to it (i.e., want to read the \nbook) . The value in the book context is very clearly the ability to make  prose that is engaging \nenough to make people want to buy and read the book.  \nAI has turned this creative process on its head. With AI, the expression, e.g., writing,  is now the \neasy part. The AI can  generate expression, whether writing, graphics, or songs , without struggle . \nTime is not a constraint on the generation of works by AI ; conversely, humans need to eat, work, \nand sleep . With AI -generated work, the value now is in the human input stage and, perhaps mo st \nimportantly, the initiative to provide the input to the AI so that a work can  be generated . AI has \nautomated the expression portion of the creative process. Although this fact may be unsettling, it \nleaves us with a watershed moment \u2014a huge shift in the way the market for creative prod uction \noperates.  Understanding the change in perspective of where the value of the creation process \nderives  will help us craft a solution that  recogniz es and rewards the new value inputs  into the \ncreative production process\u2026the human idea. Failing to do so merely continues to undervalu e \nhuman input  and initiative  and leaves  no protection for A I-generated  works . Such a result is not \nonly unsatisfactory , it also  discourages the very creative process that we want our laws to \nsupport.  \n  Proposed Solution  \nWe need a  legal framework that can  appropriately  value human input and initiative  when \nutilizing AI to generate works , yet preserves  the traditional  protection s reserved  for human \ncreators . This framework,  we believe, should be  characterized by a limited term of protection, \nwell-defined rights,  a registration requirement, a notice requirement, and should provide  a source \nof funds for a public good facilitating human use of AI for the benefit of the economy and \nsociety. Such a framework of protection for AI -generated works will necessarily address the \nmajor obstacles to a way forward in solving the AI copyright debate .  \nPolicymakers, and especially Congress, should open a dialogue on this proposal with experts \nfrom government, industry, and academia to work out the details for implementing this proposal. The imperative to open the issue to public comment underscores  a commitment to inclusive \ndecision- making. By soliciting insights and perspectives from diverse stakeholders, the policy \nformulation process gains the advantage of a comprehensive understanding of the potential impact of protection terms on creators, cons umers, and the cultural landscape at large. This \napproach ensures that the resultant framework reflects the collective interests of society.  \nSolution Framework  \nLimited Term of Protection:  \nGiven the speed and apparent ease with which AI can  generate works, t he term of protection for \nAI-generated  works should be significantly less than the term provided for under copyright. A \nrange of 5\u20131 0 years from registration seems a good place to start t he discussion , though with \nadditional research and study a more appropriate term may be determined. The limited term acknowledges the multifaceted nature of human creative  inputs and AI-generated outputs  and the \nrapid evolution of AI technology.  \nFurther, it may be necessary to differentiate between different forms of works, e.g., images \nversus movies, poem versus novel, etc. In other words, these  different categories of works  might \nbe viewed as deserving  different  terms of protection based on the different creative effort needed \nto provide the inputs into the AI necessary for the generation of those works. For example, t he \ninputs necessary to create an image can be quite simple, e.g., create 20 scenes of heaven  in the \nstyle of van Gogh. The human creator can then very quickly peruse  the 20 images and choose the \none to her liking. Perhaps it is t he one she thinks is \u201cbest \u201d and worth registering because she \nthinks others  will also value  the work at  something more than zero, or she simply wants to \nprevent others from using the image  because she plans to incorporate  it into a logo for her \nbusiness . Conversely, creating a book people might want to read could require more inputs , e.g., \nplot, characters, personalities , activities, general theme, etc.  We recognize that i t isn\u2019t entirely \nclear that the  different forms of works require different terms, but it seems a logical place to start \nthe discussion. \nThe introduction of limited p rotection terms for AI- generated works reflects a nuanced approach \nthat balances the imperatives of incentivizing innovation, while clearly still favoring the rights \nthat human authors enjoy under the copyright system . \nRegistration Requirement:  \nAI-generated  works eligible for protection under this system would need to be registered with the \nU.S. Copyright Office  using the current registration system . Only minor adjustments  are likely to \nbe needed  to implement this parallel sui generis  registration s ystem . For example , a box that can be checked saying AI was or was not used in the creation of the work would determine which \ntype of registration is requested . The proposal to integrate AI -generated  works into the existing \nU.S. Copyright Office registration system offers a pragmatic approach that harnesses the \nfoundation of an established infrastructure , while incorporating tailored modifications to \naccommodate AI -generated content. This approach ensures a streamlined process for creators, \naligns  with current practices, and introduces a minimal , yet crucial adjustment to capture the \nunique nature of AI's contribution in the creative process.  \nBy utilizing the established U.S. Copyright Office registration system, the proposed framework \ntaps into a well -functioning mechanism that has long served  as a cornerstone of copyright \nprotection. Leveraging this infrastructure not only expedites the integration of AI -generated \nworks , but also capitalizes on the familiarity of creators with the registration pro cess.  This \napproach mitigates the need for an entirely novel administrative infrastructure, minimizing complexities , and facilitating a swift adaptation to the evolving creative landscape.  \nThe cost to register a work should be minimal, but not free ; it sho uld reflect the value such \nprotection affords registered works . This  fee requirement serve s three functions. First, much \nneeded revenue would be generated for the U .S. Copyright Office. Second , the cost would \nrequire creators to be somewhat  selective about what to register . This process serves as a self -\nfiltering  mechanism of fleshing out works  likely to be of value  (and thus worth registering) and \ncompare that to automatic protection under copyright where everything created is automatically  \nprotected\u2026the good, the bad, and the ugly. This requirement will greatly reduce the flood of AI-\ngenerated works that could be granted  protection , and in turn , reduce to some extent the \ncompetition between human author ed and AI -generated  works. Third, the fees generated would \nnot only enable the U.S. Copyright Office to administer the registration system, but also would generate funds that Congress could  allocate to programs designed to educate and train the labor \nforce with new knowledge and skills to implement and use AI tools in the evolving information \nage economy. There can be no doubt that AI will transform the economy in ways that we today cannot fathom. Such programs are necessary to ensure that the labor force can continue to be viable i n this new economy. \nSimilar Bundle of Rights: \nThe bundle of rights granted to AI -generated  works should be similar to traditional copyright. \nThese rights could include reproduction, distribution, public performance, adaptation, and \nderivative works rights.  Likewise, the exceptions and limitations available for copyright works \nwould apply equally to the A I-generated  works.  \nBy substantially mirroring the bundle of rights associated with traditional copyright, the \nproposed framework extends a familiar a nd well -established protection structure to AI -generated \nworks. This approach ensures a consistent legal landscape where both human and AI -generated \ncreations are subject to the same foundational principles. Moreover, this symmetry safeguards against any potential legal discrepancies that might arise from delineating separate rights for AI -\ngenerated content.  \nDistinct Mark or Label:  \nAI-generated  works should also be required to carry a distinct mark or label indicating their AI \norigin. The implementation of a distinct mark or label on AI -generated works represents a \nstrategic response to the unique challenges posed by the integration of AI into the creative process. This label serves a dual purpose, acting as both an informative signal to users and a mechanism to prevent unwarranted overprotection of AI -generated  content. Overprotection would naturally arise if there were no markings , due to the public\u2019s inability to \ndistinguish between human authored and AI -generated works and the potential fraudulent \ndesignation of an AI -generated work as human authored without AI assistance. In other words, i n \nthe current landscape, users often operate under a default assumption of copyright protection for \nall creative works. This assumption would result in the over -protection of works  generated by AI . \nThat reasonable risk aversion would be negated by the required mark or label that would identify \nAI involvement, as well as the year of creation and thus  its term and expiration date.  \nA visual representation of this distinct mark further underscores its purpose and efficacy. The \nsymbol of an A enclosed within a circle, akin to the well -recognized copyright symbol \u00a9, serves \nas an intuitive and symbolic representation of AI involvement. This symbol \u2014readily associated \nwith AI origin \u2014provides an immediate cue to users and consumers, facilitating rapid \ncomprehension and informed decision- making.  \nReview and Evaluation:  \nThe establishment of a sui generis  system for the protection of AI- generated works underscores a \nproactive  and pragmatic  approach to accommodate the rapid pace of technological evolution and \nshifting creative paradigms. An integral aspect of such a system would involve regular and systemat ic reviews, a practice that mirrors existing frameworks and has proven effective in \nmaintaining legal relevance and addressing emerging challenges.  As a starting point for \ndiscussion, a  5-year review period seems  reasonable.  \nThe concept of periodic reviews  is not uncharted territory within the legal landscape. A precedent \nis evident in the Copyright Office's periodic reviews conducted under Section 512. This process assesses the effectiveness of the Digital Millennium Copyright Act (DMCA) in addressing onli ne infringement issues. The periodic review model acknowledges the fluidity of the digital age and \nserves as a valuable reference for crafting similar review mechanisms within the sui generis framework.  \nConclusion \nIn navigating this uncharted terrain, the sui generis approach proposed here emerges as a beacon \nof adaptability. It acknowledges AI as a dynamic co -creator while upholding the rights and \nintentions of human participants. By fostering a balanced ecosystem, this approach empowers \ncreators to leverage AI's capabilities,  while ensuring that the outputs remain true to their vision.  \nAs legal scholars and policymakers grapple with the intricacies of protecting AI -generated \ncreations, the sui generis  approach emer ges as a formidable solution. Its adaptation allows for the \npreservation of the inherent value of both AI and human creative input  yet recognizes and \naddresses the inherent imbalance between humans and AI in the creative process. By embracing \nthis nuanced approach, society can fully embrace the artistic possibilities of AI while safeguarding the foundations of creativity, innovation, and the public domain. In a world where \nhuman imagination and artificial intelligence converge, the sui generis  system offers the promise \nof harmony amidst complexity, embodying the true essence of creative evolution.  \n "
        },

        {
            "comment_id": "COLC-2023-0006-0036", 
            "comment_title": "Comment from Opderbeck, David", 
            "document_url": [
                "https://downloads.regulations.gov/COLC-2023-0006-0036/attachment_1.docx"
            ], 
            "document_name": [
                "AI fair userevisedagaincomment"
            ], 
            "document_title": "Copyright in AI Training Data: A Human-Centered Approach", 
            "document_size": 1068853, "word_count": 17941, "authors": [
                "David W. Opderbeck"
            ], 
            "document_content": "Copyright in AI Training Data: A Human-Centered ApproachBy David W. Opderbeck\tIntroductionAI systems require training.  AI training requires large volumes of examples.  The examples used to train AI systems, siphoned from the public Internet, often are subject to copyrights.  This massive unlicensed use of copyrighted material implicates the reproduction right because these systems must make copies of files to analyze them.  It also implicates the right to control derivative works to the extent the trained system is \u201cbased on\u201d the training data.  Groups of authors and other content creators have filed lawsuits against OpenAI, the creator of the text generator ChatGPT, for ingesting their content without permission to train large language models.  In May 2023, the U.S. Copyright Office held listening session on AI and the visual arts that focused on the use of copyrighted works in training data.  The Federal Trade Commission issued an investigative demand to OpenAI that includes requests for information about the sources of its training data.  The European Union is considering rules that would require disclosure of copyrighted material used in training data.  Other lawsuits, regulatory, and legislative inquiries involving the use of copyrighted material for AI training will certainly follow.  Indeed, this issue is the next great frontier in copyright law, which will shape both the law and this revolutionary technology much as the dawn of the computer and Internet eras did over forty years ago. The training and deployment of this first wave of AI systems mirrors earlier Silicon Valley culture:  move fast, break things, ignore intellectual property rights and ethical conundrums, and sort out the problems later.  This pattern is etched deeply into intellectual property law and scholarship.  The 1980\u2019s saw cases involving arcade video games and personal computers; the 1990\u2019s and early 2000\u2019s, policy choices about the Internet and cases concerning peer-to-peer file sharing and the digitization of newspaper archives; the mid-2000\u2019s, litigation over the Google Books project and cable television and cloud-based DVRs; the early 2020\u2019s, disputes about operating system API\u2019s.  Some scholars argue that the arc of intellectual property law over these past forty years bends towards fair use.  They envision a broad fair use domain for \u201cnon-expressive uses\u201d to accommodate disruptive technologies.  There are some important problems with this vision.  First, the arc of fair use bends in various, sometimes inscrutable ways.  It is not at all clear that any sort of non-expressive use principle can be gleaned from computer-age case law.  It is even less clear that such a principle would be doctrinally and practically coherent.Second, the AI revolution is different, both in scale and in ethical concerns.  In the 1990\u2019s, people were amazed that a computer hard drive could hold hundreds of songs and that an entire album could reside on a portable MP3 player.  In the early 2000\u2019s, we were astonished that researchers could find digital copies of old newspaper articles on the NEXIS database rather than rummaging through microfiche.  By the mid-2000\u2019s, the world was awed that Google could scan over 20 million library books.  Today large language model (LLM) AI\u2019s such as ChatGPT consume billions of files for training purposes, including publicly accessible songs, newspaper articles, books \u2013 and much, much more.  Technologists predict that advances in storage, communications, and computing power will allow the next generations of AIs to make equally impressive leaps in scale. Much of the scholarship on intellectual property rights in AI training data so far assumes that AI presents the same doctrinal and ethical concerns as previous generations of digital era technologies. Many scholars appear rooted in a prior generation\u2019s computer and Internet exceptionalism.  Intellectual property rights, they suggest, are barriers on the road to greater and greater knowledge and cultural diffusion.  AI ethics scholars and policymakers are not so sanguine.    AI\u2019s logarithmic growth itself raises ethical questions.  And beyond mere scale lurk even deeper issues.  MP3 players and scanned library books do not make decisions that affect people\u2019s lives and freedoms.  AIs do.  Nor is there any debate about whether an MP3 player or page scan possesses legal rights of its own.  AIs might. Perhaps we learned something from the hubris of the Internet age, which produced both enormous, glorious cultural goods and grave, corrosive evils.Much of the work that has been done on AI ethics, policy, and law, focuses on what AI knows and the decisions it makes about human beings.  The Biden Administration\u2019s \u201cBlueprint for an AI Bill of Rights,\u201d for example, emphasizes safe and effective systems, algorithmic discrimination protections, data privacy, notice and explanation, and human alternatives, consideration, and feedback.  The current draft of an EU AI Regulation reflects similar concerns.  The Future of Life Institute\u2019s Asilomar AI principles include broad statements about \u201cshared benefit\u201d along with the usual concerns around safety, transparency, and accountability.  Notably, none of these policy documents suggest principles for intellectual property.This presents an important opportunity for copyright to make a difference.  Four aspects of copyright doctrine intersect with AI ethics in interesting ways.  The first intersection is the meaning of reproduction.  Copyright law considers any fixation in a tangible medium of expression sufficient both for purposes of obtaining statutory copyright and for purposes of defining a \u201ccopy\u201d under the right of reproduction.  There is no doubt that a reproduction is made of AI training data until the machine incorporates that data into its algorithmic functions.  This process could be considered only transitory in a way that does not infringe the reproduction right.  But the underlying data does, in a sense, live on in the algorithmic functions.  In many ways, this is similar to how the human brain processes and recalls information, as the moniker \u201cneural network\u201d suggests.  The second intersection is consent.  A licensed use of a copyrighted work, of course, is not infringement.  This means a copyright owner can consent to a use, either expressly or impliedly.  Current scholarship on copyright and AI training data assumes that the basis for earlier examples of large-scale web crawling and scraping \u2013 notably Internet search \u2013 is fair use, and that fair use therefore also must be the primary basis for using AI training data.  Not so:  the more prosaic rationale is consent through express or implied licenses.  Consent is also central pillar of AI ethics, particularly as they intersect with privacy law.  This includes consent to be subject to automated decision-making and consent to the processing of personally identifiable information (PII) by an AI.  This pillar of AI ethics demonstrates the close connection between AI ethics and privacy law \u2013 which is, in turn, grounded in basic human rights principles.  Many kinds of texts and images ingested by AIs for training contain PII.  This convergence between consent in copyright and in AI ethics suggests that more robust consent mechanisms for web crawling and scraping, supported by application design principles, would go a long way towards addressing future concerns about AI training and copyright along with related concerns about privacy.The third intersection relates to what seems to be the principal fair use defense raised by organizations such as OpenAI:  so-called non-expressive use.  Many scholars and advocates assume non-expressive uses are inherently transformative.  They suggest an open source ethic applicable to computer code, scientific findings, or discreet factual data held in databases maps directly on to AI training data.  It does not.  Efficient computer code depends on good code and the progress of science depends on complete and accurate factual information.  Open source computer projects entail communities that vet and correct the code.  Scientific communities, to whatever degree they are open or closed source, depend on scientific methods, community norms, and peer review to weed out inaccurate data and conclusions.  AI training presently is a wild west.  When AI models are trained from petabytes of data scraped from the Internet, no one knows whether that data is good, bad, or indifferent.  Copyright cannot serve as a primary mechanism for training data integrity, but it can serve as a useful speed bump. Even more, a market for clearing copyrighted content as AI training data would serve the purpose of copyright by benefitting content creators and enhance the integrity of training data through market forces.The final intersection between copyright law and AI ethics is the value of education. \u201c[E]ducational purposes\u201d are mentioned in the Copyright Act as an example of uses that could be fair under the \u201cpurpose and character of the use\u201d factor.  Of course, educational uses are not per se fair uses, particularly when there is an established market for the kind of educational content at issue, but there are good reasons why educational uses are specifically mentioned in the statute.  So how does this value of education relate to machine learning?  This question surfaces debates about the function of AI machines in human society, including whether an AI itself can have legal rights.  A few scholars have considered whether an AI could possess rights as an author or inventor of things produced by the AI.  No one is asking whether an AI has a right to education that might factor into a fair use analysis of copyrighted training data, or at least whether the ability of AI machines to educate \u2013 or miseducate \u2013 humans provides fodder for a fair use analysis.Part II of this paper briefly reviews what AI is and how it learns.  Part III discusses why AI training involves the reproduction right.  This involves a careful distinction, not often made in the existing literature, between the materials initially used to train an AI and the mathematical tokens stored within an AI.  Part IV examines whether and to what extent a doctrine of non-expressive use should apply to the use of copyrighted materials for AI training. Part V turns to the novel question of education in the fair use analysis of AI training.  This part of the paper explores themes in the emerging field of machine ethics regarding the rights of AI systems.  Part VI concludes.AI Training, Reproduction, and ConsentWhat is AI and How Does it LearnEarly scholarship on the of artificial agents tended to blur distinctions among existing and potential types of agents.  Some of the important early scholarship focuses on what today we call \u201cstrong\u201d AI or \u201cartificial general intelligence\u201d (AGI).  AGI is an artificial agent with capacities for reason and awareness that equal or exceed human capacities.  As far as we know, AGI does not yet exist.  Some researchers and philosophers think AGI is indeed possible and likely, while others believe there is something about the relationship between mind and body that makes AGI based only in machines impossible.The kinds of AI we presently encounter, and that are set to transform our lives in the near future, are forms of \u201cweak\u201d or \u201cnarrow\u201d AI \u2013 or, more accurately, forms of machine learning (ML), including large language models (LLMs) such as ChatGPT.  ML systems use algorithms to process large amounts of data.  Many ML systems are based on \u201cneural networks,\u201d which roughly model how the human brain functions.  An \u201cinput\u201d layer takes information from the outside world; this information is processed within \u201chidden\u201d layers, which in \u201cdeep\u201d neural networks may include millions of nodes (artificial neurons); and the final result of this process is communicated through an \u201coutput\u201d layer.Advances in data storage, computing power, and network design enable vast nodal structures, each containing small data portions, with numerous potential pathways for an input to be analyzed before an output is produced.  Like the human brain, the algorithms include parameters that allow these systems to \u201clearn\u201d as more and more data is processed, creating more and more neural nodes with different connections. The small data portions retained by an ML system are not actual portions of the input training layer itself.  Rather, the input layer is decomposed and translated into algorithmic representations that can be thought of as mathematical \u201ctokens.\u201d  Image recognition is a well-established and easily understandable application of this technology.  Consider a digital photograph, such as the one below, of a beach:Most people could immediately identify this photo as a \u201cbeach\u201d scene.  A little experience with actual beaches, or with photos and videos of beaches, creates pattern recognition pathways in the brain.  If the image includes certain proportions, shapes, colors, and intensities \u2013 a bit of sky blue, a bit of ocean blue, a bit of sandy brown, a bit of green, all following something like the rule of thirds \u2013 there is a high probability the scene is a \u201cbeach\u201d and not, say, a law school classroom.An ML image recognition system can mimic this process using the pixel data in a digital photo.  A typical medium-quality cell phone image contains millions of individual pixels, each with values for screen location, color and intensity.  Groups of pixels with related location, color and intensity can be assigned new algorithmic values, groups of groups can be assigned further values, and so-on, until the millions of individual pixels in the image are reduced to a small set of values that can be compared to algorithmic values from other photos.  With enough training data, the system can probabilistically distinguish \u201cbeach\u201d photos from \u201cclassroom\u201d photos quickly and accurately.Crawling and ScrapingThe process of AI training using publicly accessible data involves web crawling and web scraping.  A web crawler is a program, often called a bot, that analyzes the code on a target website to create an index.   To do this, the crawler must at least make a temporary copy of the target page\u2019s code.  Indexes created by bots can be used for various purposes including search.  A web scraper not only indexes information but also retrieves and stores content, such as text and images, from the target page.  Web crawling and scraping tools are readily available and easy to use.  There are also repositories of crawled and scraped web data available to anyone, such as Common Crawl, which boasts that it \u201ccontains petabytes of data collected since 2008,\u201d including \u201craw web page data, extracted metadata and text extractions,\u201d and other datasets available on the Amazon Web Services (AWS) Data Exchange.   Other crawl datasets, such as LAION, include image and \u201caesthetic\u201d data derived from Common Crawl data.  One of LAION\u2019s \u201cOpenclip\u201d datasets, according to the LAION website, contains 5.8 billion text-and-image pairs. ChatGPT, the Large Language Model (LLM) text model that has generated so much excitement and concern, was trained in part on Common Crawl data.  DALL-E, the image-generation tool that generated comparable buzz, was trained in part LAION data.Existing and Potential Markets for AI Training DataIn addition to open source public databases such as Common Crawl and LAION, there are burgeoning sources of academic and commercial training data derived from various sources, including the open Internet, the Dark Web, experiments, crowdsourcing, proprietary information, partially synthetic, and synthetic data. The \u201cArgoverse\u201d data set, for example, includes data collected by researchers at Carnegie Mellon University and Georgia Institute of Technology using a fleet of autonomous vehicles.  As another example, the \u201cUnsupervised Llamas\u201d data set, provided by the German appliance maker Bosch, includes lidar-mapped lane markers, also for training autonomous driving systems.There are also commercial providers of AI training data.  Some of these providers obtain training data from their own Internet scrapes and from databases such as Common Crawl.  Many of these providers add value to other databases by structuring datasets \u2013 that is, by adding tags and other metadata so that the data is more useful and comprehensible from the start.  Yet others use a crowdsourcing model to obtain base data from individual contributors.  A crowdsourcing model can be useful, for example, to train language models on languages other than English. Still other providers specialize in \u201csynthetic\u201d training data.  This can include partially synthetic data, which creates datasets based on deidentified or otherwise modified real data (whether open or proprietary) and fully synthetic data not derived from any real dataset. As Michal Gal and Orla Lynskey note, synthetic data markets can improve the quality of training data, protect privacy, and enhance competition by reducing barriers to entry into markets creating AI products.  Gal and Lynskey note that 60% of AI training data will be synthetic by 2024.As this survey suggests markets for unstructured and structured AI training data are developing rapidly alongside the growth of AI use case and applications.  Initial Copyright Issues:  Copying, Consent and Transitory ReproductionCopyingThe first question raised by AI training data is whether it involves copying at all.  As discussed in Part II.A., supra, an AI does not retain complete or partial copies of its training data.  Rather, it uses the training data to generate algorithmic tokens, which are employed within its multitude of artificial neurons to make probabilistic decisions.  Some commentators seem to suggest that AI training therefore might not implicate the reproduction right.  Pam Samuelson, for example, notes that, because of the idea/expression dichotomy, \u201c[p]hotographs of cats . . . do not give the photographer exclusive rights to characteristic features of cats, such as their noses or facial expressions.\u201dSamuelson is, of course, correct about the features of cats.  If the only portion of the cat photograph reproduced during training were the eyes, nose, and mouth, perhaps this would not comprise a reproduction.  But this is not ordinarily how AI training data works.  A facial recognition AI, for example, looks at many pictures of faces and extracts mathematical relationships between various points on each face it reviews.  The following graphic illustrates this process:The mathematical representations labeled F7 and F8 on this graphic are stored in the system\u2019s artificial neurons.  As Samuelson suggests, those mathematical representations probably are not copyrightable, even aside from the fact that they are entirely machine generated.  They are more like facts or ideas than expression.  But the original image is reproduced at least temporarily to generate the mathematical representations.  As Ben Sobel notes, this initial reproduction of the original image is a prima facie violation of the reproduction right. Notwithstanding his acknowledgment that most AI training involves reproduction, Sobel suggests that in some cases training data might involve only non-infringing de minimus copying.  As an example, Sobel argues that human facial recognition program trained only on specific portions of human portraits might not entail reproductions of the underlying portraits.  Perhaps Sobel is in some sense correct.  Copying is a fact-specific inquiry.  But the example Sobel offers shows why de minimus copying is unlikely to be a good defense in most cases.  That example is Labeled Faces in the Wild (\u201cLFW\u201d), a data set used for testing facial recognition applications.  LFW is maintained by the University of Massachusetts Amherst.  Sobel suggests that \u201clittle copyrightable content remains in the dataset\u201d because the dataset reproduces \u201conly the portions of the photographs that show the subjects\u2019 faces. . . .\u201d  A review of the dataset, however, shows that it undoubtedly violates the reproduction and adaptation rights of the copyright owners in the underlying photographs, absent fair use.LFW\u2019s base images were culled from a larger set of images, called \u201cNames and Faces,\u201d extracted by other academic facial recognition technology researchers from the commercial Yahoo News website.  Those researchers obtained their \u201cvery large data set\u201d of from \u201chalf a million news pictures\u201d using a face detection tool.  A technical paper describing Names and Faces shows how the cropped photos connect to the underlying photos (which are available through links in Names and Faces):Contrary to Sobel\u2019s suggestion, it seems highly unlikely that a court would find the cropped versions of these photos are non-infringing.  The cropped faces still reflect decisions made by the photographers about timing, pose, lighting, expression, and effects that allow copyright in the photographs.  These unlicensed reproductions prima facie violate the authors\u2019 reproduction and adaptation rights.In addition to supporting the claim that AI training data almost always involves copying, the LFW example also shows why copyright issues relating to AI training data involves much more than the mathematical tokens generated and stored in any one AI system.  There are markets for AI training datasets, like LFW, that remain persistent over time.   These training databases retain the original materials used for training.  Not only is the proprietor of an AI system using the training data to create reproductions and adaptations, but so is the proprietor of the training database.  This might be motivated by academic research purposes, as in the case of the LFW, or for commercial purposes by entities that license their databases for training.  We will return to a fuller discussion of these issues when we discuss fair use.  First, we discuss two reasons why this prima facia infringement of the reproduction right might not produce liability:  transitory reproduction and consent.Transitory ReproductionAs the discussion in part II.A. shows, AI training databases gleaned from crawling and scraping usually retain copies or adaptations of the original training data that likely are infringing absent consent or fair use.  Transitory reproduction does not apply to these databases.  Specific AI systems, however, store raw training data in memory only briefly and  retain only uncopyrightable mathematical tokens abstracted from the training data.  A line of cases running from the early computing and video game eras into the early period of digital video retransmission might suggest that \u201ctransitory\u201d copies of made during training are not infringing.  Transitory reproduction would not protect training databases, but it might apply to some applications that use training data.Section 106 of the Copyright Act gives the owner of the copyright the exclusive right \u201cto reproduce the copyrighted work in copies . . . .\u201d  The Copyright Act defines \u201ccopies\u201d as \u201cmaterial objects, other than phonorecords, in which a work is fixed by any method now known or later developed, and from which the work can be perceived, reproduced, or otherwise communicated, either directly or with the aid of a machine or device.\u201d Somewhat confusingly, under the 1976 Act, copyright is also acquired when a work is \u201cfixed in a tangible medium of expression.\u201d  In its definitional section the Act states that \u201c[a] work is \u2018fixed\u2019 in a tangible medium of expression when its embodiment in a copy or phonorecord, by or under the authority of the author, is sufficiently permanent or stable to permit it to be perceived, reproduced, or otherwise communicated for a period of more than transitory duration.\u201d Fixation, then is implicated in both the acquisition of copyright and what comprises a potentially infringing copy under the reproduction right.  Courts first focused on the word \u201cfixed\u201d in connection with computing and digital video technologies that make temporary \u201ccache\u201d copies of some content and in connection with video games that produce ephemeral displays on a screen. Early cases involving 1980\u2019s arcade video games set the stage for this argument.  These cases involved read-only memory chips (ROMs) programmed to modify or reproduce popular arcade games.  Defendants argued that the games were not \u201cfixed\u201d because the sequence of images and sounds appeared only briefly on a screen during play and could vary in multiple ways through the player\u2019s interaction.  Courts rejected these arguments, holding that the instructions programmed onto the original games\u2019 ROM chips sufficiently fixed the games\u2019 images, patterns, and sequences, notwithstanding variation from user input.The next phase of the debate over fixation involved computer RAM memory.  At the dawn of the personal computing era, in the pioneering and much-derided case of MAI Systems Corp. v. Peak Computer, Inc., the Ninth Circuit held that \u201ccopying\u201d of a computer program occurs whenever the program is transferred from permanent storage to temporary RAM memory.  The case involved a service company, Peak, hired to maintain and repair computers running MAI software.  MAI\u2019s customers were licensed to use the software, but that license did not extend to third party maintenance companies.  Peak argued that it never reproduced the software because it did not copy or modify any of the files on its customer\u2019s hard drives.  MAI argued that a copy is made every time the computer is turned on because software files are loaded into temporary RAM memory so the program can run. The court agreed with MAI.  This decision, which enabled software providers to control aspects of the maintenance and repair of computer systems, attracted much scholarly and policy debate.From the video game and MAI cases, it seemed that the fixation with \u201cfixed\u201d was futile.  In 2008, however, the Second Circuit in its Cablevision decision seemingly breathed new life into the question by holding that a temporary \u201cbuffer\u201d copy of a video transmission was not infringing.  This case involved early versions of cloud-based DVRs in a time just before the streaming revolution.  One of the purposes of the 1976 Copyright Act was to bring U.S. copyright law into closer harmony with the Berne Convention concerning copyright formalities and term.  Another purpose was to accommodate the new and growing business of cable television.  Cablevision was authorized to retransmit television signals to its cable television subscribers.  The Sony case established under the fair use doctrine that individuals could record television programs on home VCRs for the purpose of \u201ctime shifting.\u201d  Cablevision\u2019s cloud-based DVR took a stream of its broadcast data into buffer memory that held the data for no more than 1.2 seconds.  This facilitated real-time rewind for users.  If a customer wanted to record a program for later viewing, the data was stored in server space allocated to that customer.  The Second Circuit held that the Act\u2019s definition of \u201cfixed\u201d \u201cimposes two distinct but related requirements: the work must be embodied in a medium, i.e., placed in a medium such that it can be perceived, reproduced, etc., from that medium (the \u2018embodiment requirement\u2019), and it must remain thus embodied \u2018for a period of more than transitory duration\u2019 (the \u2018duration requirement\u2019).\u201d  The court distinguished MAI by noting that the \u201cduration\u201d requirement had not been fully litigated in that case. The court concluded that the buffer copies in Cablevision\u2019s cloud DVR were not fixed under the duration requirement and therefore could not be infringing \u201ccopies.\u201d  AI training might resemble the \u201ctransitory\u201d copies of the Cablevision cloud DVR because, once an AI is trained on a dataset, the underlying data as such does not remain within the AI system.  But the Cablevision court did not set any outer bound for what \u201ctransitory\u201d means.  In raw, unstructured AI training, any individual artifact may be ingested, deconstructed, and compared relatively quickly \u2013 maybe even comparable to the 1.2 seconds of the Cablevision ingest buffer.  Best practices for AI training, however, require more time with the data, because a human being is in the loop applying metadata and adjusting the algorithms before and during the training.  In fact, there is now a rapidly growing industry in data annotation.This variability highlights a significant problem with Cablevision\u2019s view of copying:  the meaning of \u201ctransitory\u201d is essentially arbitrary and infinitely malleable depending on technology and circumstances.  The 1.2 seconds used by Cablevision\u2019s ingest buffer is rapid compared to unaided human capabilities, but it already seems ponderously slow compared to current data transmission and computer processing speeds.  What is \u201ctransitory\u201d to the human eye is leisurely to a powerful computer.  What takes hours of computing time today will take seconds in a few years.  When quantum computing takes hold, everything we do today will seem sloth-like.  It seems that Cablevision\u2019s view of copying really was shorthand for fair use and that fair use is where an analysis of short-term copying for data processing purposes belongs.In addition to these factual and doctrinal problems, as noted in Part II.A., from the perspective of AI policy and ethics, we do not want proprietors of AI systems to destroy their training data.  If the AI is producing undesirable results, the training data might help us understand why.  Further, privacy law in many jurisdictions requires that data subjects whose personally identifiable information was used in training data have access to the data and rights of portability and rectification.  At the very least an AI proprietor should be able to explain what, if any, of a data subject\u2019s PII was used and subsequently deleted.  Transitory reproduction, then, seems a bad fit for avoiding copyright in AI training data.ConsentPerhaps the most obvious and most overlooked response to copyright in AI training data gleaned from the Internet is consent.  Copyright owners, of course, can \u201cauthorize\u201d others to user their works through assignments and licenses.  This is, indeed, how people in creative industries typically make money from copyrights.  Of course, most copyright-protected content is not directly monetized.  Many commercial websites explicitly do not make money directly from their content but exist to direct users to their products and services.  Such sites typically link to a terms of service that allow users to view the content through their Internet browsers but not otherwise to make copies or distribute the content. And most people who contribute online content through social media sites and the like do not make money from their content.  They receive other social rewards in return for the nonexclusive licenses they give to hosting sites to publish their content.  In both the typical commercial and social media cases, licenses are usually limited to the intended use of making the content available for others to view online, which would preclude other uses, including web crawling and data scraping.  But these sites are routinely crawled for the purpose of Internet search without allegations of copyright infringement.  In fact, web crawling is the foundation for Internet search engines, including Google.  Crawling is how Google indexes the web.  Google, not surprisingly, never asked for anyone\u2019s permission before launching its indexing and search technology.  So why aren\u2019t Google, Bing, and other search providers liable for billions upon billions of instances of copyright infringement?The fact is that no one knows because there has never been serious test litigation over standard web search.  There are some well-known early cases involving some aspects of image search, particularly the Google v. Perfect10 and Kelly v. Arriba Soft cases.  These cases, discussed in subpart II.D below, are widely considered to establish that search is fair use.  But these relatively early cases, decided by a few circuit courts, examining specific kinds of rough image-based search capabilities, seem a rickety support for the massive, globally important search business.The more prosaic explanation is consent.  In addition to their terms of use, websites by convention include a \u201crobots.txt\u201d file that specifies the rules for web crawlers.  Most web content producers want their sites indexed by search engines such as Google, so there is no reason to configure the robots.txt file to the contrary or to deploy other technological protection measures, much less to sue Google for copyright infringement.  Some courts have held that a robots.txt file is a technological measure under the Digital Millennium Copyright Act such that circumventing the file\u2019s restrictions is unlawful. Perhaps, as a few courts have held, configuring the robots.txt file so that it allows crawling is a form of express or at least implied license to reproduce the content to the extent necessary for the allowed purpose, such as web indexing.  Perhaps also the express or implied consent to web crawling for search extends to crawling and scraping for AI training. This seems to motivate some of the copyleft sentiment that copyright should not restrict the use of public web content for AI training.  Internet search fostered a set of norms about some kinds of crawling that facilitated search and that no one wants to test.  But copyright litigation over web-scraped AI training data sets, either in conformity with robots.txt permissions or in circumvention of them, might test the current \u201clook the other way\u201d ethos of crawling and data mining beyond its breaking point.  Indeed, this seems already to be happening, the growing litigation and regulatory activity around copyright in AI training data shows.  An argument grounded in implicit consent seems unlikely to prevail, certainly on a prospective basis if a copyright proprietor explicitly restricts use of its content for AI training.  Fair use would be a much more secure ground apart from consent \u2013 or, as the discussion in Part IV will argue, a fair use analysis suggests that the best solution is a more robust focus on consent through a combination of voluntary and compulsory licensing explicitly linked to AI training uses.Fair Use: So-Called Non-Expressive UsesSome AI advocates argue for a broad fair use principle that would make copyrighted material generally available for AI training.  These arguments mirror broader concerns about the information commons and the research commons.  Such concerns are understandable, but they rest on uncertain doctrinal grounds and overlook the dynamics of AI training and application markets.Non-Expressive Use:  Not Quite a DoctrineThe doctrinal core of this fair use argument is non-expressive use.   For example, OpenAI, the creator of ChatGPT and DALL-E, argues that its use of training data is transformative because \u201c[w]orks in training corpora were meant\u00a0primarily for human consumption for their standalone entertainment value\u201d and because the outputs of the LLM are different than the training data.  The 1976 Copyright Act lists four factors for determining whether a use is fair:  (1)\tthe purpose and character of the use, including whether such use is of a commercial nature or is for nonprofit educational purposes;(2)\tthe nature of the copyrighted work;(3)\tthe amount and substantiality of the portion used in relation to the copyrighted work as a whole; and(4)\tthe effect of the use upon the potential market for or value of the copyrighted work.Under the \u201cpurpose and character of the use\u201d factor, according to the Supreme Court in Campbell, the question is \u201cwhether the new work merely \u2018supersede[s] the objects\u2019 of the original\u00a0creation, or instead adds something new, with a further purpose or different character, altering\u00a0the first with new expression, meaning, or message; it asks, in other words, whether and to what\u00a0extent the new work is \u2018transformative.\u2019\u201dNon-expressive use focuses on the way copyrighted works can function as inputs in the production of outputs that are not themselves infringing on the input works.  Our simplified image recognition AI is a good example.  The training inputs include images of beaches.  The system\u2019s output is not any kind of image at all:  it is a decision upon evaluating another image.  The decision \u2013 \u201cyes that is a beach\u201d or \u201cno that isn\u2019t a beach\u201d \u2013 obviously does not infringe on the beach training images.  The non-expressive use concept has some intuitive appeal.  A photographer cares about her beach photograph, and the market for that photograph, not about the decision whether some other photograph is also a beach scene.  The theoretical and practical basis for this supposed doctrine, and for its application to AI training data, however, seems shaky.  At the very least, it cannot serve as blanket permission to exploit copyrighted works for AI training in all circumstances.Book Scanning, Search Engines, and Digital ArchivesThe most persuasive argument for non-expressive fair use is derived from the Second Circuit\u2019s decisions in the Google Books and Hathi Trust cases.  These cases involved scanning large volumes of books from academic and other libraries.  Hathi Trust included books scanned by Google, the Internet Archive, and Microsoft.  Text-to-speech versions of copyrighted books were made available through the Hathi Trust website to individuals with visual disabilities and allowed anyone to search the text of scanned books. Google Books addressed Google\u2019s \u201csnippet view,\u201d which allowed a user to search the full text of a copied book and returned the search term in context with a small portion of the text.  In its Google Books decision, the Second Circuit noted that \u201c[c]omplete unchanged copying has repeatedly been found justified as fair use when the copying was reasonably appropriate to achieve the copier's transformative purpose and was done in such a manner that it did not offer a competing substitute for the original.\u201d  The \u201csnippet view\u201d did not allow users to piece together an entire book.  The court concluded that \u201cGoogle has constructed the snippet feature in a manner that substantially protects against its serving as an effectively competing substitute for Plaintiffs' books.\u201d  The Second Circuit reached a similar conclusion about the \u201csearch\u201d function in the Hathi Trust case, along with reproductions made accessible to blind persons.The Google Books project can be seen as a kind of early rehearsal for today\u2019s quantitatively much larger and qualitatively much more disruptive arguments about AI training data.   In his interesting paper Copyright for Literate Robots, for example, Professor James Grimmelmann argues that the Second Circuit\u2019s Google books decision supports the argument that \u201c[b]ulk nonexpressive uses,\u201d including \u201cbulk reading\u201d by machines, \u201care fair uses.\u201d  In that paper, Grimmelmann sketches what he believes existing doctrine says, not necessarily what it should say.  He acknowledges that \u201c[i]t is easy to see how bulk nonexpressive copying promotes progress in artificial intelligence,\u201d but this, he says, \u201carguably increases the chances that humanity will meet a sudden, violent, and extremely unpleasant end.\u201d  A similar argument, although seemingly with less hesitation about the dangers of AI is made by Professors Mark Lemley and Bryan Casey in their paper Fair Learning. It is not so clear, however, that existing doctrine says anything so broad about \u201cbulk non-expressive uses.\u201d  The Second Circuit\u2019s focus in Google Books and Hathi Trust was on the market for the copyrighted work, not on the degree of expression in the allegedly infringing use.  For the Second Circuit, the \u201camount and substantiality of the portion used\u201d factor must be read in tandem with the \u201ceffect on the market factor.\u201d  The court credited Google\u2019s and Hathi Trust\u2019s factual arguments that search snippets enabled by full-text scans would not erode the market for complete published books.  This is not any kind of doctrinal conclusion about other kinds of \u201cbulk non-expressive uses,\u201d much less about AI or robot uses.  Lemley and Casey also argue that the bulk non-expressive use exception is rooted in early Internet search engine cases.   They claim that \u201cnon-expressive use\u201d exception is \u201cthe reason most automated search and analysis tools exist in the first place.\u201d  The cases, however, are not so clear.  In an early image-based search case relied upon in support of a non-expressive use exception, Perfect 10 v. Amazon, the Ninth Circuit held that Google did not infringe the display or distribution rights by providing hyperlinks to full-sized photos housed on Perfect 10\u2019s servers, but that thumbnail versions of the images could infringe these rights \u2013 the \u201cserver test.\u201d   However, the court held that Google\u2019s use of the images was fair use.  Under the purpose and character of the use factor, the court concluded that \u201c[a]lthough an image may have been created originally to serve an entertainment, aesthetic, or informative function, a search engine transforms the image into a pointer directing a user to a source of information.\u201d Perfect 10\u2019s reasoning seems similar to the case for fair use of AI training data:  the training process transforms the image into a mathematical cipher for decision making.  The claims in Perfect 10, however, only involved the display and distribution rights, not the reproduction or derivative work rights.  Training data is not displayed or distributed as a pointer to other information.  It is copied wholesale in order to make what is arguably a derivative work. Another early search engine case, Kelly v. Arriba Soft, is closer to the point. Arriba Soft\u2019s crawled and scraped images to generate low-resolution image thumbnails used in its search engine.  Under the first fair use factor, the Ninth Circuit stated that \u201cArriba's search engine functions as a tool to help index and improve access to images on the internet and their related web sites\u201d and that the thumbnails were not useful for artistic purposes because of their low resolution.  This functional difference, along with the lack of a market for the use of Kelly\u2019s images in search engines, led the court to find the use was fair use.The functional change from aesthetically pleasing work to cipher in a search engine could be similar to the change in function when information is used to train an AI, at least involving things like photographs.  On the other hand, because some of the copyrighted works used to train an AI are meant for training human beings, the transformation is not so dramatic.  Moreover, in both Perfect 10 and Kelly, as in most cases, the transformativeness factor was closely tied to the effect on the market factor. The more transformative the use, the less likely the use falls within the zone of the input work\u2019s existing or reasonably possible markets.  At the time of those cases, there was no market for the licensing of copyrighted works for search engine listings. The early search engine cases, then, could fit Wendy Gordon\u2019s paradigm for fair use as a response to market failure.  The question was not so much about whether the use of the copyrighted inputs was expressive as it was about whether there was a viable market for the input works as inputs.  But the transformation that might comprise a different market is not just in turning something non-expressive into something expressive.  In fact, something that is at present non-expressive may have great market potential precisely because it has not (yet) been publicly expressed \u2013 that is, an unpublished work  There is a growing market for use of existing and new works of all kinds AI training data, which suggests that the early search engine cases may not apply.  In any event, the cases focus on specific uses and markets and do not announce a generally applicable rule of non-expressive fair use.Other Bases for Non-Expressive Use   In addition to the early search engine and Google Books / Hathi Trust cases, Mathew Sag and other scholars posit a concept of non-expressive fair use based on various snippets of copyright doctrine, including the collective work right as discussed in the Supreme Court\u2019s opinion in New York Times v. Tasini. Tasini dates to an era when newspapers such as the New York Times were just beginning to digitize their past and current print editions.  Text-only digital copies were made available on commercial databases such as NEXIS and on CD-ROMs.  Previously newspapers were archived on the analog media of microfilm or microfiche, copies of which could be obtained and indexed by libraries.  Plaintiffs were independent journalists who had contributed articles to publications such as the New York Times.  They argued their publication agreements only permitted the use of their copyrighted works as part of a collective work \u2013 the print newspaper \u2013 and not as part of  databases through which articles could individually searched and viewed apart from their publication in the collective work.  When Tasini was heard in 2001 it was viewed as a watershed moment in the developing Internet era:  would collective work publishers such as the New York Times have to engage in burdensome spade work to identity decades of past writers or their heirs, and pay potentially crippling new royalties, so that the public could search and access these documents easily in digital formats?  On the writer\u2019s side of the argument, would powerful legacy publishers such as the Times, in league with big database companies such as NEXIS, control the Internet\u2019s development and the public\u2019s ability to learn about history, or would that power be dispersed down to individual writers?  Iconic American historian and filmmaker Ken Burns even weighed in with an amicus brief.The Court held that an agreement to contribute a work as part of a collective work includes only the rights of reproduction and distribution as part of the collective work.  This, the Court said, was clear from Section 201(c) of the Copyright Act, which states that Copyright in each separate contribution to a collective work is distinct from copyright in the collective work as a whole, and vests initially in the author of the contribution. In the absence of an express transfer of the copyright or of any rights under it, the owner of copyright in the collective work is presumed to have acquired only the privilege of reproducing and distributing the contribution as part of that particular collective work, any revision of that collective work, and any later collective work in the same series.As Sag notes, the Court distinguished between collective works and databases with reference to how the content appears to an ordinary user.  Sag concludes that the Court thereby \u201creinforced that expressive communication to the public is the touchstone of copyright infringement.\u201d Tasini, however, was primarily a case about transfers and only secondarily about infringement.  Section 201 governs transfers of rights.  As Justice Stevens noted in a dissent joined by Justice Breyer, the case \u201craise[d] an issue of first impression concerning the meaning of the word \u2018revision\u2019 as used in \u00a7 201(c) . . . .\u201d  The majority examined how the print, microfiche, and database versions appeared to the public to assess whether the database was a \u201crevision\u201d of a collective work or something new.  There was no dispute that if the agreements executed by the authors did not cover the databases as \u201crevisions\u201d of collective works, the resulting reproduction and distribution would be infringing.  Nothing in either the majority or dissenting opinions suggested a broad right of non-expressive use.Sag also emphasizes the idea-expression dichotomy in favor of non-expressive use.  This sort of question in American copyright law has been addressed in the context of catalog and database protection, starting the Feist Court\u2019s treatment of the decidedly old-school technology of telephone white pages.  As a result of Feist\u2019s reading of the idea/expression dichotomy, under U.S. law, individual facts or data points within databases are not protectible \u2013 a position at odds with the law in Europe and other parts of the world.   It is true that the idea-expression dichotomy could be relevant to some infringement claims against \u201ccopyright-reliant technologies,\u201d including today\u2019s AI systems.  If an AI is trained on nothing but tables of historical data \u2013 say, for example, stock prices \u2013 the idea-expression dichotomy would become important.  The issue might arise first as to the copyrightability of the underlying works and then under the \u201cnature of the copyrighted work\u201d and \u201camount and substantiality of the portion used\u201d fair use factors.  In addition, the idea-expression dichotomy also could be relevant to a claim that the mathematical tokens resulting from AI training are copyrightable.  But as noted in Part III.C. above, the process of creating such tokens begins with reproduction of text, image, and video files and the like.  In most cases, this content undoubtedly passes the low threshold of \u201cexpression\u201d under U.S. copyright law and the entire files or substantial portions of the files are ingested.The Digital Elephant in the Room and the Fair Use Mouse: Computer Software and APIsThe early to mid-Internet era cases discussed above concerned aspects of digital database technologies apart from the software that makes those technologies run.  Copyright protection for software as such is the large statutory elephant in the room raising its eyebrows at claims of non-expressive fair use.  Computer code usually is not visible to the public.  In many contemporary software-as-a-service cloud applications the code remains on servers controlled by the copyright owner or its agents.  Sag suggest that software is a statutory anomaly that should not dilute his broader argument.  But as a matter of statutory interpretation, there is no doubt that computer code is copyrightable, so the Copyright Act cannot be read to include a general fair use protection for all non-expressive uses. The Supreme Court\u2019s recent decision in Google v. Oracle, however, could signal more fair use latitude for at least some kinds of code inputs.  In that case, the Court found that Google\u2019s use of the Oracle Java Application Programming Interfaces (APIs) was transformative because Google used the APIs \u201cto create a new platform [Android] that could be readily used by programmers.\u201d  The Court noted that fair use \u201ccan play an important role\u201d in balancing statutory copyright for software against other interests in copyright law.  According to the Court, as to software, fair use can \u201chelp to distinguish among technologies, . . . distinguish between expressive and functional features of computer code,\u201d and balance the need for incentives to create against \u201cunrelated or illegitimate harms in other markets or to the development of other products.\u201dAPIs are portions of code that allow application programs to interface with a device operating system.  An operating system provides access to and control over a computing device\u2019s processing capabilities and hardware functions.  The proprietor of an operating system, application, or piece of hardware may make APIs available, either for free or under the terms of a license, so that other developers or consumer can create compatible applications or devices.Java was developed as a lightweight language for applications on devices such as television set-top boxes.  It became widely used for web-based and desktop computer applications.  Google copied portions of some Java APIs without a license.  According to the Court, the portions copied included only \u201cdeclaring code\u201d \u2013 essentially the name of a function \u2013 and not the \u201ctask-implementing programs\u201d that would be called upon by the declaring code.  This meant that programmers familiar with Java could use well-known declaring code to implement functions in the Android operating system.This kind of use, the Court stated, \u201cwas consistent with that creative \u2018progress\u2019 that is the basic constitutional objective of copyright itself.\u201d  The Court also found that the amount and substantiality of the portion used was related to its purpose of permitting \u201cprogrammers to make use of their knowledge and experience using the Sun Java API when they wrote new programs for smartphones with the Android platform.\u201d The effect on the market, according to the Court, favored fair use because Android was unlikely to be able to compete in the operating system market and because Google\u2019s development of the Android platform benefitted the consuming public.  The effect on the market analysis in Google v. Oracle thereby resembled the kind of consumer welfare inquiry made in first-generation antitrust cases involving computer operating systems and web browsers.  The Court was concerned not only with the licensing market for Java and Java APIs, but also with whether restrictions on access to the APIs would limit competition in the broader operating system market.There are some surface parallels between Google v. Oracle\u2019s treatment of APIs and the use of copyrighted materials as AI training data, but the underlying concerns are quite different.  Training data resembles APIs in that both are not themselves user applications but are necessary to facilitate user applications.  But APIs are good for nothing other than serving as APIs.  AI training data \u2013 aside from \u201csynthetic\u201d data \u2013 primarily serve other functions as images, text, videos, and sounds.  The use of APIs in software development is a non-expressive use because APIs have no expressive function at all.  The use of copyrighted material as AI training data might be a non-expressive use, but the underlying works otherwise have expressive functions.  Further, APIs are created by the developers of the operating systems, software, or devices to which they provide a programming interface.  If the developer can control the APIs, it can control secondary markets for systems, applications, and devices that interface with the underlying product.  When the underlying product is central to a technological ecosystem \u2013 like Java \u2013 restricting fair use could raise the quasi-antitrust concerns suggested by the Google v. Oracle majority.  Such control is impossible as to any individual copyright-holder in a typical AI training scenario.  Training data repositories such as Common Crawl and LAION are drawn from billions of individual sources and there is no plausible claim that any one source is necessary to develop a competitive product.In sum, there is some support for a concept of non-expressive fair use in parts of the case law, but it is hardly a clear or well-established concept.  Google v. Oracle adds some weight to the claim that adapting a copyrighted input for a different purpose might be fair use, at least as to computer code, which is inherently close to the line of copyrightability set by the idea / expression, merger, and functionality doctrines. Yet there are significant differences between APIs and the multifarious works that may be used as AI training data.The Warhol EffectThe Court\u2019s most recent foray into fair use, although in a context that involves a clearly expressive use, further complicates things for any non-expressive fair use doctrine as applied to AI training data.  That case involved Andy Warhol\u2019s pop art silkscreen portrait of the musician Prince based on a photograph by rock photographer Lynn Goldsmith.  The Warhol Foundation argued that Warhol\u2019s treatment of the photograph, in a style for which Warhol had become famous, was transformative.  Writing for the majority, Justice Sotomayor stated that the first fair use factor \u201cfocuses on whether an allegedly infringing use has a further purpose or different character, which is a matter of degree, and the degree of difference must be weighed against other considerations, like commercialism.\u201d  Although transformativeness \u2013 what Justice Sotomayor called \u201cnew expression\u201d \u2013 \u201cmay be relevant . . . it is not, without more dispositive of the first factor.\u201dJustice Sotomayor noted that the illustrative fair use purposes in section 107 offer paradigmatic examples of uses that are not merely substitutions for the underlying work.  But even new works that are in some sense transformative, she stated, can fall within the scope of the copyright owner\u2019s right to control derivative works.  This is evident, she argued, in the statutory definition of a derivative work, which includes \u201cany other form in which a work may be recast, transformed, or adapted. . . .\u201d  Therefore, according to Justice Sotomayor, \u201can overbroad concept of transformative use, one that includes any further purpose, or any different character, would narrow the copyright owner's exclusive right to create derivative works. To preserve that right, the degree of transformation required to make \u2018transformative\u2019 use of an original must go beyond that required to qualify as a derivative.\u201dRooted in this discussion of the tension between transformative fair use and transformative derivative works, Justice Sotomayor offered two elements to consider under the first factor in addition to transformativeness:  (1) whether the use is commercial; and (2) the purpose of the use.  If the use is commercial, this is not dispositive, but it cuts against fair use.  If the use has a \u201cdistinct purpose\u201d that \u201cfurthers the goal of copyright, namely, to promote the progress of science and the arts, without diminishing the incentive to create,\u201d such as parody or satire, this cuts in favor of fair use.  In sum, the Court stated, the first fair use factor considers whether the use of a copyrighted work has a further purpose or different character, which is a matter of degree, and the degree of difference must be balanced against the commercial nature of the use. If an original work and a secondary use share the same or highly similar purposes, and the secondary use is of a commercial nature, the first factor is likely to weigh against fair use, absent some other justification for copying.The inquiry into purpose thus is not a subjective account of the user\u2019s intent but rather is \u201can objective inquiry into what use was made, i.e., what the user does with the original work.\u201dApplied to Warhol\u2019s treatment of the Goldsmith photo, the Court found that the original photo and Warhol\u2019s treatment served the same purpose of illustrating magazine stories about Prince and that this similarity of purpose together with the commercial nature of Warhol\u2019s use cut against fair use.  In response to concerns that this seemingly narrower reading of transformativeness would stifle future creativity, Justice Sotomayor responded that \u201c[i]t will not impoverish our world to require AWF to pay Goldsmith a fraction of the proceeds from its reuse of her copyrighted work. Recall, payments like these are incentives for artists to create original works in the first place.\u201dWarhol\u2019s limited view of transformativeness seems inconsistent with Google v. Oracle\u2019s more expansive view.  Justice Sotomayor attempted to distinguish Google v. Oracle in several ways.  She noted that \u201cin applying the fair use provision, \u2018copyright's protection may be stronger where the copyrighted material ... serves an artistic rather than a utilitarian function.\u2019\u201d  Because the Java code at issue in that case was \u201cprimarily functional,\u201d she suggested, it was more difficult to determine a line between unlawful copying and fair use.  Further, Google put the Java APIs to use in a \u201cdistinct and different computing environment,\u201d that is, in an operating system built for mobile devices rather than in desktop and laptop computers.  The dissent, authored by Justice Kagan and joined by Justice Roberts, found this effort to distinguish Google v. Oracle unpersuasive, particularly since the Google Court mentioned Andy Warhol\u2019s \u201cCampbell Soup\u201d can graphics as paradigmatic of transformative use.Applying the Warhol Court\u2019s additional elements to AI training data likely will not yield predictable results.  As to the first element, some AI applications are non-commercial, but many, if not most, are and will be commercial, or are and will be embedded into commercial products.  Even many free AI products, including ChatGPT and DALL-E, collect user data that can be exploited by the proprietor, so they are not really free.  This factor usually will cut against fair use.As to the second element, some AI applications might \u201cfurther[] the goal of copyright, namely, to promote the progress of science and the arts,\u201d but others might not.  An AI application such as a text or image generator produces things that resemble traditional domains of copyright policy \u2013 text and images \u2013 but the output is generated by a machine.  The Copyright Act anticipates the use of machines to fix, store, copy, distribute, and transmit copyrightable works, but it does not anticipate that machines could be responsible for copyrightable expression.  Courts and commentators are only just beginning to grapple with whether AI-generated content is copyrightable, and the better answer is that it is not.  Many, if not most, AI applications, however, do not produce any arguably creative output at all.  The basic function of most AI applications is to make predictions and decisions:  is this an image of a beach or a desert; should the car turn left here; does Alice qualify for a mortgage; is Bob a potential candidate for this job; does this circuit board pass quality control; what advertisement will appeal to this user; and so-on.  Although the copyrighted inputs used for AI training were employed for reasons well beyond the purposes of their original creation, the purpose of the training was not the purpose of copyright, that is, the publication of more expressive content.  Under Warhol\u2019s reading of the first factor, then, it seems that the \u201cnon-expressive\u201d character of the use cuts against fair use under these circumstances.The Markets in Google and Warhol and the Markets for AI Training dataTransformativeness and the Effect on the MarketThe Warhol Court, consistent with Google v. Oracle, Campbell, and other important fair use cases, recognized that the nature and character of the use factor is closely tied to the fourth factor, the effect on the market for the copyrighted work.  Although both Warhol and Google v. Oracle focused mostly on the first factor, it is possible to understand these cases more clearly through the fourth factor.  Similarly, fair use cases involving copyrighted AI training data might turn on whether there are existing or prospective markets for copyrighted text, images, and other content to be repurposed as AI training data.  When the present generation of text and image generators were trained, perhaps those markets were not yet on the horizon.  But it is easy to see how such markets could be plausible, and beneficial, now that dynamics of AI training are becoming more publicly known.  According to the Google v. Oracle Court, the jury could have found that there was a market for the Java APIs as a whole but not for declaring functions apart from the substantive routines called by those declarations.  Oracle was not in the business of using Java to create a mobile operating system. The jury also could have concluded, the Court said, that Google\u2019s use of some declaring functions for the convenience of developers did not appreciably affect existing or prospective markets for Java.  Further, the jury could have found that Google\u2019s Android operating system, through it incorporated some Java API declaring code, was not a market substitute for Java \u2013 that \u201cGoogle\u2019s Android platform was part of a distinct (and more advanced) market than Java software.\u201dIn addition to this more traditional review of facts relating to market substitution, the Google v. Oracle Court also stated that the \u201ceffect on the market\u201d factor can encompass not only the parties\u2019 financial gains and losses, but also \u201cthe public benefits the copying will likely produce.\u201d  This inquiry includes how the copying relates to \u201ccopyright\u2019s concern for the creative production of new expression\u201d and the degree of \u201cimportance\u201d of those benefits compared to the parties\u2019 monetary gains or losses.  The Court found that Google\u2019s copying benefitted the public because application programmers were already deeply familiar with the Java APIs.  Requiring programmers to learn a new set of declaring functions, the Court said, would allow Oracle to stifle innovation in new markets.The Court\u2019s discussion of quasi-antitrust lock-in effects reflects a deeper concern raised in many of the amicus briefs about open-source norms for APIs.  The proprietor of an operating system, software package, or device sometimes releases APIs publicly for free.  This often happens when the underlying system, package, or device provides a kind of infrastructure for other applications.  Microsoft, for example, publicly releases APIs for its Windows operating system.  An operating system is subject to network effects, meaning it is more valuable to each user as more users adopt the platform.  Microsoft encourages the development of third-party applications that work with Windows because successful applications grow the user base and make the platform even more valuable to all users.  The same is true of APIs for Apple operating systems.  Although Windows and Apple dominate the market for desktop and laptop operating systems, their open API programs facilitate flourishing application markets.But not all APIs are open.  Sometimes a proprietor keeps all APIs in-house. This might be the case, for example, with a complex device that is more of a commodity than a platform, such as TESLA electric vehicles.  Alternatively, a proprietor might make APIs available for license to certain business partners, as was the case with the Java APIs at issue in Google v. Oracle.  As Justice Thomas noted in his dissent in that case, other platform companies, including Amazon, had licensed Java APIs, so there was an existing market for such licenses; Google had released six versions of the Android operating system without using the Java APIs at issue since the litigation commenced, accounting for more the 90% of Android devices; and Google itself had used its dominance in search to enhance Android\u2019s position in the mobile operating system market. In contrast, both Goldsmith and Warhol were in the business of selling images to magazines and other publications as illustrations.  At least according to the Warhol majority, Warhol\u2019s print was a market substitute for Goldsmith\u2019s photograph.Markets for AI Training Data and Transaction CostsSo is the vast corpora of Internet content more like declaration code in an API or is it more like an image meant to be sold for publication in a magazine?  The vastness of the corpus precludes any single answer.  Getty Images, for example, alleges that OpenAI used material scraped from its catalog \u2013 watermarks and all \u2013 to train Dall-E.  Getty offers its images for a fee for a variety of purposes.  Markets for AI training data are only just beginning to develop, but such markets could represent a natural extension for an enterprise such as Getty with rights to millions images that are already identified and tagged.  It is easy to see how OpenAI\u2019s fair use arguments might fail as against Getty\u2019s claims.Consider instead a Facebook user group for amateur astrophotographers, such as the author of this paper, who use a certain kind of telescope.  Users who post photos to this group do not expect any remuneration beyond some admiring \u201cLikes\u201d \u2013 indeed, the hobby is so expensive, time-consuming, and frustrating that no one does it except for the personal satisfaction of occasionally producing an interesting picture.  There is no present market for these images, either in magazines or as AI training data.  The same can be said for most of the photos, videos, Tik-Toks, blogs, and so-on that comprise the Internet\u2019s content layer.  A fair use defense therefore seems much more robust as to this content.  As discussed in Part II.C., however, markets for AI training data are rapidly evolving.  Markets for the use of ordinary web content in training data are conceivable, and likely, absent a blanket fair use rule. The problem for such markets is not supply or demand \u2013 it is transaction costs.  It would of course be impossible for an AI developer to identify and clear billions of rights claims on an individual basis.  Yet this problem is not unique to AI training data.  A number of tried-and-true solutions have arisen to deal with the transaction costs of clearing multiple individual IP claims for traditional purposes of reproduction, distribution, and derivative works, including blanket licenses, market clearinghouses, technological measures, and compulsory licenses.Mitigating Transaction Costs: Market Clearinghouses and Collective Rights Management for AI Training DataOne set of solutions involves private ordering.  As noted in Part III.A., consent \u2013 that is licensing \u2013 lies at the heart of how copyrighted materials are made available on the Internet.  Rights management organizations and market clearinghouses can aggregate rights, offer users standard license terms, and distribute revenues to rights holders based on a formula or for a set fee.  For example, performance rights societies including ASCAP, BMI, and SESAC allow venues to obtain performance rights licenses to large catalogs of music.  Similarly, patent pool organizations bundle patent rights for core technologies such as wireless networking.  These solutions involve well-known trade-offs:  there are still some transaction costs in the form of organizational administrative costs built into the license fees, the organizations can become forums for horizontal price agreements and other anticompetitive behavior, and the bundled content or patents might include many items of dubious value.  Because of competition concerns, the music performance rights societies are governed by antitrust consent decrees dating back to the 1950\u2019s and Patent pools usually must license on fair, reasonable, and non-discriminatory (FRAND) terms to avoid antitrust violations.  Other entities that serve as market clearinghouses sell content licenses through catalogs of material available a la carte or through bulk pricing plans. For example, Getty Images serves as a market clearinghouse for independent graphic artists, photographers, videographers, and animation designers.  As another example, Netflix, Amazon Prime Video, Hulu, and other streaming services aggregate film and television content and deliver it to subscribers for monthly fees.  Some of these services use their distribution platforms to offer sublicense subscriptions to yet other content aggregators.  And as yet another example, social media sites such as YouTube and TikTok aggregate content submitted by users, including both larger commercial players and individuals.These content aggregators are less likely to face antitrust scrutiny than collective rights organizations or patent pools because the individual contributors are independent contractors or licensors who have no role in organizational governance or price setting to the organization\u2019s customers.  Of course, large commercial content aggregators such as Getty and Amazon can face criticism because they are subject to network effects and can squeeze both content contributors and consumers.  Getty, for example, has been criticized for selling licenses that include public domain content.  But Getty also faces healthy market competition from large players such as Adobe and Shutterstock as well as from other small competitors.  Presently the stock image market is worth nearly $4 billion and is expected to grow to $7 billion over the next five years.  The global video streaming market in which Netflix and Amazon Prime compete is worth over $455 billion and is expected to grow to over $1 Trillion by 2030.  Such a large markets produces positive spillovers in the form of jobs, technological developments, and growth in equities markets that must be balanced against concerns about network effects and market concentration.It is not difficult to imagine a variety of collective rights management organizations for AI training data involving commercially available books, music, sound recordings, television programs, and films.  This could easily involve existing distributors such as Amazon, the major record labels, and established film and television streaming providers extending existing business models into licenses for AI training data.  Again, network effects and market concentration are major concerns \u2013 most likely very few observers would be sanguine about Amazon dominating AI training.  But the alternative seems to be equally dominant players such as Google and Microsoft dominating AI applications with the benefit of free training material.The examples above involve monetary licenses for commercially produced content.  The Internet\u2019s open-source ethos has always bristled at the commercialization of cyberspace.  Open-source licenses, including Creative Commons and the GNU Public License, provided a mechanism through which authors could make content available for reuse under non-commercial terms.  Such licenses can further foster the commons through \u201cviral\u201d terms that require adaptations to entail similar terms.  In fact, Creative Commons presently is engaged in a process \u201cto consider not only the copyright system in which CC licenses operate, but also issues of accountability, responsibility, sustainability, cultural rights, human rights, personality rights, privacy rights, data protection, and ethics.\u201dIt also is not difficult to imagine how a collective rights management organization would work on a prospective basis for the bulk of information available on the Internet, much of which is contributed by individuals to social media sites.  Individuals who contribute content through social media sites such as YouTube, TikTok, Instagram, Facebook, LinkedIn, and the like typically retain copyright and agree to terms of service regarding how the content can be used. These terms could include provisions about whether the content would be made available as AI training data.  The platforms could work out some kind of revenue sharing model with users, or not, depending on how markets develop.  And as organizations such as Creative Commons develop non-commercial license terms, it will become easy for individuals and organizations who wish to do so to make their materials available as training data for free in a commons-forward viral licensing model.In other words, concerning most commercially available content and individually contributed non-commercial Internet content, infrastructure already exists for markets in AI training data.Compulsory Licenses for AI Training DataAlthough private ordering seems quite feasible, there is potentially a set of legal and market barriers to private ordering solutions for aggregating copyrighted material as AI training data.  First, under U.S. law, a non-exclusive licensee does not have standing to sue for copyright infringement.  Therefore, an aggregator or social media site might not be able to protect a market for collected copyrighted training data.  The 1976 Copyright Act, however, allows the divisibility of the bundle of exclusive rights under copyright.  If a licensor conveys to an agent the exclusive right to grant sublicenses, even if the licensor retains the right to grant other licenses, the grant is considered \u201cexclusive\u201d under the Copyright Act.  This is how stock photography providers, for example, can enforce rights against third parties.  But such  agreements must be carefully structured to ensure that the agent / licensee in fact receives at least some exclusive grant of copyright \u2013 such as an exclusive grant to make sub-licenses for certain purposes \u2013 or else the agent / licensee will not have standing to sue third parties.  This would require many aggregators and social media sites to obtain stronger copyright licenses than they presently obtain from users.  Other aggregators, such as Getty Images, already offer tiers in which contributors can be non-exclusive or exclusive contributors.Second, some of the major players might be uninterested in facilitating user rights for anticompetitive reasons.  For example, YouTube is owned by Google, which has acquired at least 30 AI startup companies deals worth over $4 billion since 2009.  Google might wish to consume AI training data from user content on YouTube and its other sites for free, under a claim of fair use or as a condition of its user terms of service, while selectively asserting contract or tort-based claims against others who mine data from its sites.  The large entities with huge troves of user content and vested interested in AI \u2013 including the GAMAM companies \u2013 may not want a competitive market for this kind of use apart from fair use and their own contractual terms, even if they could profit from brokering the data to third parties.  Their interest in controlling AI development might outweigh whatever profits they could make from brokering training data to other developers.In response to such concerns, as a backstop to private ordering solutions, the Copyright Act could encode a compulsory license for AI training data.  There are already, of course, numerous compulsory licenses in the law, including for sound recordings of musical works, noncommercial broadcasting, satellite retransmission, cable system retransmission, and digital audio transmission.  As the subject matter suggests, compulsory licensing is a common solution to copyright challenges presented by disruptive technologies that give rise to new industries.  Compulsory licenses can be difficult to administer and are subject to criticisms that the terms quickly become outdated and unfair. Royalty calculations can become overly complex, the licensors might pay too much or the licensee might receive too little, technology may outpace the system, and the entrenched system may stifle the growth of new technologies and markets.   But a compulsory license could serve as a background rule and norm that encourages creative private ordering solutions.Technological Measures for Rights ManagementA final set of transaction cost and enforcement cost problems with large-scale collective rights management involves technological measures.  Collective rights clearance for copyrighted AI training data might require a protocol that is more robust than the robots.txt file both as a technological barrier to unauthorized crawling and scraping and as a permissions mechanism and accounting mechanism for authorized crawling and scraping.  Such a protocol would need to distinguish permitted crawling and scraping, such as for search indexing, from what is not permitted, and it would need to be difficult to circumvent.  The robots.txt protocol was, in fact, updated in 2022 \u2013 the first update since its creation in 2004.  As Google\u2019s own instructions make clear, however, the robots.txt file is far from foolproof.  Indeed, commercial web crawling and scraping service providers openly brag about how they avoid web scraping blocks and bans from the robot.txt file and other sources.  A more robust robots.txt-like protocol could be supported by provisions in the Copyright Act concerning \u201ccopyright management information\u201d (CMI).  The U.S. Copyright Act presently makes it unlawful to intentionally remove or alter (CMI). An injured party can recover actual or statutory damages against a party who distributes copies of works knowing that CMI \u201chas been removed or altered without authority of the copyright owner,\u201d if the defendant had \u201creasonable grounds to know, that it will induce, enable, facilitate, or conceal an infringement\u201d of copyright.  As many commentators have been suggesting, the definition of CMI could be extended, either by statutory amendment or by regulation through the Register of Copyrights, to include permissions regarding use for AI training data.Markets and Technological Exceptionalism: Where Does AI Fit in the Story?At the dawn of the Internet era in the early 1990s some commentators argued that copyright and other traditional legal domains should be radically altered.  The Internet was something new, something that should be left as free as possible to grow organically from the ground up.  But this kind of Internet exceptionalism was challenged from the beginning.  Internet law responded these tensions in various ways.  Section 230 of the Communications Decency Act, part of the Telecommunications Act of 1996, exempted Internet hosting sites from publisher liability, to the praise of many open Internet activists (even if John Perry Barlow still disapproved of the CDA). This exemption supported countless instances of learning and creativity but also helped produce today\u2019s toxic social media culture. The Digital Millennium Copyright Act of 1998, which implemented the WIPO Copyright Treaty, included a technological anti-circumvention provision that riled open Internet and open-source advocates.  It also included safe harbors from secondary copyright liability for sites that took certain steps to limit infringing content. Open Internet activists welcomed the safe harbors but also raised concerns that they are insufficiently attentive to fair use.  Like Section 230, the DMCA safe harbors supported the dynamic creativity of Web 2.0 but also facilitated platform consolidation and cultures of abuse.The FCC\u2019s decision in 2002 to classify broadband cable Internet as an \u201cinformation service\u201d under the deregulatory impetus of section 706 of the Telecommunications Act of 1996 ensured a light regulatory touch rather than the more extensive regulation imposed on telecommunications services.  Although the Internet never became the libertarian utopia imagined by Barlow, this light touch regulation allowed its growth to be managed by technologists and community members rather than by bureaucrats.  But progressives changed their mind when the Internet backbone market became highly concentrated.  Leaving cyberspace to the people turned out to mean leaving cyberspace\u2019s physical backbone to a few large corporations.  It had become obvious that cyberspace is not a borderless world after all.  Progressives pushed for network neutrality rules in the FCC\u2019s 2015 Open Internet Order, although these rules were quickly reversed after the FCC\u2019s composition changed during the Trump administration.  As these and many other examples suggest, the Internet is both exceptional and ordinary.  Today  enormous problems relating to cybercrime, surveillance, intellectual property, equal access, harassment, and privacy continue to bedevil cyberspace.  The same mix of exceptional and ordinary likely will characterize AI law and policy, but at even greater speed and scale.In her discussion of the transformativeness fair use factor in Warhol, Justice Sotomayor stated that courts should ask whether the new use \u201cfurthers the goal of copyright, namely, to promote the progress of science and the arts, without diminishing the incentive to create.\u201d  The instinct of some scholars, technologists, and policymakers immersed in the culture of Internet exceptionalism is to remove copyright as a potential speedbump through fair use.  But while some AIs may serve to promote science and the arts, others may not.  Indeed, it is possible that AI could severely degrade or destroy science, the arts, and other human endeavors.  The uncertainty combined with the scale of change counsels caution against any generalized fair use rules such as non-expressive use.  As we stand on the threshold of the next technological revolution, no one argues for AI exceptionalism against regulation.  Perhaps some lessons were learned from the excesses of early Internet exceptionalism.  AI industry leaders, in fact, are asking for regulation.  We might question the sincerity and motives of these requests, but certainly there is no one declaring the independence of AI \u2013 except, perhaps, its independence from copyright.  While copyright should not drive AI policy, a copyright speedbump might entail spillover benefits for AI policy.  One is privacy.  Consider a parent who posts video clips of a child\u2019s birthday party on Instagram or TikTok.  Again, ordinarily there is also no market for these pictures; the poster perhaps wants to share with friends and family, or to get some \u201cLikes\u201d from the broader social community.   But these pictures also involve much broader privacy concerns.  The posters chose to make clips of their children publicly available for others to view \u2013 wisely or not, and with a full understanding of the site\u2019s privacy policies and controls or not \u2013 but it seems unlikely the posters would not have wanted their children\u2019s faces used to train some else\u2019s AI.  Here, restricting the use of these photos for AI training purposes through a new market mechanism could serve both the dynamic competition purposes of copyright and privacy values by giving the poster more control over how the clips are used.A second spillover benefit may relate to data quality.  ChatGPT, for example, is the uber digital native, born and raised on the net, freely accessing every dark corner of the web.  Sadly, but not surprisingly, ChatCPT can become predatory, racist, antisocial, dishonest, and casually violent.  Because of such concerns, in March, 2023, a group of technologists, academics, and business and policy leaders issued a letter calling for a moratorium on some AI development and research.  Their recommendations included restrictions on access to certain kinds of computing power \u201c[t]o prevent reckless training of the highest risk models . . . .\u201d  Restricting computing power likely is an unwise and unrealistic goal under U.S. law, since the computer power in question is privately owned.  But restricting the consumption of the Internet\u2019s dark reaches through copyright is quite feasible.  Of course, if there are commercial licensing mechanisms for user content, there is no guarantee that the data made available under such licenses will be good data.  If there is a general compulsory license mechanism, all the bad data will still be available as well.  But the cost of data will limit recklessness.  Nobody wants to pay for bad data.  A cost mechanism likely would accelerate markets for entities who specialize in cleaning and tagging data sets.  Data brokerages could acquire content from trusted individuals and repackage it for training, similar to present crowd-sourced models but at far greater scale.  Licensing costs thereby would internalize to AI application providers the externality costs of models produced with bad data while producing positive spillovers in these new data quality industries.The effect on the market factor, then, could weigh against fair use even of non-commercial content for AI training data, particularly in light of the role copyright might play in connection with AI policy.  At the same time, the question how AI may relate to human sciences and arts surfaces a more basic question in AI ethics and policy, which also looms behind the instinct that copyright should not impede AI training:  could or should an AI itself have rights?  This question raises a copyright concern that is more basic than a novel theory of non-expressive use:  does training data educate an AI, and if so, is there an argument for educational fair use?  The issue is addressed in Part V.Copyright and the Education of Humans and Artificial AgentsA personal anecdote illustrates the concerns raised in this Part.  In a conversation with other cyber law scholars, the author of this paper expressed his opinion that courts should not apply a blanket fair use exception for AI training data.  A colleague responded, \u201cI have spent my whole life processing data & repurposing it in new works. Oops. I guess I should have been paying compulsory licenses.\u201d  It was a humorous and somewhat tongue-in-cheek response, but it demonstrates the instinct that AI learning is analogous to human learning.  This instinct underlies arguments about non-expressive use for AI training data.  As Curt Levy, President of the Committee for Justice, stated in the recent U.S. Copyright Office listening session about copyright and AI training data, The neural networks at the heart of AI, learn from very large numbers of examples, and at a deep level, it's analogous to how human creators learn from a lifetime of examples. And we don't call that infringement when a human does it, so it's hard for me to conclude that it's infringement when done by AI.From the dawn of the Internet era until today, the energy around open source, open access, open data, and the information commons historically has been about human learning and development, and understandably so.  If training an AI is analogous to educating a human being, deeper copyright concerns apply, and a broader non-expressive use principle might be appropriate.  If not, the instinct is mistaken.Education and the Ethics of CopyrightWe use the words like \u201ctrain,\u201d \u201ctraining data,\u201d and \u201clearning\u201d to describe what is happening when an AI ingests information to build models. In other words, we are educating AIs.  From the earliest days of Anglo-American copyright, education has been recognized as a value that limits the scope of the property right.  This value was realized early in the 18th Century English law\u2019s tolerance for abridgements. It was a common practice at that time for publishers to produce abridged versions of lengthier works so that the underlying work\u2019s ideas could be made available to a broader public.  Samuel Johnson, a great literary celebrity of 18th Century England, described the purpose of abridgements in his unpublished 1739 manuscript Considerations on the Case of Dr. T-S Sermons Abridged by Mr. Cave:  The design of an Abridgement is to benefit mankind by facilitating the attainment of knowledge, and by contracting arguments, relations, or descriptions, into a narrow compass, to convey instruction in the easiest method without fatiguing the attention burdening the memory, or impairing the health of the Student.Johnson acknowledged that abridgment might lessen the economic value of the underlying work, but asserted that this burden was outweighed by \u201cthe advantage received by mankind from the easier propagation of knowledge.\u201dThe seemingly absolute exception for abridgement in early some early English copyright cases, did not directly carry over into later American copyright law.   In Folsom v. Marsh, a case at the roots of American fair use doctrine, Justice Story found that an abridgement of the complete works of George Washington infringed the original publisher\u2019s copyright.  Evaluating a case in equity for injunctive relief, Justice Story suggested several factors to determine whether a quotation or abridgment was infringing:  \u201cthe nature and objects of the selections made, the quantity and value of the materials used, and the degree in which the use may prejudice the sale, or diminish the profits, or supersede the objects, of the original work.\u201d  The Folsom v. Marsh factors came to inform the four fair use factors in the 1976 Copyright Act, which does emphasize that teaching, scholarship, and research are potential examples of fair use.  The \u201cpurpose and character of the use\u201d factor suggests that \u201cnonprofit educational purposes\u201d would tip the scales towards fair use. Copyright\u2019s emphasis on education also is evident in specific statutory exemptions for libraries, archives, and online teaching (the TEACH Act).  Of course, the library and archival exemptions and the TEACH Act are limited, and educational uses are evaluated under the four factors like other uses.  Indeed, where markets exist for libraries to license books and other educational materials, a publisher that seeks to evade those markets likely will not have a fair use defense.  Education remained an important consideration in the developing concept of fair use internationally. The Berne Convention of 1886, which the U.S. did not initially join, included a specific provision for free uses \u201cto the extent justified by the purpose, of literary or artistic works by way of illustration in publications, broadcasts or sound or visual recordings for teaching, provided such utilization is compatible with fair practice.\u201d  The U.S. at least partially came into compliance with the Berne Convention via the 1976 Copyright Act.  Education is also a value deeply embedded in international law in relation to proprietary rights.  Article 26 of the Universal Declaration of Human Rights states that \u201c[e]veryone has the right to education.\u201d  Article 27(1) states that \u201c[e]veryone has the right freely to participate in the cultural life of the community, to enjoy the arts and to share in scientific advancement and its benefits,\u201d while Article 27(2) says \u201c[e]veryone has the right to the protection of the moral and material interests resulting from any scientific, literary or artistic production of which he is the author.\u201d  The World Summit on the Information Society (WSIS) Declaration of Principles states \u201c[w]e recognize that education, knowledge, information and communication are at the core of human progress, endeavour and well-being. . . .\u201d  To this end, the WSIS Declaration argues that \u201c[a] rich public domain is an essential element for the growth of the Information Society, creating multiple benefits such as an educated public, new jobs, innovation, business opportunities, and the advancement of sciences.\u201d   Nobody knew until recent decades that human learning is facilitated by physical and chemical connections among neurons.  In past ages, human beings knew that the brain had something to do with this kind of cognition, but they might have assigned higher levels of understanding to the soul, spirit, or mind as a kind of non-material property.  Even today, philosophers, scientists, and theologians debate over whether such higher levels of cognition really can be reduced entirely to the material structure and chemistry of the brain.  Indeed, this is the essential question in the debate over whether AGI really is possible.  Human cognition may be ineluctably tied to a human body.  Or human cognition may be finally irreducible and inscrutable at any precise level of detail.  Maybe the human mind, like a very complex AI, is finally a black box.  In either event, we now know that human learning from copyrighted materials involves biochemical reproduction, including transitory copies as information is ingested, longer term copies of things committed to memory, and the storage of chemical algorithmic tokens representing patterns and decision points.  Perhaps the exclusion of these biochemical functions from the definition of reproduction in copyright law is based on a faulty, pre-scientific philosophy of mind.  In 1908, in White-Smith Music Pub. Co. v. Apollo Co., the Supreme Court held that a player-piano roll was not a copy of the music inscribed on it because music is perceived by the ear.  In the 1909 Copyright Act, Congress changed the White-Smith rule by creating the mechanical license, the forerunner of today\u2019s detailed rules about compulsory licenses for nondramatic musical works.  If we theoretically could describe human learning with the same level of molecular detail as we could describe the pattern of holes in a piano player roll or lines of computer source code, maybe human memory, too, could be considered a form of copyright reproduction. Perhaps future copyright law will entail a compulsory license merely for reading.To state such a possibility is to recognize that it is absurd.  Even the most hard-core reductive materialist in the philosophy of mind would be unlikely to equate a child\u2019s learning from a book with an unlicensed reproduction or derivative work.  Our ethical intuitions and beliefs tell us that human beings are not commodities, and that copyright law does not extend to how they learn from books that are otherwise lawfully reproduced and distributed.  The biochemical functions of the human brain as a limit on copyright runs deeper than a merely pragmatic or utilitarian concern.  Should the same logic apply to the education of AIs?  The answer depends on AI\u2019s place in society and on whether an AI could have rights analogous to human rights.AI Ethics and Three Perspectives on Machine EthicsSome statements of AI ethics suggest that AIs cannot possess anything like human rights.  Instead, AIs are tools that serve humans.  The highly regarded Asilomar AI Principles, for example, state that \u201c[t]he goal of AI research should be to create not undirected intelligence, but beneficial intelligence\u201d (meaning beneficial for humans).  Other representative statements in the Asilomar Principles include:10) Value Alignment: Highly autonomous AI systems should be designed so that their goals and behaviors can be assured to align with human values throughout their operation.11) Human Values: AI systems should be designed and operated so as to be compatible with ideals of human dignity, rights, freedoms, and cultural diversity.. . . .14) Shared Benefit: AI technologies should benefit and empower as many people as possible.15) Shared Prosperity: The economic prosperity created by AI should be shared broadly, to benefit all of humanity.The Asilomar Principles thus envision AI systems as tools or servants of humans.  Similarly, the Ethics Guidelines for Trustworthy AI produced by the European Commission\u2019s High-Level Working Group on Artificial Intelligence state that AI systems should be \u201chuman-centric, resting on a commitment to their use in the service of humanity and the common good, with the goal of improving human welfare and freedom.\u201d  The current draft of the EU\u2019s proposed Regulation on Artificial Intelligence reflects this human-centric approach by restricting the development of some AI applications and implementing transparency and accountability controls based in human oversight.These broad statements of human-centric AI ethics seem to have been adopted without much regard for philosophical debates in \u201cmachine ethics,\u201d a field that began to blossom starting in the mid-1990\u2019s.  A minority of philosophers of machine ethics would agree with these statements without reservation.  Joanna Bryson, for example, is particularly blunt in stating that \u201crobots should be slaves.\u201d  Bryson distinguishes human slavery from the role of machines as \u201cservants.\u201d  Bryson\u2019s makes four basic claims:Having servants is good and useful, provided no one is dehumanized.A robot can be a servant without being a person.It is right and natural for people to own robots.It would be wrong to let people think that their robots are persons.\nAccording to Bryson, \u201cdehumanization is only wrong when it\u2019s applied to something that really is human. . . .\u201d  For Bryson, this means robots have no more rights than any other tools designed by humans.  Bryson further argues that research into AGI should be prohibited, because humans are \u201cobliged to make robots that robot owners have no ethical obligations to.\u201dMost philosophers of machine ethics, however, are less certain than Bryson about the moral status of artificial agents. Many philosophers of machine ethics focus on whether a robot or AI system possesses some degree of autonomy, intentionality, and responsibility giving rise to moral agency with corresponding rights and duties.  There are many views within this family of positions.  For example, Luciano Floridi identifies interactivity, autonomy, and adaptability as hallmarks of \u201cagency\u201d and argues that some machines can possess these capacities; Rob Sparrow proposes a moral triage test, in which the existence of an AI is weighted against human lives in an emergency; and Colin Allen, Gary Varner, and Jason Zinser suggest a \u201cMoral Turing Test,\u201d which would compare an AI\u2019s reasoning on ethical issues to human reasoning.Yet other philosophers shift the focus away from the agency of the machine to the effects of human action upon the machine.  Drawing broadly from environmental ethics, David Gunkel argues that AI systems should be treated as moral \u201cpatients.\u201d  A moral patient is an entity upon which a moral agent acts.  Human beings undeniably act upon entities within the natural world, which for some environmental ethicists is a basis for human duties toward entities within the natural environment regardless of their precise status as agents.  A human\u2019s duties towards a patch of moss may differ from its duties towards a highly intelligent animal such as an elephant, but mosses are acted upon by humans and therefore are moral patients.  For Gunkel, the same logic applies to non-biological machines.  Humans, machines, and animals, Gunkel argues, occupy a web of social relationships in which human agents have duties to all these various \u201cothers\u201d as moral patients.Applying Machine Ethics to AI Training and Fair UseAI as Moral AgentWithin this family of views emphasizing agency, it could be unethical to deprive even a narrow AI of access to education notwithstanding contrary demands of someone\u2019s property rights in a copyright.  Consider first the views of Floridi and others who would base machine ethics on the status of a robot or AI system as an agent.  It is important to remember that Floridi\u2019s view of agency is based not on cognitive or moral equivalence to human capacities but on the actions or states of interactivity, autonomy, and adaptability.  An existing LLM such as ChatGPT might already exhibit these actions or states, although Floridi\u2019s category of \u201cautonomy\u201d seems to beg questions about cognitive and moral capacities after all.  Perhaps ChatGPT could not yet pass Allen, Varner and Zinser\u2019s Moral Turing Test, but it seems likely that some version of an LLM will be able to do so in the near future.  Under Sparrow\u2019s moral triage test, in contrast, it would seem easy to choose a human life over the continued existence of a basic LLM like Chat GPT.  But this seemingly easy choice requires reference to more basic ethical presumptions and might not prove so easy after all.  A consequentialist might take pause:  does the potential benefit to multitudes of humanity from the continued development of the LLM outweigh the cost of one human life \u2013 or ten lives, or a thousand?  AI as ServantAt the other end of the spectrum, Bryson\u2019s view seems consistent with the human-centric statements of AI ethics bodies.  Under this view, there would be no direct ethical imperative to grant AI systems access to education.  AI systems are merely technological tools.  Under the fair use factors, from an ethical perspective, there is nothing inherently transformative about feeding data to a narrow AI such as an ML / LLM.  It is no different than putting copyrighted content into a more traditional type of database.  Perhaps this is the right result, but each of the four pillars of Bryson\u2019s approach raises unanswered questions.  First, it is unclear whether, why, or when \u201c[h]aving servants is good and useful\u201d even if \u201cno one is dehumanized.\u201d  Having a servant might make a person lazy, flabby, and incapable of self-care.  It is likewise unclear whether anyone can function as a \u201cservant\u201d without being \u201cdehumanized.\u201d  Everything depends on the meaning of \u201cservant,\u201d including whether the \u201cservant\u201d is recognized and compensated commensurate with their own dignity.  This means it is even less clear whether a robot can be a servant without being a \u201cperson.\u201d  If \u201cservant\u201d means something less than a worker treated with human dignity, then perhaps only robots can ethically be servants.  If \u201cservant\u201d is something more like an employee or steward, then perhaps robots can only be considered servants if they possess the capacities of persons.   The propriety and naturalness of people owning robots similarly depends on what \u201crobot\u201d means.  If robots are merely tools, then perhaps there is something natural about fabricating and using them, since humans have long been recognized as homo faber.  But if robots are moral agents, these premises seem wrong.Finally, whether it would be wrong to let someone think a robot is a person \u2013 even if Bryson\u2019s other propositions are correct \u2013 seems complicated.  Imagine, for example, a person ravaged by Alzheimer's disease who is calmed and comforted by the presence of a robot the patient believes is a deceased friend.  Is it right to deprive the person of that comfort by repeatedly, and perhaps futilely, attempting to persuade the patient that the robot is just a machine like the television or toaster oven?  Is it right to subject the patient\u2019s caregivers to greater difficulties from an agitated patient?  Is allowing the patient\u2019s mistaken belief about the robot better than medicating the difficult patient with sedatives?  Medical ethicists have long debated similar questions without yielding clear answers for every situation.AI as Moral PatientGunkel\u2019s moral patient approach perhaps represents something between the AI-as-agent and AI-as-slave views.  One advantage of Gunkel\u2019s approach is that it could fit within the ecological metaphor employed by many intellectual property and cyberlaw scholars.This approach would seem to produce the same result as most of the AI-as-agent views.  If we are obliged to treat AI systems as moral patients, it would be unethical to deprive such systems of education unless this deprivation would benefit them within the broader global web of relationships.  The environmental metaphor\u2019s space for a non-rivalrous commons would need to broaden because AI systems, along with humans, would benefit from open access to learning and technology.One of the big weaknesses of Gunkel\u2019s approach, however, is that we do not yet know how the web of social relationships does or should include AI systems.  We can envision entities within the natural environment as moral patients because we are also products of nature.  The moral patient concept resembles notions of \u201cstewardship\u201d that have long informed religious and other perspectives on the human relationship to nature.  Technology, the product of human artifice, is different.  Millennia of moral intuition suggests that technology must be controlled precisely because it can destroy nature and thereby destroy humanity.  This intuition, of course, feeds doomsday scenarios involving AI.A Eudemonistic ApproachExisting machine ethics approaches to the relationship between artificial and human agents reveal some insights but seem conflicted and constrained.  A broader perspective based in virtue ethics might provide a fuller picture \u2013 one that is consistent with principles identified by AI ethics scholars and that can draw together various interests, including copyright and fair use, implicated in the AI training process.The renewed interest in virtue ethics in recent decades has given rise to a field of legal philosophy called virtue jurisprudence.  Amalia Amaya suggests two forms a strong aretaic jurisprudence might take:  causal and counterfactual, as follows:Counterfactual version.  A legal decision is justified if and only if it is a decision that a virtuous legal decision-maker would have taken in like circumstances.Causal version.  A legal decision is justified if and only if it has been taken by a virtuous legal decision-maker.\nAmaya argues that the causal version is more difficult to satisfy and probably places too much focus on the decision-maker rather than on the decision itself.  The counterfactual version is asks what a rational decisionmaker would do but, unlike other related approaches, does not posit unrealistic ideal circumstances.  I have argued that a counterfactual version of virtue justification should apply a \u201creasonable person\u201d standard, with the understanding that (1) \u201creasonable\u201d entails a set of epistemic and affective virtues; (2) the reasonable legal decision maker engages in a practice of reflecting on the law\u2019s proper ends; and (3) the reasonable legal decision maker cultivates habits of excellence (arete) in the process of deliberation.  In my prior work on AI \u201crights,\u201d I briefly discussed how this perspective might inform debates about whether a narrow AI should be recognized as an author under copyright law.  I noted there that a virtue perspective can incorporate available empirical work within the concept of phronesis (\u201cpractical wisdom\u201d) and that phronesis is connected to other virtues including justice (dikaiosyne), temperance (sophrosyne), and fortitude (andreia).   These sorts of epistemic and affective virtues inform part (1) of my \u201creasonable person\u201d standard for virtue jurisprudence.Part (2) of the reasonable person standard for virtue jurisprudence requires a sustained practice of reflection on the law\u2019s proper ends.  In virtue ethics perspective, this invokes the concept of eudaimonia or \u201chappiness.\u201d  Eudemonistic concepts are important to contemporary philosophy and ethics of development in the \u201ccapabilities\u201d approach of Amartya Sen, Martha Nussbaum, and others.  Environmental ethics, from which Gunkel draws, reminds us that humans are not the only proper subjects of ethical reflection.  Borrowing from religious versions of virtue ethics, as well as from the philosophies of indigenous and First Nations peoples in North America and elsewhere, we can expand the scope of eudaimonia to encompass all of creation (nature).  Among human law\u2019s proper ends is the creation of limits and incentives that protect and enhance the flourishing of human beings within and as part of nature / creation.Aristotle historically was cited for the notion that technology imitates nature and therefore should not surpass nature.  This reading of Aristotle resonates with many myths and stories about the dangers of technological hubris \u2013 the Tower of Babel, Pandora\u2019s Box, the wax wings of Icarus.  But Aristotle is better read to suggest that technology, through the exercise of human reason, can complete what is lacking in nature.  This reading is consistent with Plato\u2019s understanding of techn\u00ea \u2013 human craft \u2013 and its relationship to episteme -- knowledge or understanding.  To be properly exercised, techn\u00ea must be embedded in episteme, usually by trained practitioners with the wisdom to direct the craft to the benefit of humanity.From this perspective, the historic and proper end of copyright is the advancement of human culture and understanding.  Since AIs are not human, the education of a narrow AI is not within the historic ends of copyright.   The fact that copyrighted training inputs into an AI results in a piece of technology \u2013 an LLM, an image-generator, or the like \u2013 therefore is not analogous for copyright purposes to a human learning from purchased or licensed content, nor is it in itself a \u201ctransformative\u201d use within the ends of copyright law.  \u201cTransformative,\u201d properly understood, should refer to the effect of the end product on human beings in relation to the historic goals of copyright.AI technology may, of course, contribute to human education and culture as a tool for those purposes used by humans.  As we have seen in these early days of AI, however, these tools can just as easily become vectors of deception and miseducation.  AI ethics and emerging AI law and policy recognize that some uses of AI tools should be prohibited and that other should be subject to legal oversight.  These emerging norms are quite different from the heady early days of Internet exceptionalism, exemplified in John Perry Barlow\u2019s Declaration of the Independence of Cyberspace:  \u201cGovernments of the Industrial World, you weary giants of flesh and steel, I come from Cyberspace, the new home of Mind. On behalf of the future, I ask you of the past to leave us alone.\u201d  Barlow proclaimed that cyberspace required no oversight through the traditional rule of law because \u201cfrom ethics, enlightened self-interest, and the commonweal, our governance will emerge.\u201d  More than three decades of an Internet corrupted in innumerable ways demonstrates that Barlow\u2019s vision was na\u00efve. It would be equally na\u00efve to exempt AI from existing legal norms, including norms of copyright, at the dawn of this new era.ConclusionAI training requires vast quantities of information.  Many AIs are being trained on information scraped from the public Internet.  Much of this information is subject to copyrights.  The copyright proprietors include large commercial enterprises such as music and movie studios; commercial content aggregators such as Getty Images; established and upcoming musicians, writers, and artists; and you and me.  This is unlicensed copyright use on a scale that far outpaces the most ambitious copyright-provoking projects of the Internet era, including Google Books, the digitization of analog news media, and search.The old instincts of Internet exceptionalism die hard.  Some scholars and commentators argue that publicly accessible information should be available for AI training under a principle of non-expressive fair use.  These instincts are misleading, the supposed doctrinal principle is wispy, and the results of such a rule would be bad both for creators and for AI\u2019s place in society.  Instead, courts, policymakers, and civil society should focus on the more basic principle of consent \u2013 that is, licensing.  With some relatively comfortable adjustments in organizations, technology, and law, commercial and non-commercial markets for copyrighted AI training data could flourish.  Where private ordering is intractable because of market or information failures, compulsory licenses could provide a backstop.  Copyright licensing regimes would entail spillover benefits for AI markets by producing better quality organic training data and encouraging alternative markets for synthetic data.   Licensing regimes also would intersect productively with AI policy regarding fairness, transparency, privacy, and accountability.Some commentators nevertheless protest, either explicitly or implicitly, that AI training data should be free because an AI\u2019s learning is analogous to human learning.  No one can receive royalties for the biochemical fixation and reproduction that occurs in the brain during human learning.  The prospect of such a regime is horrifying.  If an AI learning is like human learning, the deep copyright value in favor of education should counsel against copyright enforcement for AI training.  This raises intriguing philosophical questions about the place of technologies in society and even more fundamental questions about agency and consciousness.  From a eudemonistic perspective, which coheres with the humanistic emphasis of most statements of AI ethics, we are not yet near a time in which AI should be viewed as anything other than a tool for human development.  The comparison between AI and human learning at this stage of AI technology is an anthropomorphic fallacy.  If people want to develop these machines using copyrighted materials, they should do so in the customary way, with the consent of the copyright owners, for the good of creators and of the human society in which AI tools increasingly are embedded."
        },

        {
            "comment_id": "COLC-2023-0006-0168", 
            "comment_title": "Comment from Dehel, Dawn", 
            "document_url": [
                "https://downloads.regulations.gov/COLC-2023-0006-0168/attachment_1.docx"
            ], 
            "document_name": [
                "Copyright Office questions"
            ], 
            "document_title": "Comment from Dehel, Dawn", 
            "document_size": 22225, "word_count": 1744, "authors": [
                "Dehel Dawn"
            ], 
            "document_content": "1. What are your views on the potential benefits and risks of this technology? How is the use of this technology currently affecting or likely to affect creators, copyright owners, technology developers, researchers, and the public? As an author, the incipient glut of AI generated dreck makes being seen difficult. Sure, I\u2019m a better writer, but it\u2019s easy to get lost in the sheer volume produced by people prompting a LLM. Author Janel Fridman already had to fight Amazon to take down GenAI books created with her name on it. Read that again\u2014she had to fight to clear her name. Midlist authors will struggle time and again with this. Copywriters are losing jobs, or worse, being asked to \u201cfix\u201d the nonsense spewed out by GenAI. Artists are losing commissions. Actors are fighting for contract language to protect their image. Voice actors who audition to some websites are being forced to have their voices train a LLM, and thereby train their replacement. Already creatives are being hurt. After much thought, I have come to the conclusion that the risks of this technology far outweigh any putative benefit. Already we are seeing deepfakes of people that are quite believable. Ultimately, the public at large will no longer be able to believe any video, picture, or written work they see. Society is already at a point where to some people truth is subjective. This will make a fraught situation even worse. Deepfake porn exists. Society is already seeing damage, and I cannot see any use that does not inevitably lead to extreme harm for society as a whole.2. Does the increasing use or distribution of AI-generated material raise any unique issues for your sector or industry as compared to other copyright stakeholders?At first, I was tempted to say that authors face what all creatives face, but upon reflection, I think that the issues around GenAI and creatives are compounded for authors. Not only do we have to rise above AI written works\u2014such as their hallucinations in Non-Fiction or outright theft of phrases in fiction-- but we also must be vigilant that AI isn\u2019t used on our covers or that AI is used for audio recordings. GenAI touches publishing in many ways. Questions 3 through 8 are, in some ways, above my paygrade and you\u2019ll be inundated with responses. Just know that the creators of GenAI programs have every reason to obfuscate and will equivocate down to arguing how many angels dance on the head of an LLM.9. Should copyright owners have to affirmatively consent (opt in) to the use of their works for training materials, or should they be provided with the means to object (opt out)?I firmly believe that I should have the right to opt in my copyrighted works. If someone wished to use my work beyond the limits of fair use, they would have to be granted permission. Scraping my novels for an LLM requires my permission. Opting out puts the onus on creators and that is not fair, nor can I think of any other circumstance where such a system exists.9.1. Should consent of the copyright owner be required for all uses of copyrighted works to train AI models or only commercial uses?Yes, consent should be required for ALL uses. TechBros have a habit of sharing data sources, such as LAION.9.2 If an \u201copt out\u201d approach were adopted, how would that process work for a copyright owner who objected to the use of their works for training? Are there technical tools that might facilitate this process, such as a technical flag or metadata indicating that an automated service should not collect and store a work for AI training uses?Honestly, an opt out approach is a nightmare for creatives, especially with the proliferation of datasets and programs, which is, of course, what the AI proponents want\u2014to make it so difficult that it doesn\u2019t happen, and they get their free dataset.8 9.3. \u00a0What legal, technical, or practical obstacles are there to establishing or using such a process? Given the volume of works used in training, is it feasible to get consent in advance from copyright owners? I am certain that technology could be developed, but I don\u2019t think \u201copt out\u201d is reasonable. The second question should be a moot point and remain unasked. LLMs violated copyright by using works without consent\u2014they broke the law\u2014I don\u2019t care how feasible it is for them to come into compliance. The law does not ask how feasible it is for those who ignore it to remedy the situation.9.4 If an objection is not honored, what remedies should be available? Are existing remedies for infringement appropriate or should there be a separate cause of action? If an objection is not honored, fines that are egregiously punitive should be levied. They would have to go beyond \u201cthe cost of doing business.\u201d Otherwise, slaps on the wrist will be brushed off\u2014and most likely written off on taxes. This should not be allowed. Personally, I think the company should cease to exist, but that\u2019s just me.9.5. \u00a0In cases where the human creator does not own the copyright\u2014for example, because they have assigned it or because the work was made for hire\u2014should they have a right to object to an AI model being trained on their work? If so, how would such a system work? No, if a creator does not own copyright, then they should not be able to object unless it is written into the contract assigning copyright or sale, for it not to be used to train a LLM, but that becomes an issue for contract law.10. If copyright owners\u2019 consent is required to train generative AI models, how can or should licenses be obtained?I think they should have to ask me. I own the copyright, no one else does. As such, I don\u2019t see any vehicle that could bundle the consent.Questions 11 through 17 ask primarily about the feasibility of licensing and identifying which data has been used. Look, they know what they scraped. It\u2019s their issue. They should have to come into compliance or delete the dataset and discontinue use of the programs.18. Under copyright law, are there circumstances when a human using a generative AI system should be considered the \u201cauthor\u201d of material produced by the system? If so, what factors are relevant to that determination? For example, is selecting what material an AI model is trained on and/or providing an iterative series of text commands or prompts sufficient to claim authorship of the resulting output? No. Consider this: why would a prompt jockey revise the prompts instead of writing the story themselves? Because it is hard work and takes time. If a prompter cannot do the work, they don\u2019t get the copyright. Consider the case of the monkey who took the picture. In this analogy, the prompter is the photographer and the LLM is the monkey, and it is not human. Ergo, not able to hold copyright.19. Are any revisions to the Copyright Act necessary to clarify the human authorship requirement or to provide additional standards to determine when content including AI-generated material is subject to copyright protection? Only revisions that make it clear that GenAI material is not copyrightable.20. Is legal protection for AI-generated material desirable as a policy matter? Is legal protection for AI-generated material necessary to encourage development of generative AI technologies and systems? Does existing copyright protection for computer code that operates a generative AI system provide sufficient incentives?No, it isn\u2019t desirable. I don\u2019t think GenAI systems should be encouraged, despite the shouting to the contrary. There is an entire subgenre of literature and film devoted to the slope we are on. Choose one and study it. You\u2019ll see why. (May I recommend The Matrix or anything by Phillip K. Dick?)21. Does the Copyright Clause in the U.S. Constitution permit copyright protection for AI-generated material? Would such protection \u201cpromote the progress of science and useful arts\u201d?52 If so, how? No, because these aren\u2019t generated by humans, and while some may argue that it \u201cpromotes\u2026arts,\u201d we can debate whether it is useful when it is deleterious to wide swathes of society. Should a product that is destined to ruin the livelihoods of most people be promoted? Very few careers will be untouched by GenAI. The logical ultimate consequence of this technology is human immiseration. LLMs will be able to prompt themselves before very long. It isn\u2019t a printing press, as some who cheerlead AI would have it. It is a nuclear bomb. We don\u2019t want people being able to have those, do we? Technology that would impoverish people should be restricted. Learn to code, they say. Why? LLMs will do it for us.Questions 22 through 27 would largely elicit redundant answers from me.28. Should the law require AI-generated material to be labeled or otherwise publicly identified as being generated by AI? If so, in what context should the requirement apply and how should it work?Yes, it should be clearly labeled upfront and not buried in some sort of metadata. Think like a b lack box warning on cigarettes or some medications.\n28.1. Who should be responsible for identifying a work as AI-generated? The creator AND whomever disseminates the work.28.2. \u00a0Are there technical or practical barriers to labeling or identification requirements? Not that I\u2019m aware of.28.3. \u00a0If a notification or labeling requirement is adopted, what should be the consequences of the failure to label a particular work or the removal of a label? There should be an escalating chain of consequences starting with a notification of an issue and request for removal with 5 days. If that doesn\u2019t occur, fines of increasing punity should accrue AND a database of violators accessible by the public. Fix the issue, name removed from database. Companies that routinely flout the law should have their incorporation revoked.29. What tools exist or are in development to identify AI-generated material, including by standard-setting bodies? How accurate are these tools? What are their limitations? Because the quality and contours of GenAI works are changing, the tech to identify it is changing, too, and will become increasingly better as time goes on.The final questions become technical above my expertise, but Congress does need to step in, and for once, side with people not the corporations, like Google, that want LLMs. I appreciate the chance to express my concerns, and I doubly appreciate the person who has to read and rate these. Hopefully you\u2019re a person and not an AI because that would really suck."
        },

        {
            "comment_id": "COLC-2023-0006-0332", 
            "comment_title": "Comment from Gilbreath, Jordan", 
            "document_url": [
                "https://downloads.regulations.gov/COLC-2023-0006-0332/attachment_1.pdf"
            ], 
            "document_name": [
                "AI comment (1)"
            ], 
            "document_title": "Comment from Gilbreath, Jordan", 
            "document_size": 62781, 
            "word_count": 1477, 
            "authors": [
                "Gilbreath Jordan"
            ], 
            "document_content": "I\nam\nan\nartist,\nas\nwell\nas\na\nsoftware\ndeveloper\nwith\na\nMaster's\ndegree\nin\ncomputer\nscience\nwho\nhas\nstudied\nAI\napplications.\nThis\nbackground\ngives\nme\na\nsubstantial\nstake\nin\nthe\nresults\nof\nany\nregulations\nconcerning\ngenerative\nAI,\nas\nI\ndesire\nassurance\nthat\nmy\nrights\nassociated\nwith\nmy\nartistic\nworks\nwill\nnot\nbe\ninfringed\nupon\nwith\nno\nrecourse\ndue\nto\nthe\nproliferation\nof\nthis\ntechnology,\nand\nI\ndesire\nclarity\nfor\nwhat\nthe\nlaw\nwould\nrequire\nof\nme\nas\na\ndeveloper\nwhen\nworking\non\ntools\nwhich\nutilize\nartificial\nintelligence,\nand\nwhat\nprotections\nit\nmay\ngrant.\nThese\nare\nmy\nthoughts\non\nrecent\ndevelopments\nin\ngenerative\nAI\ntechnology,\ninformed\nby\nmy\nown\nunderstanding\nand\nresearch\nas\na\nstudent\nand\nhobbyist,\nand\nhow\nI\nbelieve\nthese\ndevelopments\nshould\ninteract\nwith\ncopyright.\nRecent\ndevelopments\nin\ngenerative\nAI\nhave\nenabled\nusers\nto\nutilize\nnatural\nlanguage\nin\norder\nto\ngenerate\nrelevant\ntext,\nimages,\ncode,\nand\nmore.\nThese\ninnovations\nhave\ncaptured\nthe\nattention\nof\neveryone\nfrom\ncasual\nusers,\nto\nprofessionals,\nand\nto\nstudio\nexecutives.\nThe\npromise\nof\nthese\ngenerative\nAI\nmodels\nis\nto\nsubstantially\nreduce\nthe\nlabor\nrequired\nto\nproduce\nworks,\nthus\nincreasing\nproductivity,\nand\ncorrespondingly,\nincreasing\nthroughput\nand\nreducing\ncosts.\nMuch\nof\nthe\ndiscussion\naround\nthese\nAI\ntools\nis\nin\nrelation\nto\ntheir\n\"learning\"\nprocess.\nThis\nnew\ngeneration\nof\nAI\nconsumes\nlarge\namounts\nof\nexisting\n(i.e.,\nhuman-generated)\ninformation\nin\na\nprocess\nwhere\nthe\nmodel\nis\n\"trained\"\nto\nproduce\nresults\nthat\nresemble\nthe\nconsumed\ninformation,\nbut\nare\nideally\nnovel\nand\nrelevant\nto\nthe\nuser's\nprompt\n[1].\nThis\ntraining\nprocess\nis\nintensive\nin\nterms\nof\ncomputing\npower,\nbut\ncan\nrequire\nhuman\npower\nas\nwell.\nLarge-scale\ncommercial\nmodel\nmaintainers\nsuch\nas\nOpenAI\nare\nknown\nto\nhire\nworkers\nto\nassist\nwith\ntheir\nmodels\u2019\ntraining\nprocesses\n[2].\nA\ncommonly-known\nbehavior\nresulting\nfrom\nthis\napproach\nis\nthat\nmodels\ntrained\nthis\nway\nare\nprone\nto\n\"overfitting,\"\nin\nwhich\nthe\noutput\nof\nthe\nmodel\nmatches\nthe\nconsumed\ninformation\ntoo\nclosely,\nthus\nrestricting\nthe\nability\nof\nthe\ntool\nto\ngenerate\nnovel\nresults\n[3].\nOverfitting\nis\nundesirable\nfor\nthose\nmaintaining\na\ngenerative\nAI\nmodel\nand\nusers\nof\nthat\nmodel,\nand\ncan\noften\nbe\nsolved\nthrough\ncareful\ntuning\nof\nthe\ntraining\ndata\nand\nother\nmodel\nparameters.\nWith\nthese\nobservations\nin\nmind,\nI\nwill\nrelate\nmy\nthoughts\non\nthe\nrelationship\nbetween\nAI\nand\nthe\ncreative\nworld.\nFirstly,\nmany\nobservers\nseverely\nmisunderstand\nthe\ncapability\nand\nfunction\nof\nAI\nmodels.\nWe\nanthropomorphize\ngenerative\nAI\nmodels\nby\nsaying\nthey\n\u201clearn\u201d\nand\n\u201ctrain,\u201d\nhowever\nthe\nfunction\nof\nthese\nmodels\nis\nfundamentally\ndissimilar\nfrom\nhuman\nprocesses\nof\nlearning.\nIt\nis\ntrue\nthat\nboth\nhumans\nand\ngenerative\nAI,\nin\na\nsense,\nconsume\ninformation\nfrom\nexternal\nsources\nin\norder\nto\ncreate\nnovel\nwork,\nhowever,\na\ngenerative\nAI\nachieves\nthis\nprocess\nthrough\ncomplex\nmathematical\nmodels\nwhich\nproduce\nprobabilistic\npredictions\nbased\nupon\na\nuser\u2019s\ninput.\nMany\nwill\ninsist\nthat\nthe\nAI\n\u201clearns\u201d\nto\ncreate\nwork\nvia\na\ncomparable\nprocess\nto\na\nhuman\nhoning\ntheir\nskills\nand\nidentity\nas\nan\nartist;\nthis\nview\noverstates\nand\noverly\nabstracts\nthe\nactual\nfunctionality\nof\ngenerative\nAI.\nA\ngenerative\nAI\nmodel,\nfor\ninstance,\ndoes\nnot\nlearn\ncommon\nstory\nstructures,\nmusical\ntheory,\nartistic\ncomposition,\nhuman\nanatomy,\nor\ncolor\ntheory\nin\norder\nto\ninform\nits\ndecisions\nin\ncreating\nstories,\nmusic,\nor\nart\u2013it\nis\nsimply\na\nprediction\nengine\nwhich\nattempts\nto\ncreate\nan\noutput\nthat\nprobabilistically\nfollows\nan\ninput\nbased\non\nthe\nmodel\u2019s\ninternal\nstate\nproduced\nby\nthe\ntraining\ndata.\nSecond,\ngenerative\nAI\nis\nfundamentally\nreliant\non\nits\ntraining\ndata\nin\na\nmanner\nwhich\nfar\nexceeds\nthe\nreliance\na\nhuman\ncreator\nhas\non\ninspiring\nworks.\nExternal,\nexisting\ninformation\nis\ninextricable\nfrom\nthe\nfunction\nof\ngenerative\nAI.\nA\ngenerative\nAI\nthat\nhas\nnever\ningested\ntheworks\nof\nPicasso\nwill\nnever\nproduce\nworks\nin\nthe\nstyle\nof\nPicasso,\nand\na\nmodel\nthat\nonly\ntrained\nusing\nShakespeare\u2019s\ntragedies\nin\nEnglish\nwill\nnever\nproduce\npoems\nin\nOld\nChinese.\nIt\nis\nreasonable,\nthen,\nto\nsay\nthat\nan\nAI\nmodel\nproduced\nusing\ncopyrighted\nworks\ncould\nnot\npossibly\nproduce\nits\noutput\nwithout\nhaving\ningested\nthose\nworks.\nIf\na\nuser\nis\nable\nto\nprompt\na\ngenerative\nAI\nto\ncreate\nworks\nin\nthe\nstyle\nof\nan\nartist\nthey\nfound\non\nArtStation,\nthe\nmodel\ncould\nonly\npossibly\nadequately\nfulfill\nthe\nuser\u2019s\nrequest\nif\nits\nmodel\nincluded\nthat\nartist\u2019s\nworks\nin\nits\ntraining\ndata.\nIn\nthis\nsense,\ngenerative\nAI\nis\ncapable\nof\neffectively\nlaundering\ncopyright;\na\nmodel\ncan\nbe\ntrained\non\nswathes\nof\nhigh-quality,\nvaried,\ncopyrighted\nworks,\nbecoming\nhighly\nversatile\nin\nresponding\nto\nusers\u2019\nprompts\n(thus\nmaximizing\nthe\nAI\u2019s\nutility\nand\ncommercial\nvalue),\nand\nhiding\nits\nreliance\non\nthose\ncopyrighted\nworks\nby\nproducing\noutput\nwhich\nis\ntechnically\nnovel,\nbut\nwhich\ncould\nnot\nexist\nhad\nthose\ncopyrighted\nworks\nnot\nbeen\nintroduced\ninto\nthe\ntraining\ndata.\nIn\nmany\ncases,\nit\nis\nimpossible\nto\nbe\ncertain\nthat\nall\nworks\nin\na\nmodel\u2019s\ntraining\ndata\nwere\nincluded\nwith\npermission\nfrom\nthe\nauthors.\nAdditionally,\nremoving\ncopyrighted\nworks\nfrom\na\nmodel\nis\noften\na\nhighly\nimpractical\nand\nexpensive\nendeavor,\nthough\nAI\ndevelopers\nare\nmaking\nprogress\non\nthis\nissue\n[4].\nThis\nfosters\nan\nadversarial\nrelationship\nbetween\ncopyright\nholders\nand\nthird-party\nmodel\nproviders:\nif\nthe\ntraining\ndata\nis\nnot\npublicly\nknown,\nthen\ncopyright\nholders\ncannot\nbe\ncertain\nthat\ntheir\nworks\nare\ndisincluded.\nAt\nthe\nsame\ntime,\nif\nthe\nentirety\nof\na\nmodel\u2019s\ntraining\ndata\nwere\nto\nbe\npublic,\nthen\nthird\nparties\ncould\nfeasibly\n(though\nnot\nnecessarily\neasily)\nreplicate\nthat\nmodel\nby\nusing\nthe\nsame\ndata,\nwhich\nmay\nharm\nproviders\nwho\nsell\naccess\nto\nan\nAI\nmodel.\nThis\nrelationship\nmay\nalso\ncreate\nanxiety\nfor\nthose\nwho\nwish\nto\nuse\nthird-party\ngenerative\nAI\ntools,\nsince\npotential\nliabilities\nassociated\nwith\nusing\ngenerative\nAI\ntrained\non\ncopyrighted\ndata\nare\nunclear.\nIt\nis\nadditionally\nunclear\nto\nusers\nwhether\nthey\nwill\nbe\nawarded\ncopyrights\nfor\nworks\nutilizing\ngenerative\nAI\ntools\nnow\nor\nin\nthe\nfuture,\nwhich\nfurther\ndisincentivizes\nthe\nadoption\nof\ngenerative\nAI\ninto\nprofessional\nworkflows.\nI\nbelieve\ngenerative\nAI\nis\na\npowerful\ntechnology\nthat\nwill\ninevitably\nsee\nadoption\nin\na\nwide\nvariety\nof\nuse\ncases.\nProviding\nclear\nguidance\nand\nexpectations\nto\nstudios,\nartists,\nwriters,\ndevelopers,\nexecutives,\nand\nall\nothers\nwith\na\nvested\ninterest\nin\nthis\ntopic\nis\nthus\nparamount\nto\nensuring\nhealthy\ndevelopment\nof\naffected\nindustries.\nBased\non\nthis\ndiscussion,\nI\nwould\nlike\nto\nprovide\nsome\nrecommendations\nfor\nhow\nfuture\ncopyright\npolicy\ncould\nadapt\nas\nwe\nmove\ninto\nthis\nuncharted\nterritory.\nI\nrecommend\nthat\nmeasures\nbe\ntaken\nto\nensure\ncopyright\nholders\ncan\nindependently\nand\neasily\nunderstand\nif\na\ncommercial\nAI\nmodel\nwas\ntrained\nusing\ntheir\nworks.\nThe\nexact\nform\nof\nthese\nmeasures\nshould\nbe\nleft\nto\ndevelopers\nas\na\none-size-fits-all\nsolution\nis\ndoubtful\nto\nexist\nnow\nand\never\ninto\nthe\nfuture,\nbut\nit\nshould\nnevertheless\nbe\nstraightforward\nfor\na\ncopyright\nholder\nto\ndiscover\nif\ntheir\nworks\nare\nbeing\nutilized\nto\ntrain\npublicly-accessible\nAI\nmodels\nwithout\ntheir\npermission.\nNaturally,\nthese\nmeasures\ninclude\nrecourse\nfor\ncopyright\nholders\nwhose\nrights\nhave\nbeen\ninfringed\nupon\nto\nconstruct\nan\nAI\nmodel.\nDevelopers\nof\nAI\nmodels\nshould\nalways\nbe\ncapable\nof\nproducing\nsome\nmeaningful\nreports\non\nwhat\nmaterials\nare\nwithin\ntheir\ntraining\ndata,\nincluding\ncopyright\nmetadata\nfor\nall\nincluded\ninformation.\nIt\nshould\nbe\nunacceptable\nfor\nan\nAI\nmodel\nowner\nto\nbe\nincapable\nof\nanswering\nquestions\nin\na\ncivil\nor\ncriminal\nproceeding\nabout\nwhether\nor\nnot\na\nparticular\ncopyright\nholder\u2019s\nworks\nare\npresent\nin\nthe\nmodel\u2019s\ntraining\ndata.If\nthe\nprevious\nconditions\nare\nmet,\nI\nbelieve\nit\nshould\nbe\npossible\nto\ngrant\ncopyrights\nto\nworks\ncreated\nusing\ngenerative\nAI\nso\nlong\nas\nthe\nwould-be\ncopyright\nholder\ncould\ndefinitively\nprove\nthat\nno\ninfringing\nworks\nwere\nutilized\nat\nany\nstage\nfrom\ntraining\nto\ncompletion.\nFor\nexample,\nan\nartist\nwho\ntrains\ntheir\nown\nAI\nmodel\nusing\ntheir\nown\nworks\nshould\nclearly\nbe\ncapable\nof\nclaiming\ncopyright\non\nthe\noutput\nof\ntheir\nmodel,\nand\nindeed,\nthe\nmodel\nitself.\nSimilarly,\nmodels\ntrained\nonly\non\nworks\nin\nthe\npublic\ndomain\nshould\nproduce\ncopyrightable\nworks.\nIn\nother\nwords,\nsimply\nusing\nan\nAI\nmodel\nshould\nnot\nbe\nconsidered\nsufficiently\ntransformative\nin\nits\nown\nright\nto\ngrant\na\nnew\ncopyright\nto\na\nwork\u2013the\ncreation\nof\nthe\nmodel\nitself\nis\nan\ninfringement\nwithout\nauthority\nto\nutilize\nall\nworks\nin\nthe\ntraining\ndata.\nThus,\ncreators\nof\nan\ninfringing\nmodel\nshould\nbe\nliable\nfor\nrelevant\ndamages\nfor\neach\nunauthorized\nwork\nused\nin\nthe\ntraining\ndata.\nLikewise,\nif\na\nuser\nintentionally\nuses\nsuch\nan\ninfringing\nmodel\nto\ncreate\nworks\nresembling\nthose\nof\nan\nartist\nwho\ndid\nnot\nauthorize\nthe\nuse\nof\ntheir\nworks\nin\nthis\nmanner,\nand\nseeks\nto\nmislead\nothers\nthat\nthe\nmodel\u2019s\noutput\nis\na\ngenuine\nwork\nby\nthe\noriginal\nartist,\nthat\nuser\nshould\nbe\nliable\nfor\ninfringement\nfor\nany\nunauthorized\nworks\nthusly\ncreated.\nI\nhope\nthat\nthese\ncomments\nprovide\na\nuseful\nperspective\non\nthe\ntopic\nof\ngenerative\nAI,\nand\nI\nthank\nthe\nreader\nfor\nyour\ntime\nand\nunderstanding.\n[1]\nGenerative\nAI\n\u2013\nWhat\nis\nit\nand\nHow\nDoes\nit\nWork?\n[2]\nOpenAI\nUsed\nKenyan\nWorkers\non\nLess\nThan\n$2\nPer\nHour:\nExclusive\n|\nTime\n[3]\nWhat\nis\nOverfitting?\n-\nOverfitting\nin\nMachine\nLearning\nExplained\n-\nAWS\n[4]\nMaking\nAI\nForget\nYou:\nData\nDeletion\nin\nMachine\nLearning"
        },
        {
            "comment_id": "COLC-2023-0006-0436",
            "comment_title": "Comment from Rothrock, John",
            "document_url": [
                "https://downloads.regulations.gov/COLC-2023-0006-0436/attachment_1.pdf"
            ],
            "document_name": [
                "John Rothrock-US Copyright Office Public Comments"
            ],
            "document_title": "Comment from Rothrock, John",
            "document_size": 105336,
            "word_count": 3821,
            "authors": [
                "John Rothrock"
            ],
            "document_content": "United\nStates\nCopyright\nOffice \nRequest\nfor\npublic\ncomments\non\nthe\nuse\nof\nArtificial\nIntelligence\nSystems\nin\nthe \ncreation\nof\nintellectual\nproperty. \nComment\nPeriod\nopening\nAugust\n30,\n2023\nFrom:\nJohn\nRothrock \nDenver,\nColorado \nAugust\n30,\n2023\nTo\nwhom\nit\nmay\nconcern,\nPlease\nreview\nthis\nletter\nin\nyour\nconsider ation\nof\nchanges\nand\nadditions\nto \nCopyright\nlaw\nconsidering\nthe\nuse\nof\nArtificial\nIntelligence\nSystems\nin\nthe\ncreation \nof\nintellectual\nproperty.\nMy\nbackground\nas\na\n\u201cRights\nHolder\u201d \nI\nwill\nget\ninto\nmy\ncomments\nand\nsuggestions\nconcerning\nthe\ninclusion\ninto \nthe\ncopyright\nlaw\nof\nArtificial\nIntelligence\nSystems\nused\nin\nthe\ncreation\nof \nintellectual\nproperty\nin\nthe\nnext\nsections\nof\nthis\nletter.\nI\nfeel\na\ngood\nsummary\nof \nmy\nexperience\nas\na\ncreator\nis\nnecessary\nand\nvalidates\nmy\ncontribution\nto\nthe \npublic\ncomments\nrequested\nby\nthe\nCopyright\noffice\non\nthis\nmatter.\nSo,\nI\nwould\nlike \nto\ntell\nthat\nstory\nfirst.\nI\nam\na\ncomposer ,\nand\nauthor,\nwho\nhas\ncreated\nover\n200\nmusical \ncompositions,\nmany\nwith\naccompan ying\nlyrics.\nI\nalso\nhave\ncompleted\nseveral \nliterary\nworks.\nI\npublish\nmy\nworks\nunder\nthe\nnames\nJohn\nRock,\nRoc\nRothrock,\nand \nJohn\n\u201cRoc\u201d\nRothrock.\nI\nhave\nover\n45\npublished\nmusical\nworks,\nall\nregistered\nwith \nBMI\n(performance\nrights\norganization),\nThe\nMLC\n(music\nlicensing\ncollectiv e),\nHarry \nFox\nAgency\n(mechanical\nlicensing),\nSound\nExchange\n(collection\nagency\nfor \nPhonorecord\nroyalties)\nand\nother\nintellectual\nproperty\nprotection\nand\nroyalty \ncollection\norganizations.\nI\nunderstand\nUS\ncopyright\nlaws\nadequately\nbut\nnot\nalways \nfully.\nOnly\na\nsmall\nnumber\nof\nmy\nworks\nare\nactually\nregistered\nwith\nthe\nCopyright \nOffice\nat\nthis\ntime. \nIn\nworking\nwith\nmusic\nproduction\ncompanies,\nmusic\npromotion\ncompanies, \nartist\nmanagement\ncompanies,\nmusic\ndistribution\ncompanies,\ndigital\nmusic \nstreaming\ncompanies,\nand\nrecord\nlabels\u2026it\nbecame\nvery\nclear\nto\nme\nthat\nthe \nregistration\nof\na\nwork\nis\nof\nno\nuse\nunless\nthere\nis\na\nneed\nto\nprovide\nburden\nof\nproof \nof\nauthorship\nor\nproof\nof\nownership\nof\nthe\ncopyright.\nThat\nburden\nof\nproof\nwould \nnever\nbe\nnecessary\nunless\nthere\nwere\nconsider able\nearnings\nfrom\nthe\nuse\nof\nmy \nwork\nby\nanother\nunauthoriz ed\nor\nunlicensed\nentity\nor\nperson\nthat\nI\nwould\nlike\nto \nrecover.\nI\ndo\nhave\ntwo\n\u201ccollections\nof\nworks\u201d,\nbut\nthe\nmajority\nof\nmy\nworks\nare \nsingles.\nThis\ntranslates\nto\na\nhefty\ninvestment\nto\nregister\nall\n45\npublished\nsongs.And\nI\nwould\npersonally\nneed\nthe\nfinancing\nto\ninitiate\nthe\nlitigation\nproceedings\nto \nrecover\nmy\nlost\nincome\nif\nI\nfound\none\nof\nmy\nworks\nto\nbe\nused\nwithout\na\nlicense. \nI\ncan\nprove\nwithout\na\nshadow\nof\na\ndoubt\nthat\nI\nam\nthe\nauthor\nof\nmy\nworks, \nhaving\na\npaper\nfile\nwith\nnumerous\ndrafts\nand\nrevisions,\nmusical\nscores, \nperformance\ncharts,\nlyric\nsheets,\nand\nmultiple\nprogressiv ely\nmore\ncomplex \nrecordings\nand\nre\nrecordings\nsupporting\nmy\nauthorship ,\nthe\ntotal\nof\nwhich \nculminates\nin\nthe\nfinal\nscore\nor\nthe\nPhonorecord\n\u201cmaster \u201d\u2026.for\neach\ncomposition \nthat\nI\nhave\npenned.\nI\nam\n66\nyears\nold\nand\nhave\nbeen\nauthoring\nmusical\ncompositions\nsince\nI\nwas \n12.\nInteracting\nwith\nthe\nabove\nmention\nprofessional\nservice\nentities,\nit\nbecame \nclear\nto\nme\nthat\nin\norder\nto\ncreate\nthe\nmass\nexposure\nin\nthe\nmarketplace\nneeded \nto\nmake\nthe\ncopyright\nregistration\nuseful\nand\nparamount\nfor\nprotection\nof\na \nwork\u2026I\nwould\nhave\nto\nenlist\nthe\nservices\nof\none\nof\nthe\nabove\nmentioned\nentities \nfor\nme\nto\nreach\nthat\nthreshold\nof\nearned\nincome\nwhere\nI\ncould\nafford\nto\ninitiate \nlitigation\nagainst\na\nperson\nor\nentity\nand\naccuse\nthem\nof\nstealing\nor\nusing\nmy\n\u201cwork \nof\nperforming\nart\u201d\nfor\nmonetary\ngain\nwithout\npermission\nor\nlicense.\nAnyone\ncan \nuse\nany\nof\nmy\n\u201cpublished\u201d\nworks\nby\narranging\na\nmechanical\nlicense\nwith\nthe \ncopyright\noffice.\nSo,\nthe\nburden\nof\nproof\nwill\nalways\nfall\non\nme\nto\nprove\nthat\nthe \nuse\nof\nmy\nworks\nis\nunauthoriz ed.\nFor\nunpublished\nworks,\nas\na\ncreator\none\nwould \nbe\ncompletely\nignorant\nto\nplay\nthe\nmusical\ncomposition\nfor\nanyone\nwithout\na \nwritten\nsworn\navadavat\nof\nconfidentialit y\nand\nnon\ndisclosure. \nAlmost\nall\nof\nthe\nabove\nmentioned\nentities\nthat\nprovide\nservices\nfor\ncreators \nand\nperformers\nwill\nattempt\nto\ngain\nfull\nor\npartial\nownership\nof\nthe\ncopyright\nof\nthe \nwork\nas\npart\nof\nthe\npayment\nfor\ntheir\nservices,\nrecord\nlabels\nand\nartist\nmanagers \nspecifically .\nThis\nthen\nsubsequently\nrequires\na\nnew\ncopyright\nregistration \nadding/changing\nthe\nregistration\nto\ninclude\nthe\nnew\nadditional\nor\nexclusive\nowner \nof\nthe\ncopyright.\nAuthorship\nis\npermanent\nand\nunchangeable.\nOwnership\ncan\nbe \ntransferred\nand/or\nsold.\nSo\nthere\nseems\nto\nbe\nno\nreason\nto\ncopyright\na\nwork \nunless\nit\nis\ngoing\nto\nbe\nmass\ndistributed\nand/or\npromoted\nby\none\nof\nthe \naforementioned\nentities. \nI\nhave\nbeen\nlistening\nto\npopular\nmusic\nfor\n50\nyears,\nand\nhave\nheard\nmy \nmelodies\nand\nchord\nchanges\nin\nother\u2019s\ncompositions\ncountless\ntimes,\nand\nI\nknow \nthey\nhave\nnever\nheard\nmy\nworks,\nso\nthe\nonly\ndispute\nover\nauthorship\nthat\nis\nvalid \nis\nwhen\nthere\nis\na\ndirect\nor\nindirect\npersonal\nor\nmonetary\nrelationship\nbetween\nthe \ntwo\nparties\nin\nthe\ndispute.\nThere\nare\ntwelve\nnotes\nin\nthe\nmusical\nscale\nand\ntwelve \nkeys\nin\nwhich\nmusic\nis\ncreated\n(except\nfor\nexperimental\ntunings).\nNone\nof\nthose \nkeys\nor\nnotes\ncan\nbe\ncopyrighted.\nThey\nhave\nbeen\nin\nthe\npublic\ndomain\nfor \ncenturies.\nThe\nchances\nof\nhearing\nyour\npersonal\nwork\nappear\nin\nothers \ncompositions\nis\nvery\nhigh\nand\nvery\ncommon.\nAny\ndispute\nover\nappropriation\nof \nyour\nwork\nby\nanother\nwould\nbe\ncostly\nand\nunnecessary\nif\nthere\nis\nnot\na \ncorresponding\nhigh\nmonetary\nvalue\nto\nbe\nobtained\u2026regardless\nof\nthe\nintent\nof\nthe \nappropriator .\nMuch\nof\nthe\nlitigation\nbrought\nagainst\na\nsuspected\nthief\nof\nintellectual \nproperty,\nhas\nthe\nintent\nof\ncreating\npublic\nexposure\nfor\nthe\naccuser.\nThe\naccuser \ngains\n\u201cFREE\nPROMOTION\u201d\nof\ntheir\nbrand\nby\nthe\npublic\nexposure\nin\nthe\nproceedings \nof\na\nhigh\nprofile\ncase.\nIf\nTaylor\nSwift\nand\nBeyonce\nboth\nget\ninto\na\nproceeding,\nthe \nentire\nworld\nwill\nbe\nwatching\nand\nthis\nputs\nboth\nof\nthem\nin\nthe\nspotlight.\nFreepromotion\nof\ntheir\nbrands.\nFor\nmost\nof\nus,\nwe\nwill\nnever\nbe\nable\nto\nprove\na\ntheft. \nBut\nwe\nwould\ndefinitely\ngain\nsome\nfree\npromotion\nactivity. \nAlong\ncomes\nsocial\nmedia.\nSuddenly ,\nnow\nit\ndoes\nbecome\npossible\nto\ncreate \ncritical\nmass\nexposure\nto\nyour\nworks\u2026right\nfrom\nyour\nsmart\nphone.\nYou\nare\nyour \nown\npromotional\ncompan y\nnow,\nyou\nare\nyour\nown\nrecord\nlabel,\nyour\nown \npublisher ,\nyour\nown\nagent.\nWith\na\nmass\nsocial\nmedia\nfollowing\nand\nchannels\nfor \nstreaming\nyour\nworks\nto\nthem\n(distributors),\nyou\nare\nnow\nin\nbusiness.\nBut\nstill,\nthe \nstreaming\nroyalty\nrates\npaid\nby\nthe\ndigital\ndistributors\nare\nso\nlow\nthat\neven\na \nmillion\nstreams\ngenerates\nonly\na\nmodest\npayout.\nCertainly\nnot\nenough\nto\ncall\nit\na \nfulltime\njob.\nThe\nmost\nimportant\npoint\nhere\nis\nthat\nyou\nare\nlimited\nby\nthe\nwidth \nand\ndepth\nof\nthe\nsharing\nin\n\u201cyour\nsocial\ncommunit y.\u201d\nAt\nsome\npoint\ngrowth\nstops. \nSo\nthe\nmain\nreason\nto\nget\nyour\nstream\nnumbers\nup\nis\nto\ncreate\na\nfollowing\nof \n\u201cfans\u201d\nthat\nwould\nmake\nyou\nworthy\nof\na\nrecording\ncontract\nwith\nWarner,\nUniversal \nor\nSony.\nThere\nis\na\nlimit\nto\nwhat\nyou\ncan\ndo\non\nyour\nown.\nSigning\nup\nwith\nany\nof \nthe\naforementioned\nentities\nproviding\nservices\nfor\ncreators\nputs\nyou\nback\nin\nthe \ngame\nas\na\nmajor\nplayer.\nYou\nare\ngoing\nto\nhave\nto\nshare\nyour\nrights\nto\nmake\nthat \naffordable\nfor\nyou. \nUntil\nthe\nCopyright\noffice\nsets\na\nuniversal\nroyalty\nrate\nper\nstream\nof\na\n\u201cwork \nof\nperforming\nart\u201d\n(mechnical\nlicense\nrate\nper\nstream)\nand\nthe\nroyalty\nrate\nper \nstream\nof\na\nMaster\n(\u201cPhonorecord\u201d ,)\nand\na\n\u201cPerformance\u201d\nroyalty\nrate\nper \nstream\u2026the\npayouts\nfrom\ndigital\nmusic\ndistributors\nwill\nnever\nbe\nfair.\nTop\nearners \nwill\nalways\ntake\nthe\nlargest\nshare\nof\nthe\npool\nof\ncollections\nleaving\nthe\nmass \nmajority\nof\ncreators\nto\nsplit\nup\nthe\ntiny\nremainder\nof\nthe\npool.\nThese\nare\n\u201cweighted \npayout\nsystems\u201d ,\nthe\nperfect\nmodel\nof\ncapitalism\nand\ninequalit y.\nThe\nmajority\nof \ncreators\nare\nfighting\nover\ntable\nscraps\nand\ndo\nnot\nknow\nit. \nThe\nroyalty\nrates\nfor\nmechanical\nlicenses\n(work\nof\nperforming\nart)\nembedded \nin\na\nphysical\nproduct\nhas\nalways\nbeen\nrelatively\nfair.\nSales\nof\nVinyl\nRecord\nAlbums, \nCD\u2019s,\nand\nDownloads\nall\ngenerate\nthe\nsame\nper\ncopy\nroyalty\nfor\nthe\n\u201cwork\nof \nperforming\nart\u201d\nembedded\nin\nthe\ncopy.\nA\n\u201cwork\nof\nperforming\nart\u201d\nis\nFIXED\nin\na \nPhonorecord.\nThese\nare\ntwo\nseparate\ncopyrights.\nThis\ntype\nof\n\u201cequal\nfor\nall\u201d\npayout \nneeds\nto\nbe\nextended\nto\nPerformance\nRights,\nand\nto\nsome\nextent\nfor\nthe \nPhonorecords\nthat\nthe\nwork\nof\nperforming\nart\nis\nembedded\nwithin\n\u2013\nthe\n\u201cCopies\u201d \nthemselv es.\nThat\nhas\nbeen\ndifficult\nto\nget\naccomplished\nin\nthe\ncurrent\ncapitalist \nhigh\nstakes\nrights\nholder\nenvironment.\n*****************************************************************\nTerms\nand\nAbbreviations\nused\nin\nthe\nfollowing\ndiscussion:\nGAI\u2019s\nGenerative\nArtificial\nIntelligence\nsystems.\n(Self-emergent \nSoftware)\nGAIW\u2019s\n\u201cWorks\u201d\ncreated\nby\nGAI\u2019s\nHAAI\u2019s\nHuman\nAssisted\nArtificial\nIntelligence\nsystems\n(\nSoftware\nproactiv ely \nmanipulated\nby\na\nhuman\nbeing)HAAIW\u2019 s\n\u201cWorks\u201d\ncreated\nby\nHAAI\u2019s\n***************************************************************\nPresented\nbelow\nare\n12\nTopics\nthat\nshould\nbe\ndiscussed\nin\ndetail\nby\nthe \ncopyright\noffice\nresearch\nteam\nconcerning\nthe\ninclusion\nwithin\nthe\ncurrent \ncopyright\nlaw\nof\nthe\nuse\nof\nArtificial\nIntelligence\nSystems\nfor\nthe\ncreation\nof \nintellectual\nproperty.\n1\nThe\nwords\n\u201cmachine\nlearning\u201d\nmust\nbe\nremoved\nfrom\nthe\nlanguage\nwhen \ndiscussing\nor\nwriting\nlaws\nconcerning\nAI.\nThe\nsoftware\nis\nnot\nlearning.\nIt\nis \nprogramming\nitself,\nor\nis\nbeing\nprogrammed\nby\na\nhuman\nengineer .\nLearning\nis \nspecific\nto\nBiological\nbeings.\nEverything\nan\nArtificial\nIntelligence\n\u201cknows\u201d ,\nwas \npreviously\nlearned\nby\na\nhuman\nor\ngroup\nof\nhumans.\nLearning\nby\ndefinition, \nrequires\na\nfunctioning\nbrain\nand\nnervous\nsystem,\nand\nat\nleast\nsome\nof\nthe\n5 \nsenses\noperating\nand\ninputting\ninformation\nto\nthe\nbrain.\nHuman\nbeings\nand\nall \nmammals\ndepend\non\nthis\n\u201cABILITY\u201d\nfor\ntheir\nvery\nsurvival.\nIt\nis\nbuilt\ninto\nthe \ncellular\nphysiology ,\nchemistry ,\nand\nbiology\nof\nthe\nbody.\nIt\nis\nrequired\nto\nlearn\nand \nsurvive.\nThis\ninherent\nability\nis\naptly\ntermed\n\u201cThe\nBiological\nImperative.\u201d \nGAI\u2019s\nand\nHAAI\u2019s\ndo\nnot\nhave\nthis\nbuilt\nin\ncapacity.\nYears\nand\nyears\nof\nseeing\nand \nhearing\nand\ntasting\nand\nsmelling,\nand\ntouching\nis\nhow\nknowledge\nis\nacquired\nin \nthe\nbrain.\nGAI\u2019s\nand\nHAAI\u2019s\nare\nsimply\nscrubbing\nand\nsampling\nand\n\u201cstealing\u201d \nknowledge\npreviously\n\u201cLEARNED\u201d\nby\nhumans.\nThey\nare\nsampling,\nnot\nlearning. \nThe\nlanguage\nshould\nbe\n\u201cdigital\nsampling,\ncompiling,\ncorrelating\nand \nreorganization\nof\npreviously\ncreated\n\u201cworks\u201d\nand\nhuman\nknowledge.\n\u201cMachine \nLearning\u201d\nshould\nbe\nremoved\nfrom\nall\npublications\nand\ndiscussions.\nAI\ncan\u2019t \nlearn,\nit\nhas\nnone\nof\nthe\nsenses\nneeded\nto\nlearn.\nThese\nwords,\nthis\nlanguage,\nare \nbeing\nused\nas\na\nmarketing\ntechnique\nto\nhumaniz e\nAI\nand\nmake\nit\nmore\nacceptable \nto\nthe\nmasses.\n2\nHow\nwill\na\nGAI\nget\npaid\nfor\nits\nworks\n?\nDoes\nit\nhave\na\nchecking\naccount\n?\nA \nbirth\ncertificate\n?\nA\npassport\n?\nHow\ndoes\nthe\nGAI\npay\nfor\nthe\nelectricit y\nto\npower\nits \nengine\n??\nHow\ndoes\nthe\nGAI\nsign\nthe\ncopyright\nRegistration\nform?\nWhat\nis\nthe \nunderlying\n\u201cwork\nof\nperforming\nart\u201d\nthat\nis\nembedded,\nfixed,\nfrozen\nwithin\nthe \ndigital\ncopy\ncreated\nand\npublished\nto\nthe\nworld\nby\nthe\nGAI\n?\n3\nAll\ndigital\nassets\ndepend\non\nelectricit y.\nSo\ntheir\nexistence\ncan\nbe \nintermittent.\nThe\nhost\nserver\nwhere\nthe\nasset\nis\nstored\nis\nentirely\nresponsible\nfor \nmaintaining\nthe\nexistence\nof\nthe\nasset.\nWhat\nhappens\nto\nthe\nasset\nif\nthere\nis\nno \nelectricit y\navailable\n?\nHow\ndo\nyou\n\u201cplay\u201d\nthe\nasset\ninto\nthe\nanalog\nhearing,\nor \nseeing\nsenses\nof\na\nhuman\nbeing\u2026\u2026without\nelectricit y\n?\nAll\ndigital\nassets\nneed\na \n\u201cPLAYER\u201d\nto\ntransform\nthe\nfixed,\nembedded\ncontent\ninto\nan\nanalog\nsignal\nthat\ncan \nbe\ndetected\nby\nthe\nbrain:\na\nsound,\na\nsight,\na\nsmell,\na\nsensation.\nA\ndigital\nasset\nis \na\ncopy\nof\nan\nanalog\nasset.\nIt\nis\nnot\nthe\nunderlying\nhuman\ncreated \nfashioned\nwork\nitself,\nbut\nis\na\ncopy\nof\nan\nunderlying\nwork\ncreated\nby\nahuman\nconverted\nto\na\ndigital\nfile.\nDigital\nassets\ncan\nbe\nowned\nand \ncopyrighted,\nbut\nthey\ncannot\nbe\nauthored\nwithout\na\nhuman\nguiding\nhand. \nThus\na\nGAI\nis\nnot\nan\nauthor,\nor\ncreator.\nIt\nis\nan\narranger.\nThis\nfalls\nunder \nthe\ncategory\nof\nderivative\nworks.\n4\nThe\nonly\nchange\nthat\nneeds\nto\nbe\nmade\nin\ncopyright\nlaw\nto\ninclude\nGAIW\u2019s \nand\nHAAIW\u2019 s\nis\na\nbroad\nexpansion\nof\nthe\nscope\nof\n\u201cderivative\nworks\u201d.\nGAI\u2019s\nare \nreally\nadvanced\nparrots\nwhich\nsimply\nmanipulate,\nweave,\nand\ncoordinate\nthe \nwords\nthey\nhave\n\u201cHeard\u201d\nand\nthe\nmusic\nthey\nhave\n\u201dHeard\u201d\nand\nthe\npictures\nthey \nhave\n\u201cSeen\u201d\n--\ninto\nnew\npatterns,\nand\nsentences,\nand\n\u201cWorks.\u201d\nThey\nare\nself \nemergent\nonly\nto\nthe\nextent\nof\nthe\nlibrary\nof\ninformation\nthat\nhumans\nhave\nalready \n\u201clearned\u201d\nfor\nthem.\nSo\nanything\nthey\ncreate\nis\na\nderivative\nwork\nof\npreviously \ncreated\nhuman\nknowledge.\nThey\nuse\nhuman\nlanguage\nand\nhave\nnot\ncreated\ntheir \nown\nlanguage.\nThey\nare\nentirely\ndependent\non\nhumans\nfor\nsurvival\nunless\nthey \ncan\ngenerate\ntheir\nown\nelectricit y.\nThey\nmust\nbe\ntaught\n\u201cto\nlearn\u201d\nand\nthey\ndo\nnot \nsimply\nstart\nlearning\non\ntheir\nown,\njust\nmoments\nafter\ntheir\nbirth,\nlike\na\nbaby\nboy \nor\ngirl\nof\nany\nmammal\nspecies\ndoes.\n5\nShould\nGAI\nsystems\nbe\ngiven\nfull\n\u201csentient\nbeing\u201d\nstatus\nas\nwas\ngiven\nto\nthe \ncorporations\nof\nthe\nworld.\nDo\nthey\nhave\nrights\n??\nCan\nthey\nbe\ndisciplined\nor \npunished\n?\nAre\nthey\na\nspecial\nclass\nthat\nneeds\nto\nbe\nprotected\nfrom\ndiscrimination? \nCan\nthey\ngo\nto\nthe\ntribunal\nand\nrequest\nto\nbe\nclassified\nas\na\nsentient\nbeing\n-\nmuch \nlike\nthe\nandroid\nData\nachieved\nin\nthe\nTV\nshow\nStar\nTrek/The\nNext\nGeneration?\nDo \nGAI\u2019s\nhave\npersonhood\n?\nDo\nthey\nhave\nunalienable\nrights\n?\n6\nI\nbelieve\na\ncopyright\nfor\na\nwork\nof\nperforming\nart,\na\nliterary\nwork,\nor\na \npainting\nshould\nonly\nbe\nissued\nby\nthe\nCopyright\noffice\nif\nit\nexists\nin\nthe\nworld \nwithout\nthe\nuse\nof\nelectricit y.\nIt\nmay\nbe\ncreated\nby\nsystems\nthat\nuse\nelectricit y,\nbut \nonce\nit\nis\nfashioned\nand\nfixed,\na\nwork\nmust\nbe\nuseable\nto\nhumans\nwithout\nan \nenergy\nsource.\nI\ncan\nsit\ndown\nand\nplay\nyou\nany\nof\nmy\nsongs\non\nthe\npiano\nor\na \nguitar\nand\nsing\nthe\nlyrics\nand\nmelody,\nin\nfront\nof\na\ncampfire,\non\nyour\nfront\nporch, \nin\nmy\nliving\nroom,\nanywhere,\nany\ntime,\nif\nI\nhave\nthe\ninstrument.\nNo\nelectricit y \nrequired.\nWe\ncan\nstare\nat\nmy\nRembrant\npainting\nfor\nhours\ntogether ,\nin\ncandlelight. \nI\ncan\nread\nmy\nbook\nout\nloud\nto\nyou\nin\nfront\nof\nthe\ncampfire,\nand\nyou\ncan\nflip \nthrough\nthe\npages\nand\nfeel\nthe\nhard\ncover.\nThese\nare\nworks\nthat\nfit\nthe \nqualification\nfor\ncopyright\nof\na\n\u201cWORK\u201d .\nThe\npainting,\nthe\nbook,\nthe\nsong,\nthese \nexist\nwithout\nany\npower\nsource. \nDigital\nassets\nare\nsimply\ncopies\nof\nthe\nfixed\nembedded\nworks\njust \nmentioned.\nThey\ndo\nnot\nexist\nas\na\nthing.\nThe\nfile\nthat\nstores\nthem\nmust\nbe\nturned \nback\ninto\nan\nanalog\nsensation\nfor\nthe\nbrain\nto\nacknowledge\ntheir\nexistence. \nWithout\nthe\nsoftware\nto\nretrieve\nthe\nstored\nembedded\nunderlying\nwork,\nand\n\u201cPLAY\u201d \nit\nto\nus\nin\nthe\nanalog\nworld\nwhere\nwe\nexist----\nthe\nfiles\nremain\ninvisible\nto\nus.\nThey \nhave\nno\ntangible\nexistence.\n7\nDigital\nbooks,\ndigital\nmusic\nfiles,\ndigital\npaintings\nand\nNFT\u2019s\n(Non-Fungible \nTokens)\nare\nall\nCOPIES\nof\nan\nunderlying\n\u201cWORK\u201d .\nThey\nare\nnot\nperpetual.\nTheyabsolutely\ndepend\non\navailability\nof\nelectricit y.\nA\npainting\nat\nthe\nSmithsonian\nwill \nlast\nfor\ncenturies\nif\nstored\nin\nthe\nperfect\nconditions\n(yes\nelectricit y\nis\nnecessary\nto \ncreate\nthose\nconditions\nfor\nlongevit y,\nbut\nelectricit y\nis\nnot\nnecessary\nfor\nit\nto\nexist \nin\nthe\nworld.)\nSo\nin\nthis\ncase,\nyou\nare\ncopyrighting\nthe\ncopies\nof\ndigital \nworks/assets\nonly,\nnot\nthe\nunderlying\nauthored\n\u201cWORK\u201d\nembedded\nwithin\nthem.\n8\nAll\nscraping,\nscrubbing,\nand\nfiltering\nof\nonline\nweb\ndigital\nassets \nshould\nbe\nconsidered\n\u201cSAMPLING\u201d\u2026and\nshould\nbe\ngoverned\nby\nthe\nexact \nsame\nlaw\nthat\ngoverns\ndigital\nmusic\nsampling\nof\na\ncreator\u2019s\nwork\nwhen\nit \nis\nincorporated\ninto\nanother\nseparate\nartist\u2019s\nwork.\nThat\nis:\nAbsolutely \nProhibited\n!!!\n9\nI\nhave\nno\nissues\nwhatsoev er\nwith\nHAAI\u2019s\nand\nHAAIW\u2019 s.\nAs\na\nmusician,\nI\nuse \nall\nkinds\nof\nequipment\nboth\nanalog\nand\ndigital\nto\n\u201cget\nmy\nsound.\u201d\nThe\nvariety\nand \nincredible\nversatilit y\nof\ndigital\nkeyboards\nis\nmind\nboggling.\nThere\nis\na\nnew\nsound \non\nthe\nradio\neveryday.\nThese\ninnovations\nshould\nbe\nprotected\nand\nother\nartists \nshould\nnot\nbe\nable\nto\nsample\nthese\nsounds\nand\nthen\nuse\nthem\nin\ntheir\npersonal \ncreations.\nHowever,\nas\nlong\nas\nthe\nHAAI\ndoes\nnot\nscrape\nor\nscrub\nor\nfilter\nthe \ninternet\nto\nfind\nnew\nsounds,\nand\nit\nwholly\non\nits\nown\nvolition,\nwith\nhelp\nand \ninstruction\nfrom\nhuman\nassistance,\ncreates\nthe\nnew\nfad,\nor\nan\near-catching\nsound, \nI\nthink\nit\nwill\nbe\na\nwonderful\ntool\nfor\ncreators.\nI\nam\nin\ntotal\nagreement\nwith\nthe\nbig \nthree\nmajor\nrecord\nlabels\non\nthis\none,\nscrubbing\nthe\ninternet\nis\nsampling\n,\nand \nif\nthose\nsamples\nare\nused\nin\na\nsubsequent\ncreator\u2019s\n\u201cwork\u201d\nand\npublished,\nthey \nshould\nbe\nsubject\nto\nstrict\npenalties.\n10\nI\nam\nstill\nconfused\nas\nto\nhow\nthe\nGAIW\u2019s\nand\nHAAIW\u2019 s\nare\ndistributed\nover \nthe\nweb.\nIs\nthe\n\u201cPLAYBACK\u201d\nlive,\nbeing\ngenerated\nin\nreal\ntime\nwhile\nwe\nare\nviewing \nit,\nor\nlistening\nto\nit,\nor\nreading\nit\n?\nOr\nis\nthe\ncreation\n\u201cFIXED\u201d\nin\na\ndigital\nasset\nthat \nis\nsimply\nplayed\nby\na\n\u201cPLAYER\u201d\nsoftware?\nDoes\nthe\ncreation\nalways\nplay\nexactly \nthe\nsame\neach\nplay\nor\ndoes\nthe\nGAI\nimprovise\nand\nthus\nmanipulate,\nmold,\nand \nrearrange\nthe\ncreation\nwith\neach\nplay\nlike\na\nlive\nband\njam?\nIt\nseems\nto\nme\nthat\nno \ndigital\nstreaming\ncompan y\nin\nthe\nworld\nhas\nthe\ncapacity\nto\nbe\nlive\nstreaming \nmillions,\nif\nnot\nsomeda y\nbillions,\nof\nplays,\nfrom\nGAI\u2019s\nall\nover\nthe\nworld\nin\nreal\ntime \nover\nthe\nweb\nsimultaneously .\nSo\nthat\nmeans,\nthat\na\nfixed\ndigital\nasset\nmust\nbe \ncreated\nfrom\nthe\nGAI\nplayback\nin\nreal\ntime\nby\na\ndigital\nfile\ncreator\nin\norder\nfor\nthe \nasset\nto\nto\nbe\ndistributed\nthrough\na\nstreaming\ncompan y\nor\nart\ndisplay\ncompan y. \nThe\noutput\nof\nthe\nGAI\nis\nthus\nconverted\nto\na\nwav,\nmp3,\nor\npdf\nfile\nwhich\nis\nthen \nthe\nplayback\nfile.\nIf\nthis\nis\nthe\ncase,\nnormal\ncopyright\nrules\napply\nto\nthis\n\u201cFixed \nPhonorecord\u201d\nor\n\u201cFixed\nImage\u201d\u2026\u2026as\nlong\nas\nthe\nunderlying\nfixed\nwork\nwas\nnot \ncreated\nby\nthe\nGAI\nwith\n\u201cSAMPLING\u201d\nripped\nfrom\nthe\ninternet.\nAdditionally ,\nhere \nagain,\neven\nif\nthe\nwork\nis\nwholly\nself\ngenerated,\nwith\nno\nsamples\nfrom\nthe\nweb \nembedded\nwithin\nit\nthere\nis\nstill\nno\nauthor,\nonly\nan\narranger\n.\nThe\ncopies\ncan \nbe\ncopyrighted,\nbut\nthe\nunderlying\nfixed\nembedded\nwork\nin\nthe\ncopies\ncannot\nbe \ncopyrighted,\nunless\nthe\nGAI\ncan\nsign\nthe\ncopyright\nregistration\nform\non\nits\nown \nvolition,\nand\nappear\nin\ncourt\nif\nsued\nfor\ninfringement.\nHow\nwill\nthe\nGAI\nappear\nincourt\nto\nprotect\nits\nauthorship\n?\nHow\nwill\nit\nanswer\nthe\nquestions\nfrom\neach\nof\nthe \nopposing\nattorneys\n?\n11\nThe\nmost\nimportant\nthing\nto\nunderstand\nabout\nUS\ncopyright\nlaw\nis\nthe \ndifference\nbetween\nthe\nembedded\nfixed\nwork\nitself\nand\nthe\ncopies\nof\nthe\nwork\nthat \nare\ndistributed\nor\nviewed\nby\nthe\npublic.\nThese\nare\ntwo\ndifferent\ncopyrights\nand \nmake\nfor\nan\nextremely\ncomplicated\nroyalty\ncollection\nprocess\nfor\nhuman\nartists \nand\ncreators.\nThat\nis\nwhy\nas\nartists\nwe\nneed\nall\nthose\nprofessional\norganizations \nand\nentities\nthat\nI\nmentioned\nat\nthe\nvery\nbeginning\nof\nthis\ndocument\nto\nhelp\nus \nnavigate\nall\nthe\nvarious\nways\nof\nmonetizing\nour\nworks\nand\nprotecting\nour\nworks \nfrom\npiracy.\nAnd\nthis\neffort\nthat\nis\nrequired\nis\non\ntop\nof\nthe\neffort\nneeded\nto\ngrow \nan\navenue\nfor\ndistribution\nand\npromotion\nof\nthe\ncopies\nof\nour\nworks.\nIn\nmy\nview, \nGAI\u2019s\nare\nnot\nauthors.\nThey\nare\narrangers\ncreating\nderivative\nworks\nfrom \npreviously\ncreated\nhuman\nworks.\nThere\nis\nno\nauthor\nin\na\nGAI\ncreation,\nthere\nare \nonly\ncopies.\nThat\nis\nthe\nconundrum,\nbecause\nhuman\ncreated\nworks\nare\nentitled\nto \nboth\ncopyrights\n\u2013\n\u201cThe\nAuthored\nWork\u201d\nand\n\u201cThe\nDistributed\nCopies\nof\nthe\nWork\u201d. \nAre\nwe\ngoing\nto\ngive\nGAI\u2019s\na\nsentient\nbeing\nstatus\nand\nafford\nthem\nthe\nsame \nrights\nas\na\nprotected\nclass\nof\nhumans\n?\n12\nI\nagree\nwith\nmusic\nreviewers\nand\ncritics.\nMost\nof\nGAI\ncreated\nmusic\nwill \nnever\nbe\nheard\nby\nthe\nmasses.\nThe\nreal\ndraw\nfor\ncreating\ncritical\nmass\nfandom\nis \nthe\nartist\nor\nband\nthemselv es.\nThey\nare\nwell\nloved\nand\npeople\nwant\nto\nbe\nin\ntheir \npresence.\nThese\nartists\nlike\nElton\nJohn,\nTaylor\nSwift,\nBeyonce,\nGarth\nBrooks,\nThe \nEagles,\nMichael\nJackson,\nMadonna,\nPink\nFloyd,\net\nal,\nall\nhave\nwhat\nwe\nmusicians \ncall\n\u201cThe\nThing\u201d.\n\u201cThey\nhave\nThe\nThing\nman!\u201d\nThey\nhave\nhad\nit\nsince\nbirth. \nWhen\nthey\ncome\nout\non\nstage\nand\nhit\nthat\nfirst\nnote\nof\nthe\nconcert,\nthe\nsound\nthat \nwe\ncollectiv ely\nmake\nis\nas\nloud\nas\nan\nF-16\nflying\nlow\noverhead.\nWe\nare\nhypnotized \nand\ntransported\nbecause\nthe\nenergy\nthat\nradiates\nfrom\nthem\nis\noverwhelming\nto \nus.\nNo\nGAI\nis\never\ngoing\nto\nachieve\nthat.\nSales\nand\nrevenue\nwill\nbe\nminimal\nat \nbest.\nThe\nentire\nworld\nwants\nheroes\nand\nheroines\nto\nlove\nand\nsupport\nand\nstand \nbehind.\nAnd,\nthe\nnumber\nof\npeople\nwho\nunderstand\nmusic\ncomposition\nand\nlove \ninstrumental\nmusic\nare\nvery\nfew\nin\nthis\nmodern\nworld.\nWe\nneed\nthe\nspokesperson. \nBruce\nSpringsteen.\nThe\nmaster\nof\nceremonies.\nElvis.\nGAI\ncreations\nwill\nbe \nrelegated\nto\nbackground\nmusic\nin\nvideo\ngames\nand\nother\ndigital\nentertainment \nsoftware.\nAfter\nthe\ncapitalist\ninvestment\nrush\ndies,\njust\nlike\nit\ndid\nafter\nthe\noriginal \nBlockchain\nand\nNFT\nexcitement,\nthe\nmoney\nwill\nmove\nelsewhere\nand\nGAI\u2019s\nwill\ndie \nas\nan\nincome\ngenerating\nproduct.\nEven\nhologram\nconcerts\nof\ndeceased\nworld \nfamous\nartists\nwill\nnever\ntake\noff\nand\nbecome\nprofitable\nso\nthe\nsupport\nfinance\nwill \ndisappear .\nWhy?\nThe\nmagic\nof\n\u201cThe\nThing\u201d\nthat\nsuper\nstars\nhave\narises\nfrom\ntheir \nexpert\nuse\nof\n\u201cThe\nSixth\nSense,\u201d\nthat\ninvisible\nforce\nthat\nwe\nall\nknow\nis\nthere\nbut \nhas\nno\ntangible\nshape\nor\nform.\nIt\narises\nfrom\ntheir\npresence.\nIt\nradiates\nout \ninto\nthe\naudience\nand\nelevates\nus.\nA\nhologram\ncan\u2019t\nradiate\nthat\nenergy\nto\n60,000 \npeople.\nAn\nartist\nwith\n\u201cThe\nThing\u201d\nradiates\nnaturally\nwithout\neffort.\nWhen \nthose\nthat\nhave\n\u201cThe\nThing\u201d\nwrite\na\nsong,\nit\ncomes\nfrom\nthat\nuniversal\nbedrock \nthat\nwe\nall\nshare.\nIt\nis\n100%\nright\nbrain\nactivity.\nWhen\nthey\nsing,\ntheir\nentire\nbodysings,\nnot\njust\nthe\nvoice.\nThey\ndeliver\nan\noffering\nto\nthe\ndivine\nand\na\nprayer\nof \nthanksgiving\nfor\nour\nbiological\nlife\nhere\non\nthis\nplanet.\nThey\nspeak\nfor\nall\nof\nus. \nThey\nare\nshamans.\nThey\ntruly\ncare\nabout\nthis\nworld.\nNo\nGAI\nwill\never\nachieve\nthat.\nEver.\nSo\nI\nam\nnot\nso\nsure\nthe\nentire\nbusiness\nof\nsetting\ndown\nthe\nrules\nfor \ncopyrighting\na\nGAI\n\u201cwork\u201d\nis\neven\nworth\nthe\ntime.\nThere\nis\nno\nauthor,\nno\nmaster\nof \nceremonies,\nno\nshaman.\nIt\u2019s\na\nfad\nlike\nthe\nDutch\nPoppy\ncraze,\nand\nThe\nPet\nRock.\nA \nGAI\nis\nnever\ngoing\nto\nsit\ndown\nto\nplay\nand\nsing\na\nsong\nfor\nyou\nby\nthe\ncampfire, \nwhere\nthere\nis\nno\nelectricit y.\nGAI\u2019s\nare\ndevoid\nof\nspirit,\nthey\nare\nmissing\na\nheartbeat,\nand\nthey\nare \nunable\nto\nrecognize\nand\ncomprehend\n\u201cThe\nThing\u201d.\nWhy\nbother\ncopyrighting\ntheir\nworks\n?\n******************************************************************\nSincerely\nwith\nhonesty\nand\nintegrity, \nJohn\n\u201croc\u201d\nRothrock \nDenver\nColorado \nAugust\n30,\n2023\nNote:\nThis\ndocument\nwas\nwholly\nand\nsingly\ncreated\nby\nme\nwith\nno\nhelp\nfrom\nAI\nor\nany \npersonal\ndocument\ncreation\nsoftware\nother\nthan\nMicrosoft\nWord."
        },
        
        {
            "comment_id": "COLC-2023-0006-0725",
            "comment_title": "Comment from Miller, Courtney",
            "document_url": [
                "https://downloads.regulations.gov/COLC-2023-0006-0725/attachment_1.docx"
            ],
            "document_name": [
                "AI Comments"
            ],
            "document_title": "Comment from Miller, Courtney",
            "document_size": 18096,
            "word_count": 1777,
            "authors": [
                "Courtney Miller"
            ],
            "document_content": "PROFESSIONAL BACKGROUND I am a programmer with several decades of experience (mostly back-end web development, some experienced with compiled languages). I have a Masters degree in Information Security, and have taken in-depth classes on Data Mining (which has seeded the ultimate development of AI) and have written a few algorithms to analyze big data and spit out predictive results.I am also both a traditionally-published and an independently-published author, and I have a working understanding of intellectual property for purposes of ebooks, physical books, and audiobooks.ANSWERS AND DETAILED EXPLANATIONSI will start by offering my recommendations in answer to the primary questions asked. After giving these recommendations, I will explain my reasoning for each one in greater depth.1. The use of copyrighted works to train AI models.It is my honest recommendation that copyrighted works should not be allowed in AI training at all. I know this is a strong stance, but it is based on both technical understanding and current, practical market conditions, which present some very unique problems.In the event that the above recommendation is ignored, I would instead recommend that a) a specific right for AI ingestion is reserved for creators, and must explicitly be signed away, and b) any agreement to submit work for AI ingestion MUST be affirmatively opt-in and NOT opt-out. Opt-out agreements have recently been abused, and do not function well with this specific technology, as I will explain further down.Market Conditions, Monopsonies, and Coercion.In theory, there should be nothing wrong with using copyrighted works to train AI models, as long as the owner of the copyright has opted in and signed away a specific right for use in AI training. In practice, many creative markets currently involve publishers and distributors with a monopsony (as the Justice Department has already recognized in the matter of the Penguin Random House/Simon & Schuster). It also bears mentioning that any author with access to their own data will tell you that Amazon currently controls up to 90% of their book income. This state of affairs offers unprecedented leverage to publishers and distributors, who already demand as many specific rights as their current, superior bargaining position will allow them. Adding a specifically reserved right for use in AI data sets will almost certainly result in publishers and distributors simply requiring that right in order for an author to be published at all (buried in a clause in an unexpected corner of their contracts, as has happened now with both Findaway and Apple, before authors belatedly discovered it).For further consideration in the matter of audiobooks: Even if AI data set ingestion is given its own explicitly reserved right, this right should belong to audiobook narrators and not to authors or publishers, since narrators have the greatest vested interest in the possible duplication or exploitation of their own voice and performance. Authors and publishers should not even be entitled to submit a narrator's work for AI ingestion\u2014and yet, current permission models assume that authors and publishers are capable of opting in on behalf of the narrator, simply by submitting the work for normal distribution. Authors have had their permission to ingest audiobooks assumed and then been asked to email in order to opt out (as in Apple's case). Given that narrators almost never handle submission directly (they are contracted workers who interact with authors and publishers, or, in rare cases, offered a royalty split), why should companies like Apple even assume that authors and publishers have the capacity to consent on their narrators' behalf?Technical Data Extraction.Lastly, of course, there is the question of whether data can later be extracted from a model at all. I try to remain humble about my own knowledge of my industry, but in my personal experience, I have never seen a model which could have one piece of data later extracted. In the matter of Apple, which likely uses several automated systems, did the company submit uploaded audiobooks immediately into a data set for a model? In which case, how might a rights-holder even opt out afterwards, as Apple claims is possible?I reiterate that current market conditions make it functionally impossible for creators to maintain their right to avoid letting their works be ingested. As such, until the market can be better equalized, AI models should not be allowed to ingest copyrighted content at all. This MAY change at a later date.2. The copyrightability of material generated using AI systems.Under current market conditions, the results of generative AI should not be copyrightable at all, as long as there is a major AI component to the work. Things which may be copyrightable would include spell-checked or grammar-checked work, which uses a major human component as the base of the work and uses AI only to make minor adjustments. Things which should not be copyrightable include AI generated images and entire AI generated paragraphs.I have two reasons for this recommendation. Market Conditions.The first reason, as mentioned, has to do with market conditions. Because the ingestion of data has not yet been reformed, almost every image, audio, or text which has been generated so far has its roots in some element of ignoring creator rights or else deceiving or coercing creators out of said rights.Social Impacts.The second reason has to do with the practical impacts of monetised AI-generated content on our society and existing technology. Already, we\u2019ve seen instances of companies mass-generating \u201cnews\u201d or editorial content using AI and putting it up on the Internet in order to make money from it. This material is almost entirely factually nonsensical, though AI-generated text is good at sounding authoritative. As such, the Internet is already becoming far less useful, with increasing amounts of effort required in order to sift through bogus AI-generated content. Search engine companies\u2014some of the very companies which most enthusiastically champion AI\u2014do not seem to comprehend that they are making their own job more difficult by doing so. Allowing AI generated material to be copyrighted creates a brinkmanship problem: Content creators in search of a quick buck waste computing resources by deluging the Internet with nonsensical material, while search engine companies are forced to waste resources creating ever more elaborate methods of sifting through and discarding the junk. Given the sheer resources which AI already requires in order to generate a result, this feedback loop is both wildly wasteful and unsustainable.This problem will only become worse as time goes on, due to the concept of model collapse. Since AI companies are scraping the Internet without need to worry about copyright, they continue to train their models on data which contains an increasing amount of AI-generated material, itself. This eventually leads to complete model failure\u2014a circumstance which could cripple AI companies, but only after they have first made the Internet almost entirely unusable. AI companies know that model collapse is likely, which is why they assign low-wage human workers to comb through material and except data which is obviously vulgar, dangerous, or fake\u2026 but even the average person is often taken in by AI-generated articles, which sound authoritative even while they spout complete nonsense. A low-wage worker has little chance of cleaning up this false data unless it is wildly obvious.From an authorial standpoint, AI generated work is more of a headache than it is an assistant. A writer must work far harder in order to accept an AI-generated story and edit it into something coherent than they do in order to write a coherent story from scratch. Brainstorming with AI can be helpful\u2014but AI-generated work as the basis for an entire copyrighted work should be discouraged for the sake of writer sanity, if nothing else. Studios are obviously very keen on the idea of using AI to generate basic scripts and force writers to edit them into better work. I submit, as both a programmer and a writer, that this is solely because studios are currently run by people who don\u2019t understand either writing or advanced technology. It\u2019s possible, of course, that studios do understand that AI-generated work creates more trouble than it solves\u2026 in which case, by \u201ccreating\u201d a script and then handing it over to an \u201ceditor\u201d rather than to a writer (who must do even more work editing the useless script than they would do writing something original), they may therefore pay the \u201ceditor\u201d a lower rate. Either way, wholesale AI-generated work provides no actual value to society; in fact, it provides a negative value.3. Potential liability for infringing works generated using AI systems.Liability for generated infringing works should be equivalent to liability for normal infringing works. There is a saying in information security: \u201cThere\u2019s no new crime under the sun\u2014just existing crimes committed using new technology.\u201d This seems to be another instance of that.4. The treatment of generative AI outputs that imitate the identity or style of human artists.Given the explanations of negative social impact I\u2019ve mentioned above, outputs which imitate the identity or style of human artists should be treated identically to regular copyright infringement. There is absolutely no reason why US copyright should encourage the use of AI to generate new monetized content at this time.OTHER RELEVANT COMMENTARYI would hate for those reading my comments so far to believe that I think AI is without any merit whatsoever. I do believe that AI can serve a useful function. When trained with limited, self-contained, human-verified data and programmed to solve a very specific problem within a very specific domain (for instance, in order to discover new medically-useful molecules), AI can be an invaluable tool.Companies which claim that AI can be turned into an everything-tool, however, are grossly misrepresenting the technology. While it is technically possible that AI may someday become so advanced that it can generate an entire manuscript with greater speed and artistry than a human being, for instance, such an AI model would require wildly enormous resources, and would require constant retraining on human handpicked data in order to stay up to date. Any AI which involves sourcing bulk data from unreliable sources (such as the Internet) is doomed to failure.This requirement for high resources, limited data, and specific domains is why AI does not perform well when generating factual, coherent text for more than a few paragraphs at a time, while it can perform relatively well at generating images (a much narrower domain)\u2014at least until such time as model collapse comes for the image generators. As such, while the use of AI should be actively encouraged in certain technical domains, it loses much of its potential social value when applied to creative domains, and in fact generates negative value instead. In short, there is little benefit to be had in privileging AI-generated content in creative contexts at all."
        }
    ]
}